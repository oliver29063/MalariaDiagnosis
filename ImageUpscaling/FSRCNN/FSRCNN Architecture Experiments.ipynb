{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing NIH Dataset (ZIP Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-05 00:26:15--  ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
      "           => ‘cell_images.zip’\n",
      "Resolving lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)... 130.14.55.35, 2607:f220:41e:7055::35\n",
      "Connecting to lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)|130.14.55.35|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /Open-Access-Datasets/Malaria ... done.\n",
      "==> SIZE cell_images.zip ... 353452851\n",
      "==> PASV ... done.    ==> RETR cell_images.zip ... done.\n",
      "Length: 353452851 (337M) (unauthoritative)\n",
      "\n",
      "cell_images.zip     100%[===================>] 337.08M  65.7MB/s    in 5.4s    \n",
      "\n",
      "2020-03-05 00:26:22 (62.9 MB/s) - ‘cell_images.zip’ saved [353452851]\n",
      "\n",
      "Extracting images...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Download NIH dataset zip file\n",
    "!wget -nc ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
    "\n",
    "# Extract images if not already extracted\n",
    "ROOT_DIR = os.path.join(\"/\", \"content\")\n",
    "if not os.path.isdir(\"cell_images\"):\n",
    "    print(\"Extracting images...\")\n",
    "    with ZipFile(os.path.join(\"cell_images.zip\"), \"r\") as zipObj:\n",
    "        zipObj.extractall()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Images, Resize, and Store in NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.2.0.32-cp36-cp36m-manylinux1_x86_64.whl (28.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.2 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.32\n",
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease        \n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\u001b[0m                 \u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libbsd0 libice6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 x11-common\n",
      "The following NEW packages will be installed:\n",
      "  libbsd0 libice6 libsm6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6\n",
      "  libxext6 libxrender1 x11-common\n",
      "0 upgraded, 11 newly installed, 0 to remove and 28 not upgraded.\n",
      "Need to get 915 kB of archives.\n",
      "After this operation, 4091 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxau6 amd64 1:1.0.8-1 [8376 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbsd0 amd64 0.8.7-1ubuntu0.1 [41.6 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp6 amd64 1:1.1.2-3 [10.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1 amd64 1.13-2~ubuntu18.04 [45.5 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-data all 2:1.6.4-3ubuntu0.2 [113 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-6 amd64 2:1.6.4-3ubuntu0.2 [569 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxext6 amd64 2:1.3.3-1 [29.4 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libice6 amd64 2:1.0.9-2 [40.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm6 amd64 2:1.2.2-1 [15.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Fetched 915 kB in 1s (1106 kB/s)       \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libxau6:amd64.\n",
      "(Reading database ... 16107 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxau6_1%3a1.0.8-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libxau6:amd64 (1:1.0.8-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../01-libbsd0_0.8.7-1ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../02-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../03-libxcb1_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../04-libx11-data_2%3a1.6.4-3ubuntu0.2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libx11-data (2:1.6.4-3ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../05-libx11-6_2%3a1.6.4-3ubuntu0.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libx11-6:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../06-libxext6_2%3a1.3.3-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../07-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b[1mdpkg-query:\u001b[0m no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../08-libice6_2%3a1.0.9-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libice6:amd64 (2:1.0.9-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../09-libsm6_2%3a1.2.2-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../10-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libx11-data (2:1.6.4-3ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libxau6:amd64 (1:1.0.8-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libice6:amd64 (2:1.0.9-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libx11-6:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JUninfected Dataset size is: (13779, 128, 128, 3)\n",
      "Parasitized Dataset size is: (13779, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Install and import relevant packages\n",
    "import numpy as np\n",
    "import os\n",
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6 libxrender1\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Create new folders to save rescaled images\n",
    "if not os.path.isdir(\"RescaledSet\"):\n",
    "    os.mkdir(\"RescaledSet\")\n",
    "if not os.path.isdir(\"RescaledSet/Parasitized\"):\n",
    "    os.mkdir(\"RescaledSet/Parasitized\")\n",
    "if not os.path.isdir(\"RescaledSet/Uninfected\"):\n",
    "    os.mkdir(\"RescaledSet/Uninfected\")\n",
    "\n",
    "# Generate list of parasitized file names\n",
    "ParasitizedFiles = os.listdir(\"cell_images/Parasitized/\")\n",
    "UninfectedFiles = os.listdir(\"cell_images/Uninfected/\")\n",
    "\n",
    "# Remove Thumb.db files\n",
    "while 'Thumbs.db' in ParasitizedFiles: ParasitizedFiles.remove('Thumbs.db')   \n",
    "while 'Thumbs.db' in UninfectedFiles: UninfectedFiles.remove('Thumbs.db')  \n",
    "\n",
    "# Pre-allocate memory space for images\n",
    "Parasitized = np.empty([13779,128,128,3])\n",
    "Uninfected = np.empty([13779,128,128,3])\n",
    "\n",
    "# Resize and load parasitized images\n",
    "for i in range(13779):\n",
    "    TempImage = cv2.imread('cell_images/Parasitized/'+ParasitizedFiles[i])\n",
    "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
    "    Parasitized[i,:,:,:] = ResizedImage\n",
    "\n",
    "# Resize and load uninfected images\n",
    "for i in range(13779):\n",
    "    TempImage = cv2.imread('cell_images/Uninfected/'+UninfectedFiles[i])\n",
    "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
    "    Uninfected[i,:,:,:] = ResizedImage\n",
    "    \n",
    "print('Uninfected Dataset size is:',np.shape(Uninfected))\n",
    "print('Parasitized Dataset size is:',np.shape(Parasitized))\n",
    "\n",
    "\n",
    "# Generate image dataset\n",
    "Dataset = np.concatenate((Parasitized, Uninfected), axis=0)\n",
    "del Parasitized\n",
    "del Uninfected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cross-Validation Indices for Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 5-fold cross-validation groups\n",
    "CVIndices = np.random.permutation(Dataset.shape[0])\n",
    "Index1, Index2, Index3, Index4, Index5 = CVIndices[:5512], CVIndices[5512:11024], CVIndices[11024:16536], CVIndices[16536:22048], CVIndices[22048:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model and Save Results as CSV Files (4 Mapping Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = [48,56]\n",
    "Low = [12,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.8.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio>=2.3.0->scikit-image) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (44.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.13.0)\n",
      "We are now training cross-validation set # 1\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 594.9301 - mean_squared_error: 594.9299 - val_loss: 203.7362 - val_mean_squared_error: 203.7362\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 166.1296 - mean_squared_error: 166.1295 - val_loss: 146.1756 - val_mean_squared_error: 146.1755\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 134.3659 - mean_squared_error: 134.3660 - val_loss: 128.6632 - val_mean_squared_error: 128.6633\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 119.3706 - mean_squared_error: 119.3706 - val_loss: 117.2593 - val_mean_squared_error: 117.2593\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 111.1438 - mean_squared_error: 111.1438 - val_loss: 106.5403 - val_mean_squared_error: 106.5403\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 105.4757 - mean_squared_error: 105.4758 - val_loss: 108.6007 - val_mean_squared_error: 108.6007\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 12s 530us/step - loss: 101.2661 - mean_squared_error: 101.2661 - val_loss: 103.3928 - val_mean_squared_error: 103.3928\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 98.2508 - mean_squared_error: 98.2508 - val_loss: 95.2887 - val_mean_squared_error: 95.2887\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 95.2816 - mean_squared_error: 95.2817 - val_loss: 94.7613 - val_mean_squared_error: 94.7612\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 93.4984 - mean_squared_error: 93.4985 - val_loss: 90.9390 - val_mean_squared_error: 90.9390\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 515us/step - loss: 90.8159 - mean_squared_error: 90.8159 - val_loss: 94.0023 - val_mean_squared_error: 94.0023\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 89.1845 - mean_squared_error: 89.1845 - val_loss: 87.3381 - val_mean_squared_error: 87.3381\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 87.8441 - mean_squared_error: 87.8441 - val_loss: 86.7807 - val_mean_squared_error: 86.7807\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 86.1315 - mean_squared_error: 86.1315 - val_loss: 85.1342 - val_mean_squared_error: 85.1342\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 85.0324 - mean_squared_error: 85.0324 - val_loss: 83.5691 - val_mean_squared_error: 83.5691\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 83.6329 - mean_squared_error: 83.6328 - val_loss: 82.9572 - val_mean_squared_error: 82.9572\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 82.8104 - mean_squared_error: 82.8103 - val_loss: 83.3255 - val_mean_squared_error: 83.3255\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 81.7936 - mean_squared_error: 81.7936 - val_loss: 84.5377 - val_mean_squared_error: 84.5378\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 12s 537us/step - loss: 80.8336 - mean_squared_error: 80.8335 - val_loss: 81.4162 - val_mean_squared_error: 81.4162\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 80.0681 - mean_squared_error: 80.0681 - val_loss: 79.1405 - val_mean_squared_error: 79.1405\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 79.3557 - mean_squared_error: 79.3557 - val_loss: 79.9911 - val_mean_squared_error: 79.9911\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 78.5733 - mean_squared_error: 78.5733 - val_loss: 79.1043 - val_mean_squared_error: 79.1043\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 77.6059 - mean_squared_error: 77.6059 - val_loss: 77.7151 - val_mean_squared_error: 77.7150\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 77.1503 - mean_squared_error: 77.1502 - val_loss: 76.7935 - val_mean_squared_error: 76.7935\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 76.8694 - mean_squared_error: 76.8694 - val_loss: 77.2383 - val_mean_squared_error: 77.2382\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 75.4786 - mean_squared_error: 75.4786 - val_loss: 77.6211 - val_mean_squared_error: 77.6211\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 75.6118 - mean_squared_error: 75.6119 - val_loss: 78.3373 - val_mean_squared_error: 78.3373\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 75.0300 - mean_squared_error: 75.0300 - val_loss: 74.4225 - val_mean_squared_error: 74.4225\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 74.1810 - mean_squared_error: 74.1810 - val_loss: 75.6450 - val_mean_squared_error: 75.6451\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 73.8420 - mean_squared_error: 73.8420 - val_loss: 77.3512 - val_mean_squared_error: 77.3511\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 73.3605 - mean_squared_error: 73.3605 - val_loss: 77.0565 - val_mean_squared_error: 77.0565\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 12s 534us/step - loss: 72.9143 - mean_squared_error: 72.9143 - val_loss: 73.4573 - val_mean_squared_error: 73.4573\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 72.6312 - mean_squared_error: 72.6311 - val_loss: 73.9370 - val_mean_squared_error: 73.9370\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 72.1558 - mean_squared_error: 72.1557 - val_loss: 72.8497 - val_mean_squared_error: 72.8497\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 71.5316 - mean_squared_error: 71.5316 - val_loss: 75.7764 - val_mean_squared_error: 75.7764\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 71.2733 - mean_squared_error: 71.2732 - val_loss: 72.5069 - val_mean_squared_error: 72.5069\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 70.8539 - mean_squared_error: 70.8539 - val_loss: 71.1679 - val_mean_squared_error: 71.1678\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 70.6309 - mean_squared_error: 70.6309 - val_loss: 71.2583 - val_mean_squared_error: 71.2583\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 70.1445 - mean_squared_error: 70.1445 - val_loss: 70.7472 - val_mean_squared_error: 70.7472\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 69.8937 - mean_squared_error: 69.8937 - val_loss: 70.2922 - val_mean_squared_error: 70.2922\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 12s 546us/step - loss: 69.5859 - mean_squared_error: 69.5859 - val_loss: 70.6857 - val_mean_squared_error: 70.6857\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 69.3632 - mean_squared_error: 69.3632 - val_loss: 69.7271 - val_mean_squared_error: 69.7271\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 69.0037 - mean_squared_error: 69.0037 - val_loss: 92.2461 - val_mean_squared_error: 92.2461\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 68.3414 - mean_squared_error: 68.3415 - val_loss: 70.5195 - val_mean_squared_error: 70.5195\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 68.2653 - mean_squared_error: 68.2652 - val_loss: 70.3200 - val_mean_squared_error: 70.3199\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 68.0932 - mean_squared_error: 68.0932 - val_loss: 71.6937 - val_mean_squared_error: 71.6936\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 67.6450 - mean_squared_error: 67.6449 - val_loss: 69.3764 - val_mean_squared_error: 69.3764\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 67.3134 - mean_squared_error: 67.3133 - val_loss: 69.3653 - val_mean_squared_error: 69.3653\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 67.1678 - mean_squared_error: 67.1678 - val_loss: 72.9584 - val_mean_squared_error: 72.9584\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 12s 546us/step - loss: 66.7860 - mean_squared_error: 66.7860 - val_loss: 73.6235 - val_mean_squared_error: 73.6235\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 12s 534us/step - loss: 66.6635 - mean_squared_error: 66.6635 - val_loss: 68.7892 - val_mean_squared_error: 68.7892\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 66.5903 - mean_squared_error: 66.5903 - val_loss: 66.8699 - val_mean_squared_error: 66.8699\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 66.1391 - mean_squared_error: 66.1391 - val_loss: 66.9922 - val_mean_squared_error: 66.9922\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 65.8843 - mean_squared_error: 65.8843 - val_loss: 68.2132 - val_mean_squared_error: 68.2132\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 12s 536us/step - loss: 65.7545 - mean_squared_error: 65.7545 - val_loss: 67.1386 - val_mean_squared_error: 67.1386\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 65.5636 - mean_squared_error: 65.5636 - val_loss: 68.8796 - val_mean_squared_error: 68.8796\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 65.1994 - mean_squared_error: 65.1994 - val_loss: 66.9628 - val_mean_squared_error: 66.9628\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 65.1230 - mean_squared_error: 65.1229 - val_loss: 66.3031 - val_mean_squared_error: 66.3031\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 65.0539 - mean_squared_error: 65.0539 - val_loss: 66.2971 - val_mean_squared_error: 66.2971\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 64.8518 - mean_squared_error: 64.8519 - val_loss: 78.6015 - val_mean_squared_error: 78.6015\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 64.5346 - mean_squared_error: 64.5346 - val_loss: 66.1903 - val_mean_squared_error: 66.1903\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 64.3473 - mean_squared_error: 64.3473 - val_loss: 66.0383 - val_mean_squared_error: 66.0383\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 64.2622 - mean_squared_error: 64.2621 - val_loss: 65.3719 - val_mean_squared_error: 65.3719\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 63.9948 - mean_squared_error: 63.9948 - val_loss: 65.3084 - val_mean_squared_error: 65.3084\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 63.9391 - mean_squared_error: 63.9391 - val_loss: 65.1375 - val_mean_squared_error: 65.1375\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 63.7776 - mean_squared_error: 63.7775 - val_loss: 65.1730 - val_mean_squared_error: 65.1730\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 63.4518 - mean_squared_error: 63.4518 - val_loss: 65.4932 - val_mean_squared_error: 65.4932\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 63.6447 - mean_squared_error: 63.6448 - val_loss: 64.8099 - val_mean_squared_error: 64.8099\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 63.0444 - mean_squared_error: 63.0444 - val_loss: 64.8913 - val_mean_squared_error: 64.8913\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 63.2911 - mean_squared_error: 63.2910 - val_loss: 66.5460 - val_mean_squared_error: 66.5459\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 62.9507 - mean_squared_error: 62.9507 - val_loss: 64.4241 - val_mean_squared_error: 64.4241\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 62.8582 - mean_squared_error: 62.8582 - val_loss: 64.4497 - val_mean_squared_error: 64.4497\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 62.9957 - mean_squared_error: 62.9957 - val_loss: 63.8567 - val_mean_squared_error: 63.8567\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 62.4945 - mean_squared_error: 62.4945 - val_loss: 64.2022 - val_mean_squared_error: 64.2022\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 62.3254 - mean_squared_error: 62.3254 - val_loss: 64.1071 - val_mean_squared_error: 64.1071\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 62.2657 - mean_squared_error: 62.2657 - val_loss: 65.0343 - val_mean_squared_error: 65.0343\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 12s 535us/step - loss: 62.2711 - mean_squared_error: 62.2710 - val_loss: 63.9309 - val_mean_squared_error: 63.9309\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 62.0066 - mean_squared_error: 62.0066 - val_loss: 65.6781 - val_mean_squared_error: 65.6781\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 61.7884 - mean_squared_error: 61.7884 - val_loss: 71.3683 - val_mean_squared_error: 71.3683\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 61.7251 - mean_squared_error: 61.7251 - val_loss: 64.5739 - val_mean_squared_error: 64.5738\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 61.5863 - mean_squared_error: 61.5863 - val_loss: 63.7728 - val_mean_squared_error: 63.7728\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 61.4861 - mean_squared_error: 61.4861 - val_loss: 65.6532 - val_mean_squared_error: 65.6532\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 61.2960 - mean_squared_error: 61.2960 - val_loss: 62.8945 - val_mean_squared_error: 62.8945\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 61.2752 - mean_squared_error: 61.2753 - val_loss: 63.3359 - val_mean_squared_error: 63.3358\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 61.0822 - mean_squared_error: 61.0822 - val_loss: 63.7823 - val_mean_squared_error: 63.7823\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 60.9581 - mean_squared_error: 60.9581 - val_loss: 62.6280 - val_mean_squared_error: 62.6280\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 61.1036 - mean_squared_error: 61.1036 - val_loss: 63.3092 - val_mean_squared_error: 63.3092\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 60.7065 - mean_squared_error: 60.7065 - val_loss: 61.9412 - val_mean_squared_error: 61.9412\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 60.6277 - mean_squared_error: 60.6277 - val_loss: 63.4894 - val_mean_squared_error: 63.4894\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 60.6720 - mean_squared_error: 60.6720 - val_loss: 61.9854 - val_mean_squared_error: 61.9854\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 60.4204 - mean_squared_error: 60.4204 - val_loss: 64.5331 - val_mean_squared_error: 64.5331\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 60.3350 - mean_squared_error: 60.3350 - val_loss: 64.4836 - val_mean_squared_error: 64.4836\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 60.1969 - mean_squared_error: 60.1969 - val_loss: 62.6856 - val_mean_squared_error: 62.6856\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 11s 522us/step - loss: 60.1357 - mean_squared_error: 60.1357 - val_loss: 62.4945 - val_mean_squared_error: 62.4945\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 60.0855 - mean_squared_error: 60.0855 - val_loss: 61.5269 - val_mean_squared_error: 61.5268\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 59.8050 - mean_squared_error: 59.8050 - val_loss: 62.5711 - val_mean_squared_error: 62.5711\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 59.8515 - mean_squared_error: 59.8515 - val_loss: 62.1013 - val_mean_squared_error: 62.1012\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 59.7560 - mean_squared_error: 59.7559 - val_loss: 61.8026 - val_mean_squared_error: 61.8025\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 59.9088 - mean_squared_error: 59.9088 - val_loss: 63.4806 - val_mean_squared_error: 63.4807\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 59.4228 - mean_squared_error: 59.4229 - val_loss: 62.0649 - val_mean_squared_error: 62.0649\n",
      "Training Loss: [594.9301, 166.1296, 134.3659, 119.3706, 111.1438, 105.4757, 101.2661, 98.2508, 95.2816, 93.4984, 90.8159, 89.1845, 87.8441, 86.1315, 85.0324, 83.6329, 82.8104, 81.7936, 80.8336, 80.0681, 79.3557, 78.5733, 77.6059, 77.1503, 76.8694, 75.4786, 75.6118, 75.03, 74.181, 73.842, 73.3605, 72.9143, 72.6312, 72.1558, 71.5316, 71.2733, 70.8539, 70.6309, 70.1445, 69.8937, 69.5859, 69.3632, 69.0037, 68.3414, 68.2653, 68.0932, 67.645, 67.3134, 67.1678, 66.786, 66.6635, 66.5903, 66.1391, 65.8843, 65.7545, 65.5636, 65.1994, 65.123, 65.0539, 64.8518, 64.5346, 64.3473, 64.2622, 63.9948, 63.9391, 63.7776, 63.4518, 63.6447, 63.0444, 63.2911, 62.9507, 62.8582, 62.9957, 62.4945, 62.3254, 62.2657, 62.2711, 62.0066, 61.7884, 61.7251, 61.5863, 61.4861, 61.296, 61.2752, 61.0822, 60.9581, 61.1036, 60.7065, 60.6277, 60.672, 60.4204, 60.335, 60.1969, 60.1357, 60.0855, 59.805, 59.8515, 59.756, 59.9088, 59.4228]\n",
      "Validation Loss: [203.7362, 146.1756, 128.6632, 117.2593, 106.5403, 108.6007, 103.3928, 95.2887, 94.7613, 90.939, 94.0023, 87.3381, 86.7807, 85.1342, 83.5691, 82.9572, 83.3255, 84.5377, 81.4162, 79.1405, 79.9911, 79.1043, 77.7151, 76.7935, 77.2383, 77.6211, 78.3373, 74.4225, 75.645, 77.3512, 77.0565, 73.4573, 73.937, 72.8497, 75.7764, 72.5069, 71.1679, 71.2583, 70.7472, 70.2922, 70.6857, 69.7271, 92.2461, 70.5195, 70.32, 71.6937, 69.3764, 69.3653, 72.9584, 73.6235, 68.7892, 66.8699, 66.9922, 68.2132, 67.1386, 68.8796, 66.9628, 66.3031, 66.2971, 78.6015, 66.1903, 66.0383, 65.3719, 65.3084, 65.1375, 65.173, 65.4932, 64.8099, 64.8913, 66.546, 64.4241, 64.4497, 63.8567, 64.2022, 64.1071, 65.0343, 63.9309, 65.6781, 71.3683, 64.5739, 63.7728, 65.6532, 62.8945, 63.3359, 63.7823, 62.628, 63.3092, 61.9412, 63.4894, 61.9854, 64.5331, 64.4836, 62.6856, 62.4945, 61.5269, 62.5711, 62.1013, 61.8026, 63.4806, 62.0649]\n",
      "\n",
      "We are now training cross-validation set # 2\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 13s 569us/step - loss: 522.3219 - mean_squared_error: 522.3218 - val_loss: 210.7788 - val_mean_squared_error: 210.7787\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 174.0159 - mean_squared_error: 174.0158 - val_loss: 152.3440 - val_mean_squared_error: 152.3439\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 12s 545us/step - loss: 141.0509 - mean_squared_error: 141.0509 - val_loss: 135.6127 - val_mean_squared_error: 135.6127\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 127.7250 - mean_squared_error: 127.7250 - val_loss: 121.7883 - val_mean_squared_error: 121.7883\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 119.2823 - mean_squared_error: 119.2823 - val_loss: 114.5626 - val_mean_squared_error: 114.5627\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 113.6921 - mean_squared_error: 113.6920 - val_loss: 112.9601 - val_mean_squared_error: 112.9601\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 109.7754 - mean_squared_error: 109.7754 - val_loss: 106.6869 - val_mean_squared_error: 106.6869\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 106.0718 - mean_squared_error: 106.0718 - val_loss: 103.4024 - val_mean_squared_error: 103.4024\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 12s 545us/step - loss: 103.5483 - mean_squared_error: 103.5483 - val_loss: 102.3951 - val_mean_squared_error: 102.3951\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 100.8407 - mean_squared_error: 100.8407 - val_loss: 99.9381 - val_mean_squared_error: 99.9381\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 99.0351 - mean_squared_error: 99.0351 - val_loss: 98.3156 - val_mean_squared_error: 98.3156\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 97.7214 - mean_squared_error: 97.7214 - val_loss: 95.3355 - val_mean_squared_error: 95.3355\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 96.0154 - mean_squared_error: 96.0154 - val_loss: 95.1908 - val_mean_squared_error: 95.1908\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 94.7000 - mean_squared_error: 94.7000 - val_loss: 93.8107 - val_mean_squared_error: 93.8108\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 93.0065 - mean_squared_error: 93.0065 - val_loss: 92.0712 - val_mean_squared_error: 92.0712\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 12s 545us/step - loss: 92.2431 - mean_squared_error: 92.2432 - val_loss: 94.5209 - val_mean_squared_error: 94.5209\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 90.5438 - mean_squared_error: 90.5437 - val_loss: 93.2786 - val_mean_squared_error: 93.2786\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 89.4894 - mean_squared_error: 89.4895 - val_loss: 91.4073 - val_mean_squared_error: 91.4073\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 89.0047 - mean_squared_error: 89.0047 - val_loss: 87.3650 - val_mean_squared_error: 87.3650\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 87.4145 - mean_squared_error: 87.4145 - val_loss: 87.2747 - val_mean_squared_error: 87.2746\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 497us/step - loss: 87.1469 - mean_squared_error: 87.1469 - val_loss: 85.6566 - val_mean_squared_error: 85.6567\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 85.3635 - mean_squared_error: 85.3635 - val_loss: 87.4527 - val_mean_squared_error: 87.4527\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 84.6244 - mean_squared_error: 84.6244 - val_loss: 83.8036 - val_mean_squared_error: 83.8036\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 84.1769 - mean_squared_error: 84.1769 - val_loss: 82.7084 - val_mean_squared_error: 82.7084\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 82.8227 - mean_squared_error: 82.8227 - val_loss: 83.6658 - val_mean_squared_error: 83.6658\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 82.6560 - mean_squared_error: 82.6559 - val_loss: 82.4295 - val_mean_squared_error: 82.4295\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 81.7002 - mean_squared_error: 81.7002 - val_loss: 83.0565 - val_mean_squared_error: 83.0565\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 80.7282 - mean_squared_error: 80.7283 - val_loss: 107.5516 - val_mean_squared_error: 107.5516\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 12s 537us/step - loss: 79.9249 - mean_squared_error: 79.9249 - val_loss: 84.7742 - val_mean_squared_error: 84.7742\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 12s 532us/step - loss: 79.3868 - mean_squared_error: 79.3868 - val_loss: 79.1562 - val_mean_squared_error: 79.1562\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 11s 493us/step - loss: 78.5509 - mean_squared_error: 78.5509 - val_loss: 78.6847 - val_mean_squared_error: 78.6847\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 78.3381 - mean_squared_error: 78.3381 - val_loss: 78.3585 - val_mean_squared_error: 78.3586\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 77.6902 - mean_squared_error: 77.6902 - val_loss: 77.7625 - val_mean_squared_error: 77.7625\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 76.8701 - mean_squared_error: 76.8701 - val_loss: 82.4434 - val_mean_squared_error: 82.4434\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 76.9777 - mean_squared_error: 76.9777 - val_loss: 79.5731 - val_mean_squared_error: 79.5731\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 75.7966 - mean_squared_error: 75.7966 - val_loss: 76.1755 - val_mean_squared_error: 76.1755\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 498us/step - loss: 75.7467 - mean_squared_error: 75.7467 - val_loss: 76.0041 - val_mean_squared_error: 76.0041\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 75.5249 - mean_squared_error: 75.5249 - val_loss: 76.6464 - val_mean_squared_error: 76.6464\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 74.5393 - mean_squared_error: 74.5392 - val_loss: 75.3569 - val_mean_squared_error: 75.3569\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 74.3917 - mean_squared_error: 74.3917 - val_loss: 75.6852 - val_mean_squared_error: 75.6852\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 12s 547us/step - loss: 74.2612 - mean_squared_error: 74.2612 - val_loss: 74.6692 - val_mean_squared_error: 74.6692\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 73.8583 - mean_squared_error: 73.8583 - val_loss: 74.8698 - val_mean_squared_error: 74.8697\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 73.5145 - mean_squared_error: 73.5145 - val_loss: 73.8480 - val_mean_squared_error: 73.8480\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 12s 540us/step - loss: 73.0484 - mean_squared_error: 73.0484 - val_loss: 73.4745 - val_mean_squared_error: 73.4745\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 72.8180 - mean_squared_error: 72.8180 - val_loss: 74.9822 - val_mean_squared_error: 74.9822\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 72.4832 - mean_squared_error: 72.4832 - val_loss: 74.1779 - val_mean_squared_error: 74.1780\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 12s 537us/step - loss: 72.1177 - mean_squared_error: 72.1177 - val_loss: 74.3702 - val_mean_squared_error: 74.3702\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 12s 535us/step - loss: 72.0837 - mean_squared_error: 72.0837 - val_loss: 73.7581 - val_mean_squared_error: 73.7581\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 12s 535us/step - loss: 71.6418 - mean_squared_error: 71.6418 - val_loss: 73.4431 - val_mean_squared_error: 73.4431\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 12s 546us/step - loss: 71.4012 - mean_squared_error: 71.4012 - val_loss: 72.7549 - val_mean_squared_error: 72.7549\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 71.1332 - mean_squared_error: 71.1332 - val_loss: 74.2403 - val_mean_squared_error: 74.2402\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 70.7813 - mean_squared_error: 70.7813 - val_loss: 72.9971 - val_mean_squared_error: 72.9971\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 12s 551us/step - loss: 70.6522 - mean_squared_error: 70.6522 - val_loss: 84.2703 - val_mean_squared_error: 84.2703\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 70.4366 - mean_squared_error: 70.4366 - val_loss: 71.7607 - val_mean_squared_error: 71.7607\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 70.0121 - mean_squared_error: 70.0121 - val_loss: 72.9807 - val_mean_squared_error: 72.9807\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 492us/step - loss: 69.8868 - mean_squared_error: 69.8868 - val_loss: 70.5779 - val_mean_squared_error: 70.5779\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 69.7063 - mean_squared_error: 69.7062 - val_loss: 70.8781 - val_mean_squared_error: 70.8781\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 69.1275 - mean_squared_error: 69.1275 - val_loss: 70.6519 - val_mean_squared_error: 70.6519\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 69.2800 - mean_squared_error: 69.2800 - val_loss: 70.9929 - val_mean_squared_error: 70.9930\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 69.1297 - mean_squared_error: 69.1297 - val_loss: 71.0864 - val_mean_squared_error: 71.0864\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 12s 545us/step - loss: 68.4289 - mean_squared_error: 68.4289 - val_loss: 70.6241 - val_mean_squared_error: 70.6241\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 68.6629 - mean_squared_error: 68.6629 - val_loss: 73.0664 - val_mean_squared_error: 73.0663\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 11s 490us/step - loss: 68.0455 - mean_squared_error: 68.0455 - val_loss: 69.2470 - val_mean_squared_error: 69.2470\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 11s 494us/step - loss: 68.0842 - mean_squared_error: 68.0843 - val_loss: 69.4033 - val_mean_squared_error: 69.4033\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 67.9345 - mean_squared_error: 67.9345 - val_loss: 68.8937 - val_mean_squared_error: 68.8937\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 67.7684 - mean_squared_error: 67.7683 - val_loss: 69.4727 - val_mean_squared_error: 69.4727\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 67.2922 - mean_squared_error: 67.2922 - val_loss: 68.6911 - val_mean_squared_error: 68.6911\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 67.1959 - mean_squared_error: 67.1960 - val_loss: 68.8366 - val_mean_squared_error: 68.8366\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 67.1169 - mean_squared_error: 67.1169 - val_loss: 74.8512 - val_mean_squared_error: 74.8511\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 66.9910 - mean_squared_error: 66.9910 - val_loss: 69.0284 - val_mean_squared_error: 69.0283\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 66.6671 - mean_squared_error: 66.6671 - val_loss: 71.1450 - val_mean_squared_error: 71.1451\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 66.4018 - mean_squared_error: 66.4019 - val_loss: 68.3491 - val_mean_squared_error: 68.3491\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 12s 543us/step - loss: 66.4728 - mean_squared_error: 66.4728 - val_loss: 68.4518 - val_mean_squared_error: 68.4518\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 12s 542us/step - loss: 66.0466 - mean_squared_error: 66.0466 - val_loss: 68.0353 - val_mean_squared_error: 68.0353\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 66.0464 - mean_squared_error: 66.0464 - val_loss: 68.4447 - val_mean_squared_error: 68.4447\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 65.9582 - mean_squared_error: 65.9581 - val_loss: 68.3883 - val_mean_squared_error: 68.3883\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 12s 536us/step - loss: 65.7037 - mean_squared_error: 65.7037 - val_loss: 66.9194 - val_mean_squared_error: 66.9195\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 11s 494us/step - loss: 65.5183 - mean_squared_error: 65.5183 - val_loss: 67.3110 - val_mean_squared_error: 67.3110\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 494us/step - loss: 65.2995 - mean_squared_error: 65.2995 - val_loss: 76.7751 - val_mean_squared_error: 76.7751\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 65.2220 - mean_squared_error: 65.2220 - val_loss: 68.0866 - val_mean_squared_error: 68.0866\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 65.0435 - mean_squared_error: 65.0435 - val_loss: 66.4381 - val_mean_squared_error: 66.4382\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 64.9091 - mean_squared_error: 64.9091 - val_loss: 70.4570 - val_mean_squared_error: 70.4570\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 12s 541us/step - loss: 64.8316 - mean_squared_error: 64.8316 - val_loss: 66.6771 - val_mean_squared_error: 66.6771\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 64.9230 - mean_squared_error: 64.9230 - val_loss: 69.2658 - val_mean_squared_error: 69.2658\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 12s 546us/step - loss: 64.2670 - mean_squared_error: 64.2670 - val_loss: 67.8567 - val_mean_squared_error: 67.8567\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 64.4826 - mean_squared_error: 64.4826 - val_loss: 66.8855 - val_mean_squared_error: 66.8855\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 13s 573us/step - loss: 64.2627 - mean_squared_error: 64.2627 - val_loss: 65.9498 - val_mean_squared_error: 65.9499\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 12s 562us/step - loss: 63.8733 - mean_squared_error: 63.8734 - val_loss: 65.7997 - val_mean_squared_error: 65.7997\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 12s 559us/step - loss: 64.1237 - mean_squared_error: 64.1237 - val_loss: 66.0588 - val_mean_squared_error: 66.0588\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 12s 558us/step - loss: 63.8535 - mean_squared_error: 63.8535 - val_loss: 65.6861 - val_mean_squared_error: 65.6861\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 12s 552us/step - loss: 63.5619 - mean_squared_error: 63.5618 - val_loss: 65.2083 - val_mean_squared_error: 65.2083\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 12s 550us/step - loss: 63.6304 - mean_squared_error: 63.6304 - val_loss: 65.6155 - val_mean_squared_error: 65.6155\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 63.5782 - mean_squared_error: 63.5782 - val_loss: 67.5666 - val_mean_squared_error: 67.5666\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 63.1113 - mean_squared_error: 63.1112 - val_loss: 65.0887 - val_mean_squared_error: 65.0887\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.2950 - mean_squared_error: 63.2951 - val_loss: 65.2453 - val_mean_squared_error: 65.2453\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 62.9592 - mean_squared_error: 62.9592 - val_loss: 64.8593 - val_mean_squared_error: 64.8593\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.1970 - mean_squared_error: 63.1970 - val_loss: 65.6499 - val_mean_squared_error: 65.6498\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 62.8062 - mean_squared_error: 62.8062 - val_loss: 64.6210 - val_mean_squared_error: 64.6210\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 62.5605 - mean_squared_error: 62.5605 - val_loss: 67.7590 - val_mean_squared_error: 67.7590\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 12s 534us/step - loss: 62.5347 - mean_squared_error: 62.5347 - val_loss: 65.0819 - val_mean_squared_error: 65.0819\n",
      "Training Loss: [522.3219, 174.0159, 141.0509, 127.725, 119.2823, 113.6921, 109.7754, 106.0718, 103.5483, 100.8407, 99.0351, 97.7214, 96.0154, 94.7, 93.0065, 92.2431, 90.5438, 89.4894, 89.0047, 87.4145, 87.1469, 85.3635, 84.6244, 84.1769, 82.8227, 82.656, 81.7002, 80.7282, 79.9249, 79.3868, 78.5509, 78.3381, 77.6902, 76.8701, 76.9777, 75.7966, 75.7467, 75.5249, 74.5393, 74.3917, 74.2612, 73.8583, 73.5145, 73.0484, 72.818, 72.4832, 72.1177, 72.0837, 71.6418, 71.4012, 71.1332, 70.7813, 70.6522, 70.4366, 70.0121, 69.8868, 69.7063, 69.1275, 69.28, 69.1297, 68.4289, 68.6629, 68.0455, 68.0842, 67.9345, 67.7684, 67.2922, 67.1959, 67.1169, 66.991, 66.6671, 66.4018, 66.4728, 66.0466, 66.0464, 65.9582, 65.7037, 65.5183, 65.2995, 65.222, 65.0435, 64.9091, 64.8316, 64.923, 64.267, 64.4826, 64.2627, 63.8733, 64.1237, 63.8535, 63.5619, 63.6304, 63.5782, 63.1113, 63.295, 62.9592, 63.197, 62.8062, 62.5605, 62.5347]\n",
      "Validation Loss: [210.7788, 152.344, 135.6127, 121.7883, 114.5626, 112.9601, 106.6869, 103.4024, 102.3951, 99.9381, 98.3156, 95.3355, 95.1908, 93.8107, 92.0712, 94.5209, 93.2786, 91.4073, 87.365, 87.2747, 85.6566, 87.4527, 83.8036, 82.7084, 83.6658, 82.4295, 83.0565, 107.5516, 84.7742, 79.1562, 78.6847, 78.3585, 77.7625, 82.4434, 79.5731, 76.1755, 76.0041, 76.6464, 75.3569, 75.6852, 74.6692, 74.8698, 73.848, 73.4745, 74.9822, 74.1779, 74.3702, 73.7581, 73.4431, 72.7549, 74.2403, 72.9971, 84.2703, 71.7607, 72.9807, 70.5779, 70.8781, 70.6519, 70.9929, 71.0864, 70.6241, 73.0664, 69.247, 69.4033, 68.8937, 69.4727, 68.6911, 68.8366, 74.8512, 69.0284, 71.145, 68.3491, 68.4518, 68.0353, 68.4447, 68.3883, 66.9194, 67.311, 76.7751, 68.0866, 66.4381, 70.457, 66.6771, 69.2658, 67.8567, 66.8855, 65.9498, 65.7997, 66.0588, 65.6861, 65.2083, 65.6155, 67.5666, 65.0887, 65.2453, 64.8593, 65.6499, 64.621, 67.759, 65.0819]\n",
      "\n",
      "We are now training cross-validation set # 3\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 588.2167 - mean_squared_error: 588.2163 - val_loss: 213.8233 - val_mean_squared_error: 213.8234\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 174.4953 - mean_squared_error: 174.4951 - val_loss: 157.7019 - val_mean_squared_error: 157.7018\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 497us/step - loss: 142.9551 - mean_squared_error: 142.9550 - val_loss: 135.2522 - val_mean_squared_error: 135.2521\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 127.9245 - mean_squared_error: 127.9245 - val_loss: 131.9459 - val_mean_squared_error: 131.9458\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 118.8503 - mean_squared_error: 118.8503 - val_loss: 115.7041 - val_mean_squared_error: 115.7041\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 113.7548 - mean_squared_error: 113.7548 - val_loss: 117.7709 - val_mean_squared_error: 117.7709\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 108.6824 - mean_squared_error: 108.6824 - val_loss: 105.8292 - val_mean_squared_error: 105.8292\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 105.8325 - mean_squared_error: 105.8326 - val_loss: 102.9744 - val_mean_squared_error: 102.9743\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 102.7294 - mean_squared_error: 102.7294 - val_loss: 104.1050 - val_mean_squared_error: 104.1050\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 99.5854 - mean_squared_error: 99.5854 - val_loss: 99.5885 - val_mean_squared_error: 99.5885\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 97.7639 - mean_squared_error: 97.7639 - val_loss: 95.5731 - val_mean_squared_error: 95.5730\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 95.5804 - mean_squared_error: 95.5804 - val_loss: 93.3357 - val_mean_squared_error: 93.3357\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 93.2074 - mean_squared_error: 93.2074 - val_loss: 91.7771 - val_mean_squared_error: 91.7772\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 91.3585 - mean_squared_error: 91.3586 - val_loss: 91.0266 - val_mean_squared_error: 91.0266\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 463us/step - loss: 89.8440 - mean_squared_error: 89.8440 - val_loss: 89.1324 - val_mean_squared_error: 89.1323\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 88.2659 - mean_squared_error: 88.2660 - val_loss: 86.9343 - val_mean_squared_error: 86.9343\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 87.0363 - mean_squared_error: 87.0363 - val_loss: 85.5360 - val_mean_squared_error: 85.5360\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 85.9878 - mean_squared_error: 85.9878 - val_loss: 84.3326 - val_mean_squared_error: 84.3326\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 84.1429 - mean_squared_error: 84.1429 - val_loss: 83.2826 - val_mean_squared_error: 83.2826\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 83.4715 - mean_squared_error: 83.4715 - val_loss: 84.3726 - val_mean_squared_error: 84.3726\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 82.4523 - mean_squared_error: 82.4523 - val_loss: 81.1575 - val_mean_squared_error: 81.1575\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 81.0351 - mean_squared_error: 81.0351 - val_loss: 80.8438 - val_mean_squared_error: 80.8438\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 80.1335 - mean_squared_error: 80.1335 - val_loss: 86.1209 - val_mean_squared_error: 86.1208\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 79.3225 - mean_squared_error: 79.3226 - val_loss: 79.7618 - val_mean_squared_error: 79.7619\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 78.3595 - mean_squared_error: 78.3595 - val_loss: 78.0056 - val_mean_squared_error: 78.0056\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 78.0202 - mean_squared_error: 78.0202 - val_loss: 77.0842 - val_mean_squared_error: 77.0842\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 77.2606 - mean_squared_error: 77.2606 - val_loss: 77.0570 - val_mean_squared_error: 77.0569\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 76.1463 - mean_squared_error: 76.1463 - val_loss: 77.0401 - val_mean_squared_error: 77.0401\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 463us/step - loss: 75.2638 - mean_squared_error: 75.2638 - val_loss: 75.8544 - val_mean_squared_error: 75.8544\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 75.1450 - mean_squared_error: 75.1450 - val_loss: 74.5886 - val_mean_squared_error: 74.5887\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 74.4085 - mean_squared_error: 74.4085 - val_loss: 75.6767 - val_mean_squared_error: 75.6767\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 73.7345 - mean_squared_error: 73.7345 - val_loss: 74.0007 - val_mean_squared_error: 74.0007\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 73.5482 - mean_squared_error: 73.5483 - val_loss: 73.3065 - val_mean_squared_error: 73.3065\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 72.7744 - mean_squared_error: 72.7744 - val_loss: 77.3131 - val_mean_squared_error: 77.3131\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 72.3925 - mean_squared_error: 72.3925 - val_loss: 72.6493 - val_mean_squared_error: 72.6493\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 72.0303 - mean_squared_error: 72.0303 - val_loss: 72.7462 - val_mean_squared_error: 72.7462\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 71.9247 - mean_squared_error: 71.9246 - val_loss: 71.9561 - val_mean_squared_error: 71.9561\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 71.0226 - mean_squared_error: 71.0226 - val_loss: 71.7946 - val_mean_squared_error: 71.7946\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 70.6724 - mean_squared_error: 70.6725 - val_loss: 74.0891 - val_mean_squared_error: 74.0891\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 70.5253 - mean_squared_error: 70.5253 - val_loss: 70.6884 - val_mean_squared_error: 70.6884\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.9095 - mean_squared_error: 69.9095 - val_loss: 71.5539 - val_mean_squared_error: 71.5539\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 69.8968 - mean_squared_error: 69.8968 - val_loss: 76.2672 - val_mean_squared_error: 76.2672\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 69.1608 - mean_squared_error: 69.1609 - val_loss: 70.8838 - val_mean_squared_error: 70.8838\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 69.5053 - mean_squared_error: 69.5053 - val_loss: 69.8471 - val_mean_squared_error: 69.8471\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 68.5007 - mean_squared_error: 68.5006 - val_loss: 69.4017 - val_mean_squared_error: 69.4017\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 68.6904 - mean_squared_error: 68.6904 - val_loss: 68.9173 - val_mean_squared_error: 68.9173\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 67.8978 - mean_squared_error: 67.8978 - val_loss: 69.3147 - val_mean_squared_error: 69.3147\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 67.8627 - mean_squared_error: 67.8627 - val_loss: 69.7935 - val_mean_squared_error: 69.7935\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 67.6914 - mean_squared_error: 67.6914 - val_loss: 68.5406 - val_mean_squared_error: 68.5406\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 67.5899 - mean_squared_error: 67.5899 - val_loss: 68.4372 - val_mean_squared_error: 68.4372\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 67.0460 - mean_squared_error: 67.0460 - val_loss: 73.2336 - val_mean_squared_error: 73.2336\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 67.0449 - mean_squared_error: 67.0450 - val_loss: 79.1729 - val_mean_squared_error: 79.1729\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 66.6769 - mean_squared_error: 66.6769 - val_loss: 67.6436 - val_mean_squared_error: 67.6436\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 66.3910 - mean_squared_error: 66.3910 - val_loss: 67.7382 - val_mean_squared_error: 67.7382\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 66.1154 - mean_squared_error: 66.1154 - val_loss: 68.8601 - val_mean_squared_error: 68.8601\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 66.0704 - mean_squared_error: 66.0704 - val_loss: 67.5735 - val_mean_squared_error: 67.5735\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 65.8455 - mean_squared_error: 65.8455 - val_loss: 67.2957 - val_mean_squared_error: 67.2957\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 65.5243 - mean_squared_error: 65.5242 - val_loss: 67.5490 - val_mean_squared_error: 67.5490\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 65.3264 - mean_squared_error: 65.3264 - val_loss: 66.7423 - val_mean_squared_error: 66.7423\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 65.2366 - mean_squared_error: 65.2366 - val_loss: 68.2852 - val_mean_squared_error: 68.2852\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 65.0769 - mean_squared_error: 65.0768 - val_loss: 66.2495 - val_mean_squared_error: 66.2495\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 64.9513 - mean_squared_error: 64.9514 - val_loss: 65.9746 - val_mean_squared_error: 65.9746\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 64.8165 - mean_squared_error: 64.8165 - val_loss: 66.1348 - val_mean_squared_error: 66.1348\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 64.2012 - mean_squared_error: 64.2012 - val_loss: 66.3060 - val_mean_squared_error: 66.3059\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 64.2988 - mean_squared_error: 64.2988 - val_loss: 65.4059 - val_mean_squared_error: 65.4059\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 64.1128 - mean_squared_error: 64.1128 - val_loss: 70.8624 - val_mean_squared_error: 70.8624\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 64.0060 - mean_squared_error: 64.0060 - val_loss: 65.9768 - val_mean_squared_error: 65.9768\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 63.6805 - mean_squared_error: 63.6806 - val_loss: 64.7131 - val_mean_squared_error: 64.7131\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 63.4926 - mean_squared_error: 63.4925 - val_loss: 66.5154 - val_mean_squared_error: 66.5154\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 63.5149 - mean_squared_error: 63.5149 - val_loss: 64.9516 - val_mean_squared_error: 64.9516\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 63.0695 - mean_squared_error: 63.0695 - val_loss: 64.6586 - val_mean_squared_error: 64.6586\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 63.2035 - mean_squared_error: 63.2036 - val_loss: 65.0573 - val_mean_squared_error: 65.0573\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 62.8710 - mean_squared_error: 62.8710 - val_loss: 66.6021 - val_mean_squared_error: 66.6021\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 62.8484 - mean_squared_error: 62.8484 - val_loss: 64.3405 - val_mean_squared_error: 64.3405\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 454us/step - loss: 62.6463 - mean_squared_error: 62.6463 - val_loss: 71.5009 - val_mean_squared_error: 71.5009\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 455us/step - loss: 62.3274 - mean_squared_error: 62.3274 - val_loss: 63.6377 - val_mean_squared_error: 63.6377\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 62.4052 - mean_squared_error: 62.4052 - val_loss: 66.4795 - val_mean_squared_error: 66.4795\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 62.2189 - mean_squared_error: 62.2189 - val_loss: 63.6415 - val_mean_squared_error: 63.6415\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 62.0401 - mean_squared_error: 62.0401 - val_loss: 63.4752 - val_mean_squared_error: 63.4752\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.9486 - mean_squared_error: 61.9486 - val_loss: 63.1457 - val_mean_squared_error: 63.1457\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 61.6768 - mean_squared_error: 61.6768 - val_loss: 63.0797 - val_mean_squared_error: 63.0797\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 61.4685 - mean_squared_error: 61.4685 - val_loss: 64.1122 - val_mean_squared_error: 64.1123\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.5881 - mean_squared_error: 61.5881 - val_loss: 62.6265 - val_mean_squared_error: 62.6265\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 61.2584 - mean_squared_error: 61.2584 - val_loss: 62.4923 - val_mean_squared_error: 62.4923\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 60.9740 - mean_squared_error: 60.9741 - val_loss: 73.1958 - val_mean_squared_error: 73.1958\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 61.1692 - mean_squared_error: 61.1692 - val_loss: 62.6198 - val_mean_squared_error: 62.6199\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 60.9151 - mean_squared_error: 60.9151 - val_loss: 65.4276 - val_mean_squared_error: 65.4276\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 60.8276 - mean_squared_error: 60.8276 - val_loss: 62.1569 - val_mean_squared_error: 62.1569\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 60.6045 - mean_squared_error: 60.6045 - val_loss: 62.0463 - val_mean_squared_error: 62.0463\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 60.6654 - mean_squared_error: 60.6655 - val_loss: 72.4126 - val_mean_squared_error: 72.4126\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 60.5040 - mean_squared_error: 60.5040 - val_loss: 61.8642 - val_mean_squared_error: 61.8642\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 60.1683 - mean_squared_error: 60.1682 - val_loss: 62.8732 - val_mean_squared_error: 62.8732\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.1912 - mean_squared_error: 60.1912 - val_loss: 73.1962 - val_mean_squared_error: 73.1963\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.0376 - mean_squared_error: 60.0376 - val_loss: 61.8624 - val_mean_squared_error: 61.8624\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 60.0711 - mean_squared_error: 60.0711 - val_loss: 62.2332 - val_mean_squared_error: 62.2332\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 59.8324 - mean_squared_error: 59.8324 - val_loss: 62.0935 - val_mean_squared_error: 62.0935\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 59.7223 - mean_squared_error: 59.7223 - val_loss: 62.7405 - val_mean_squared_error: 62.7405\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 59.7571 - mean_squared_error: 59.7571 - val_loss: 67.5217 - val_mean_squared_error: 67.5217\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 59.4863 - mean_squared_error: 59.4863 - val_loss: 62.8816 - val_mean_squared_error: 62.8816\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 455us/step - loss: 59.5725 - mean_squared_error: 59.5725 - val_loss: 61.0926 - val_mean_squared_error: 61.0926\n",
      "Training Loss: [588.2167, 174.4953, 142.9551, 127.9245, 118.8503, 113.7548, 108.6824, 105.8325, 102.7294, 99.5854, 97.7639, 95.5804, 93.2074, 91.3585, 89.844, 88.2659, 87.0363, 85.9878, 84.1429, 83.4715, 82.4523, 81.0351, 80.1335, 79.3225, 78.3595, 78.0202, 77.2606, 76.1463, 75.2638, 75.145, 74.4085, 73.7345, 73.5482, 72.7744, 72.3925, 72.0303, 71.9247, 71.0226, 70.6724, 70.5253, 69.9095, 69.8968, 69.1608, 69.5053, 68.5007, 68.6904, 67.8978, 67.8627, 67.6914, 67.5899, 67.046, 67.0449, 66.6769, 66.391, 66.1154, 66.0704, 65.8455, 65.5243, 65.3264, 65.2366, 65.0769, 64.9513, 64.8165, 64.2012, 64.2988, 64.1128, 64.006, 63.6805, 63.4926, 63.5149, 63.0695, 63.2035, 62.871, 62.8484, 62.6463, 62.3274, 62.4052, 62.2189, 62.0401, 61.9486, 61.6768, 61.4685, 61.5881, 61.2584, 60.974, 61.1692, 60.9151, 60.8276, 60.6045, 60.6654, 60.504, 60.1683, 60.1912, 60.0376, 60.0711, 59.8324, 59.7223, 59.7571, 59.4863, 59.5725]\n",
      "Validation Loss: [213.8233, 157.7019, 135.2522, 131.9459, 115.7041, 117.7709, 105.8292, 102.9744, 104.105, 99.5885, 95.5731, 93.3357, 91.7771, 91.0266, 89.1324, 86.9343, 85.536, 84.3326, 83.2826, 84.3726, 81.1575, 80.8438, 86.1209, 79.7618, 78.0056, 77.0842, 77.057, 77.0401, 75.8544, 74.5886, 75.6767, 74.0007, 73.3065, 77.3131, 72.6493, 72.7462, 71.9561, 71.7946, 74.0891, 70.6884, 71.5539, 76.2672, 70.8838, 69.8471, 69.4017, 68.9173, 69.3147, 69.7935, 68.5406, 68.4372, 73.2336, 79.1729, 67.6436, 67.7382, 68.8601, 67.5735, 67.2957, 67.549, 66.7423, 68.2852, 66.2495, 65.9746, 66.1348, 66.306, 65.4059, 70.8624, 65.9768, 64.7131, 66.5154, 64.9516, 64.6586, 65.0573, 66.6021, 64.3405, 71.5009, 63.6377, 66.4795, 63.6415, 63.4752, 63.1457, 63.0797, 64.1122, 62.6265, 62.4923, 73.1958, 62.6198, 65.4276, 62.1569, 62.0463, 72.4126, 61.8642, 62.8732, 73.1962, 61.8624, 62.2332, 62.0935, 62.7405, 67.5217, 62.8816, 61.0926]\n",
      "\n",
      "We are now training cross-validation set # 4\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 540.5702 - mean_squared_error: 540.5706 - val_loss: 199.2250 - val_mean_squared_error: 199.2249\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 174.2816 - mean_squared_error: 174.2817 - val_loss: 155.8937 - val_mean_squared_error: 155.8937\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 138.4653 - mean_squared_error: 138.4653 - val_loss: 126.7576 - val_mean_squared_error: 126.7576\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 120.8785 - mean_squared_error: 120.8785 - val_loss: 118.3162 - val_mean_squared_error: 118.3162\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 113.7147 - mean_squared_error: 113.7147 - val_loss: 109.6808 - val_mean_squared_error: 109.6808\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 108.0037 - mean_squared_error: 108.0036 - val_loss: 105.7834 - val_mean_squared_error: 105.7834\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 104.6497 - mean_squared_error: 104.6497 - val_loss: 101.7400 - val_mean_squared_error: 101.7401\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 100.6275 - mean_squared_error: 100.6275 - val_loss: 98.8317 - val_mean_squared_error: 98.8317\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 98.2039 - mean_squared_error: 98.2039 - val_loss: 102.4668 - val_mean_squared_error: 102.4668\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 95.6368 - mean_squared_error: 95.6369 - val_loss: 97.6992 - val_mean_squared_error: 97.6992\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 93.7235 - mean_squared_error: 93.7235 - val_loss: 92.7259 - val_mean_squared_error: 92.7259\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 91.8294 - mean_squared_error: 91.8294 - val_loss: 90.7399 - val_mean_squared_error: 90.7399\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 90.0849 - mean_squared_error: 90.0849 - val_loss: 89.3888 - val_mean_squared_error: 89.3888\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 88.5907 - mean_squared_error: 88.5907 - val_loss: 90.2239 - val_mean_squared_error: 90.2239\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 87.2950 - mean_squared_error: 87.2950 - val_loss: 88.2596 - val_mean_squared_error: 88.2595\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 85.6375 - mean_squared_error: 85.6375 - val_loss: 85.0854 - val_mean_squared_error: 85.0853\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 84.5568 - mean_squared_error: 84.5568 - val_loss: 86.3127 - val_mean_squared_error: 86.3128\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 83.4820 - mean_squared_error: 83.4820 - val_loss: 86.8757 - val_mean_squared_error: 86.8757\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 82.9106 - mean_squared_error: 82.9105 - val_loss: 82.8685 - val_mean_squared_error: 82.8685\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 81.9383 - mean_squared_error: 81.9384 - val_loss: 91.9704 - val_mean_squared_error: 91.9704\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 80.5128 - mean_squared_error: 80.5127 - val_loss: 81.6572 - val_mean_squared_error: 81.6572\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 79.9384 - mean_squared_error: 79.9384 - val_loss: 79.6988 - val_mean_squared_error: 79.6988\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 79.1236 - mean_squared_error: 79.1237 - val_loss: 79.0834 - val_mean_squared_error: 79.0834\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 78.4849 - mean_squared_error: 78.4849 - val_loss: 80.0278 - val_mean_squared_error: 80.0278\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 77.5728 - mean_squared_error: 77.5728 - val_loss: 78.7738 - val_mean_squared_error: 78.7738\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 77.0189 - mean_squared_error: 77.0189 - val_loss: 89.6724 - val_mean_squared_error: 89.6724\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 76.2989 - mean_squared_error: 76.2989 - val_loss: 82.6581 - val_mean_squared_error: 82.6581\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 75.6683 - mean_squared_error: 75.6683 - val_loss: 75.8810 - val_mean_squared_error: 75.8810\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 75.0734 - mean_squared_error: 75.0734 - val_loss: 75.3977 - val_mean_squared_error: 75.3977\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 455us/step - loss: 74.7687 - mean_squared_error: 74.7687 - val_loss: 74.8016 - val_mean_squared_error: 74.8016\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 73.8493 - mean_squared_error: 73.8493 - val_loss: 74.0902 - val_mean_squared_error: 74.0902\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 73.4225 - mean_squared_error: 73.4225 - val_loss: 78.8701 - val_mean_squared_error: 78.8701\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 455us/step - loss: 72.8722 - mean_squared_error: 72.8722 - val_loss: 80.0636 - val_mean_squared_error: 80.0636\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 72.2557 - mean_squared_error: 72.2557 - val_loss: 75.2410 - val_mean_squared_error: 75.2410\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 72.1010 - mean_squared_error: 72.1010 - val_loss: 73.0489 - val_mean_squared_error: 73.0489\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 71.4917 - mean_squared_error: 71.4917 - val_loss: 72.0847 - val_mean_squared_error: 72.0847\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 71.0869 - mean_squared_error: 71.0869 - val_loss: 71.9476 - val_mean_squared_error: 71.9476\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 70.8548 - mean_squared_error: 70.8548 - val_loss: 72.7443 - val_mean_squared_error: 72.7443\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 70.3191 - mean_squared_error: 70.3191 - val_loss: 71.1929 - val_mean_squared_error: 71.1929\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 457us/step - loss: 69.8223 - mean_squared_error: 69.8224 - val_loss: 71.2435 - val_mean_squared_error: 71.2434\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 69.5763 - mean_squared_error: 69.5763 - val_loss: 70.7795 - val_mean_squared_error: 70.7795\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 69.1254 - mean_squared_error: 69.1254 - val_loss: 70.7294 - val_mean_squared_error: 70.7294\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 68.9587 - mean_squared_error: 68.9587 - val_loss: 69.8450 - val_mean_squared_error: 69.8450\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 463us/step - loss: 68.7916 - mean_squared_error: 68.7916 - val_loss: 75.3897 - val_mean_squared_error: 75.3897\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 68.1282 - mean_squared_error: 68.1282 - val_loss: 69.9222 - val_mean_squared_error: 69.9222\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 68.0804 - mean_squared_error: 68.0804 - val_loss: 69.3338 - val_mean_squared_error: 69.3338\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 67.8163 - mean_squared_error: 67.8163 - val_loss: 79.1562 - val_mean_squared_error: 79.1562\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 67.6689 - mean_squared_error: 67.6689 - val_loss: 68.7710 - val_mean_squared_error: 68.7710\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 67.1634 - mean_squared_error: 67.1634 - val_loss: 69.4893 - val_mean_squared_error: 69.4893\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 66.8826 - mean_squared_error: 66.8826 - val_loss: 68.2380 - val_mean_squared_error: 68.2380\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 66.6946 - mean_squared_error: 66.6946 - val_loss: 68.3692 - val_mean_squared_error: 68.3692\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 66.6037 - mean_squared_error: 66.6038 - val_loss: 68.5181 - val_mean_squared_error: 68.5181\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 66.3831 - mean_squared_error: 66.3831 - val_loss: 68.4605 - val_mean_squared_error: 68.4605\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 66.3042 - mean_squared_error: 66.3042 - val_loss: 67.2624 - val_mean_squared_error: 67.2624\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 65.6769 - mean_squared_error: 65.6769 - val_loss: 66.8858 - val_mean_squared_error: 66.8858\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 65.7752 - mean_squared_error: 65.7752 - val_loss: 68.3191 - val_mean_squared_error: 68.3191\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 65.4748 - mean_squared_error: 65.4749 - val_loss: 67.5726 - val_mean_squared_error: 67.5726\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 65.3370 - mean_squared_error: 65.3370 - val_loss: 69.4768 - val_mean_squared_error: 69.4768\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 65.0914 - mean_squared_error: 65.0914 - val_loss: 68.2416 - val_mean_squared_error: 68.2416\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 64.8670 - mean_squared_error: 64.8669 - val_loss: 66.7353 - val_mean_squared_error: 66.7353\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 64.8538 - mean_squared_error: 64.8538 - val_loss: 66.2698 - val_mean_squared_error: 66.2698\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 64.6355 - mean_squared_error: 64.6354 - val_loss: 66.4224 - val_mean_squared_error: 66.4224\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.3009 - mean_squared_error: 64.3009 - val_loss: 66.8516 - val_mean_squared_error: 66.8517\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 64.4900 - mean_squared_error: 64.4900 - val_loss: 65.6797 - val_mean_squared_error: 65.6797\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 64.0585 - mean_squared_error: 64.0585 - val_loss: 67.9044 - val_mean_squared_error: 67.9044\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 63.8717 - mean_squared_error: 63.8717 - val_loss: 65.9555 - val_mean_squared_error: 65.9555\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 63.8811 - mean_squared_error: 63.8811 - val_loss: 69.0808 - val_mean_squared_error: 69.0808\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.6911 - mean_squared_error: 63.6911 - val_loss: 65.6962 - val_mean_squared_error: 65.6962\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 63.5232 - mean_squared_error: 63.5232 - val_loss: 65.4768 - val_mean_squared_error: 65.4768\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 63.3127 - mean_squared_error: 63.3128 - val_loss: 65.7431 - val_mean_squared_error: 65.7431\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 63.2621 - mean_squared_error: 63.2621 - val_loss: 66.2331 - val_mean_squared_error: 66.2331\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 63.2528 - mean_squared_error: 63.2528 - val_loss: 64.8986 - val_mean_squared_error: 64.8986\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 62.8300 - mean_squared_error: 62.8300 - val_loss: 71.0244 - val_mean_squared_error: 71.0244\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.8900 - mean_squared_error: 62.8900 - val_loss: 65.1990 - val_mean_squared_error: 65.1990\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 62.8537 - mean_squared_error: 62.8537 - val_loss: 67.8466 - val_mean_squared_error: 67.8466\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 62.5381 - mean_squared_error: 62.5381 - val_loss: 64.4092 - val_mean_squared_error: 64.4092\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.4586 - mean_squared_error: 62.4586 - val_loss: 64.1210 - val_mean_squared_error: 64.1209\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.4213 - mean_squared_error: 62.4213 - val_loss: 65.8907 - val_mean_squared_error: 65.8907\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 62.2652 - mean_squared_error: 62.2652 - val_loss: 65.1033 - val_mean_squared_error: 65.1033\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 62.1635 - mean_squared_error: 62.1636 - val_loss: 65.0306 - val_mean_squared_error: 65.0306\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 62.0499 - mean_squared_error: 62.0499 - val_loss: 64.8357 - val_mean_squared_error: 64.8357\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.0447 - mean_squared_error: 62.0447 - val_loss: 63.6552 - val_mean_squared_error: 63.6552\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 61.7563 - mean_squared_error: 61.7563 - val_loss: 65.3450 - val_mean_squared_error: 65.3450\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.9239 - mean_squared_error: 61.9239 - val_loss: 66.0331 - val_mean_squared_error: 66.0331\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.5474 - mean_squared_error: 61.5474 - val_loss: 63.4378 - val_mean_squared_error: 63.4378\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.5298 - mean_squared_error: 61.5299 - val_loss: 64.0455 - val_mean_squared_error: 64.0455\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.4658 - mean_squared_error: 61.4659 - val_loss: 63.5691 - val_mean_squared_error: 63.5691\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.2624 - mean_squared_error: 61.2624 - val_loss: 63.4887 - val_mean_squared_error: 63.4886\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 61.1306 - mean_squared_error: 61.1306 - val_loss: 63.7257 - val_mean_squared_error: 63.7257\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.2424 - mean_squared_error: 61.2424 - val_loss: 66.5341 - val_mean_squared_error: 66.5341\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.7921 - mean_squared_error: 60.7922 - val_loss: 62.9572 - val_mean_squared_error: 62.9572\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 60.9014 - mean_squared_error: 60.9014 - val_loss: 62.9163 - val_mean_squared_error: 62.9163\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.8993 - mean_squared_error: 60.8994 - val_loss: 62.8740 - val_mean_squared_error: 62.8740\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.4785 - mean_squared_error: 60.4785 - val_loss: 63.5451 - val_mean_squared_error: 63.5451\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 60.7711 - mean_squared_error: 60.7711 - val_loss: 62.5921 - val_mean_squared_error: 62.5921\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 60.2140 - mean_squared_error: 60.2140 - val_loss: 62.3737 - val_mean_squared_error: 62.3737\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.3232 - mean_squared_error: 60.3232 - val_loss: 62.4952 - val_mean_squared_error: 62.4952\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 60.3641 - mean_squared_error: 60.3641 - val_loss: 66.5264 - val_mean_squared_error: 66.5264\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.1430 - mean_squared_error: 60.1430 - val_loss: 63.2889 - val_mean_squared_error: 63.2888\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.9347 - mean_squared_error: 59.9347 - val_loss: 62.9915 - val_mean_squared_error: 62.9915\n",
      "Training Loss: [540.5702, 174.2816, 138.4653, 120.8785, 113.7147, 108.0037, 104.6497, 100.6275, 98.2039, 95.6368, 93.7235, 91.8294, 90.0849, 88.5907, 87.295, 85.6375, 84.5568, 83.482, 82.9106, 81.9383, 80.5128, 79.9384, 79.1236, 78.4849, 77.5728, 77.0189, 76.2989, 75.6683, 75.0734, 74.7687, 73.8493, 73.4225, 72.8722, 72.2557, 72.101, 71.4917, 71.0869, 70.8548, 70.3191, 69.8223, 69.5763, 69.1254, 68.9587, 68.7916, 68.1282, 68.0804, 67.8163, 67.6689, 67.1634, 66.8826, 66.6946, 66.6037, 66.3831, 66.3042, 65.6769, 65.7752, 65.4748, 65.337, 65.0914, 64.867, 64.8538, 64.6355, 64.3009, 64.49, 64.0585, 63.8717, 63.8811, 63.6911, 63.5232, 63.3127, 63.2621, 63.2528, 62.83, 62.89, 62.8537, 62.5381, 62.4586, 62.4213, 62.2652, 62.1635, 62.0499, 62.0447, 61.7563, 61.9239, 61.5474, 61.5298, 61.4658, 61.2624, 61.1306, 61.2424, 60.7921, 60.9014, 60.8993, 60.4785, 60.7711, 60.214, 60.3232, 60.3641, 60.143, 59.9347]\n",
      "Validation Loss: [199.225, 155.8937, 126.7576, 118.3162, 109.6808, 105.7834, 101.74, 98.8317, 102.4668, 97.6992, 92.7259, 90.7399, 89.3888, 90.2239, 88.2596, 85.0854, 86.3127, 86.8757, 82.8685, 91.9704, 81.6572, 79.6988, 79.0834, 80.0278, 78.7738, 89.6724, 82.6581, 75.881, 75.3977, 74.8016, 74.0902, 78.8701, 80.0636, 75.241, 73.0489, 72.0847, 71.9476, 72.7443, 71.1929, 71.2435, 70.7795, 70.7294, 69.845, 75.3897, 69.9222, 69.3338, 79.1562, 68.771, 69.4893, 68.238, 68.3692, 68.5181, 68.4605, 67.2624, 66.8858, 68.3191, 67.5726, 69.4768, 68.2416, 66.7353, 66.2698, 66.4224, 66.8516, 65.6797, 67.9044, 65.9555, 69.0808, 65.6962, 65.4768, 65.7431, 66.2331, 64.8986, 71.0244, 65.199, 67.8466, 64.4092, 64.121, 65.8907, 65.1033, 65.0306, 64.8357, 63.6552, 65.345, 66.0331, 63.4378, 64.0455, 63.5691, 63.4887, 63.7257, 66.5341, 62.9572, 62.9163, 62.874, 63.5451, 62.5921, 62.3737, 62.4952, 66.5264, 63.2889, 62.9915]\n",
      "\n",
      "We are now training cross-validation set # 5\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 550.5831 - mean_squared_error: 550.5834 - val_loss: 198.4098 - val_mean_squared_error: 198.4098\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 165.4151 - mean_squared_error: 165.4152 - val_loss: 148.6956 - val_mean_squared_error: 148.6956\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 139.5014 - mean_squared_error: 139.5013 - val_loss: 130.4552 - val_mean_squared_error: 130.4552\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 125.9576 - mean_squared_error: 125.9576 - val_loss: 120.6610 - val_mean_squared_error: 120.6609\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 117.4659 - mean_squared_error: 117.4660 - val_loss: 115.9997 - val_mean_squared_error: 115.9997\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 112.5672 - mean_squared_error: 112.5672 - val_loss: 112.1207 - val_mean_squared_error: 112.1207\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 108.9279 - mean_squared_error: 108.9279 - val_loss: 106.3674 - val_mean_squared_error: 106.3673\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 105.7429 - mean_squared_error: 105.7429 - val_loss: 105.0455 - val_mean_squared_error: 105.0455\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 103.6403 - mean_squared_error: 103.6403 - val_loss: 103.2112 - val_mean_squared_error: 103.2112\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 100.5568 - mean_squared_error: 100.5569 - val_loss: 99.6216 - val_mean_squared_error: 99.6216\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 98.7655 - mean_squared_error: 98.7655 - val_loss: 97.1785 - val_mean_squared_error: 97.1785\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 96.8534 - mean_squared_error: 96.8534 - val_loss: 97.1378 - val_mean_squared_error: 97.1378\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 94.6557 - mean_squared_error: 94.6558 - val_loss: 93.2554 - val_mean_squared_error: 93.2555\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 93.6261 - mean_squared_error: 93.6262 - val_loss: 93.8974 - val_mean_squared_error: 93.8974\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 91.4411 - mean_squared_error: 91.4411 - val_loss: 90.4034 - val_mean_squared_error: 90.4034\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 90.0170 - mean_squared_error: 90.0170 - val_loss: 89.2755 - val_mean_squared_error: 89.2755\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 88.9480 - mean_squared_error: 88.9480 - val_loss: 88.2095 - val_mean_squared_error: 88.2095\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 87.6580 - mean_squared_error: 87.6580 - val_loss: 93.4679 - val_mean_squared_error: 93.4679\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 86.6953 - mean_squared_error: 86.6953 - val_loss: 86.6920 - val_mean_squared_error: 86.6920\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 85.3366 - mean_squared_error: 85.3366 - val_loss: 84.7401 - val_mean_squared_error: 84.7401\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 84.4122 - mean_squared_error: 84.4122 - val_loss: 83.9403 - val_mean_squared_error: 83.9403\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 83.5219 - mean_squared_error: 83.5219 - val_loss: 83.1320 - val_mean_squared_error: 83.1320\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 82.1357 - mean_squared_error: 82.1357 - val_loss: 82.4585 - val_mean_squared_error: 82.4585\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 81.4812 - mean_squared_error: 81.4812 - val_loss: 83.9536 - val_mean_squared_error: 83.9536\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 80.7325 - mean_squared_error: 80.7325 - val_loss: 80.6900 - val_mean_squared_error: 80.6900\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 79.6611 - mean_squared_error: 79.6611 - val_loss: 79.9504 - val_mean_squared_error: 79.9504\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 79.0632 - mean_squared_error: 79.0633 - val_loss: 96.1212 - val_mean_squared_error: 96.1212\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 78.2202 - mean_squared_error: 78.2202 - val_loss: 80.4459 - val_mean_squared_error: 80.4459\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 77.5860 - mean_squared_error: 77.5860 - val_loss: 77.5486 - val_mean_squared_error: 77.5486\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 76.7288 - mean_squared_error: 76.7288 - val_loss: 91.3546 - val_mean_squared_error: 91.3546\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 76.1174 - mean_squared_error: 76.1173 - val_loss: 76.9194 - val_mean_squared_error: 76.9193\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 75.5056 - mean_squared_error: 75.5056 - val_loss: 80.1351 - val_mean_squared_error: 80.1351\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 74.7688 - mean_squared_error: 74.7688 - val_loss: 75.3722 - val_mean_squared_error: 75.3722\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 74.5192 - mean_squared_error: 74.5192 - val_loss: 75.1581 - val_mean_squared_error: 75.1581\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 73.5984 - mean_squared_error: 73.5984 - val_loss: 74.9715 - val_mean_squared_error: 74.9715\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 73.3610 - mean_squared_error: 73.3610 - val_loss: 73.7299 - val_mean_squared_error: 73.7299\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 476us/step - loss: 72.5158 - mean_squared_error: 72.5158 - val_loss: 75.7796 - val_mean_squared_error: 75.7796\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 72.4042 - mean_squared_error: 72.4042 - val_loss: 72.9218 - val_mean_squared_error: 72.9218\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 71.7744 - mean_squared_error: 71.7745 - val_loss: 75.3452 - val_mean_squared_error: 75.3452\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 71.6971 - mean_squared_error: 71.6971 - val_loss: 71.9094 - val_mean_squared_error: 71.9094\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 70.8896 - mean_squared_error: 70.8896 - val_loss: 73.9861 - val_mean_squared_error: 73.9861\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 70.6230 - mean_squared_error: 70.6230 - val_loss: 81.4345 - val_mean_squared_error: 81.4345\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 70.3697 - mean_squared_error: 70.3697 - val_loss: 70.9062 - val_mean_squared_error: 70.9062\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.9226 - mean_squared_error: 69.9226 - val_loss: 71.5515 - val_mean_squared_error: 71.5515\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.4862 - mean_squared_error: 69.4862 - val_loss: 70.3591 - val_mean_squared_error: 70.3591\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.2514 - mean_squared_error: 69.2514 - val_loss: 72.1400 - val_mean_squared_error: 72.1400\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 68.8103 - mean_squared_error: 68.8103 - val_loss: 69.8049 - val_mean_squared_error: 69.8049\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 68.4790 - mean_squared_error: 68.4790 - val_loss: 73.2053 - val_mean_squared_error: 73.2053\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 68.2607 - mean_squared_error: 68.2607 - val_loss: 69.1232 - val_mean_squared_error: 69.1232\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 67.9559 - mean_squared_error: 67.9559 - val_loss: 69.8467 - val_mean_squared_error: 69.8467\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 67.8321 - mean_squared_error: 67.8321 - val_loss: 68.4957 - val_mean_squared_error: 68.4957\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 67.2049 - mean_squared_error: 67.2049 - val_loss: 70.7690 - val_mean_squared_error: 70.7691\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 67.0709 - mean_squared_error: 67.0710 - val_loss: 70.1380 - val_mean_squared_error: 70.1380\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 66.9751 - mean_squared_error: 66.9751 - val_loss: 68.1600 - val_mean_squared_error: 68.1600\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 66.2467 - mean_squared_error: 66.2468 - val_loss: 67.5931 - val_mean_squared_error: 67.5930\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 66.6271 - mean_squared_error: 66.6271 - val_loss: 67.2601 - val_mean_squared_error: 67.2601\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 65.8474 - mean_squared_error: 65.8474 - val_loss: 69.4606 - val_mean_squared_error: 69.4606\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 65.5588 - mean_squared_error: 65.5588 - val_loss: 66.9787 - val_mean_squared_error: 66.9787\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 65.6097 - mean_squared_error: 65.6098 - val_loss: 67.0383 - val_mean_squared_error: 67.0383\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 65.1994 - mean_squared_error: 65.1994 - val_loss: 66.8411 - val_mean_squared_error: 66.8411\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 65.0452 - mean_squared_error: 65.0451 - val_loss: 66.4420 - val_mean_squared_error: 66.4420\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 64.8106 - mean_squared_error: 64.8106 - val_loss: 66.0264 - val_mean_squared_error: 66.0264\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.6248 - mean_squared_error: 64.6248 - val_loss: 66.2502 - val_mean_squared_error: 66.2502\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.3447 - mean_squared_error: 64.3447 - val_loss: 66.7116 - val_mean_squared_error: 66.7116\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.9574 - mean_squared_error: 63.9573 - val_loss: 66.3269 - val_mean_squared_error: 66.3269\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 64.1362 - mean_squared_error: 64.1361 - val_loss: 65.0640 - val_mean_squared_error: 65.0640\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 64.3385 - mean_squared_error: 64.3385 - val_loss: 64.9555 - val_mean_squared_error: 64.9555\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.8801 - mean_squared_error: 62.8801 - val_loss: 70.0698 - val_mean_squared_error: 70.0698\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.2504 - mean_squared_error: 63.2505 - val_loss: 64.6159 - val_mean_squared_error: 64.6159\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 63.1292 - mean_squared_error: 63.1292 - val_loss: 67.2066 - val_mean_squared_error: 67.2067\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.9716 - mean_squared_error: 62.9716 - val_loss: 64.2851 - val_mean_squared_error: 64.2851\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.6075 - mean_squared_error: 62.6075 - val_loss: 64.2851 - val_mean_squared_error: 64.2851\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.5098 - mean_squared_error: 62.5098 - val_loss: 64.3350 - val_mean_squared_error: 64.3350\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 62.4052 - mean_squared_error: 62.4052 - val_loss: 64.2779 - val_mean_squared_error: 64.2779\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.0786 - mean_squared_error: 62.0786 - val_loss: 63.5224 - val_mean_squared_error: 63.5224\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.9309 - mean_squared_error: 61.9309 - val_loss: 63.4025 - val_mean_squared_error: 63.4025\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 61.7451 - mean_squared_error: 61.7451 - val_loss: 63.5564 - val_mean_squared_error: 63.5563\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 62.0234 - mean_squared_error: 62.0234 - val_loss: 63.4641 - val_mean_squared_error: 63.4641\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.1919 - mean_squared_error: 61.1919 - val_loss: 63.6635 - val_mean_squared_error: 63.6635\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 61.3046 - mean_squared_error: 61.3046 - val_loss: 63.1804 - val_mean_squared_error: 63.1804\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.2594 - mean_squared_error: 61.2593 - val_loss: 62.5552 - val_mean_squared_error: 62.5552\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 60.7527 - mean_squared_error: 60.7527 - val_loss: 62.9990 - val_mean_squared_error: 62.9990\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.7896 - mean_squared_error: 60.7895 - val_loss: 63.7718 - val_mean_squared_error: 63.7718\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 60.6705 - mean_squared_error: 60.6706 - val_loss: 63.0437 - val_mean_squared_error: 63.0437\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 60.7288 - mean_squared_error: 60.7288 - val_loss: 62.0281 - val_mean_squared_error: 62.0281\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 60.2803 - mean_squared_error: 60.2803 - val_loss: 62.5458 - val_mean_squared_error: 62.5457\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 60.4940 - mean_squared_error: 60.4940 - val_loss: 61.7229 - val_mean_squared_error: 61.7229\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 59.8491 - mean_squared_error: 59.8491 - val_loss: 61.9209 - val_mean_squared_error: 61.9209\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 59.8767 - mean_squared_error: 59.8767 - val_loss: 61.3168 - val_mean_squared_error: 61.3168\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 59.8149 - mean_squared_error: 59.8149 - val_loss: 61.3438 - val_mean_squared_error: 61.3438\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.5946 - mean_squared_error: 59.5945 - val_loss: 61.7409 - val_mean_squared_error: 61.7409\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 59.5803 - mean_squared_error: 59.5803 - val_loss: 71.5435 - val_mean_squared_error: 71.5435\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 59.3866 - mean_squared_error: 59.3866 - val_loss: 61.3920 - val_mean_squared_error: 61.3920\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 59.4948 - mean_squared_error: 59.4948 - val_loss: 61.0803 - val_mean_squared_error: 61.0803\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 58.9006 - mean_squared_error: 58.9006 - val_loss: 63.1814 - val_mean_squared_error: 63.1814\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 59.0161 - mean_squared_error: 59.0161 - val_loss: 60.8089 - val_mean_squared_error: 60.8089\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 59.1129 - mean_squared_error: 59.1129 - val_loss: 61.2831 - val_mean_squared_error: 61.2830\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 58.7876 - mean_squared_error: 58.7876 - val_loss: 60.6297 - val_mean_squared_error: 60.6297\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 58.6014 - mean_squared_error: 58.6014 - val_loss: 61.1886 - val_mean_squared_error: 61.1886\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 58.5227 - mean_squared_error: 58.5227 - val_loss: 60.8114 - val_mean_squared_error: 60.8114\n",
      "Training Loss: [550.5831, 165.4151, 139.5014, 125.9576, 117.4659, 112.5672, 108.9279, 105.7429, 103.6403, 100.5568, 98.7655, 96.8534, 94.6557, 93.6261, 91.4411, 90.017, 88.948, 87.658, 86.6953, 85.3366, 84.4122, 83.5219, 82.1357, 81.4812, 80.7325, 79.6611, 79.0632, 78.2202, 77.586, 76.7288, 76.1174, 75.5056, 74.7688, 74.5192, 73.5984, 73.361, 72.5158, 72.4042, 71.7744, 71.6971, 70.8896, 70.623, 70.3697, 69.9226, 69.4862, 69.2514, 68.8103, 68.479, 68.2607, 67.9559, 67.8321, 67.2049, 67.0709, 66.9751, 66.2467, 66.6271, 65.8474, 65.5588, 65.6097, 65.1994, 65.0452, 64.8106, 64.6248, 64.3447, 63.9574, 64.1362, 64.3385, 62.8801, 63.2504, 63.1292, 62.9716, 62.6075, 62.5098, 62.4052, 62.0786, 61.9309, 61.7451, 62.0234, 61.1919, 61.3046, 61.2594, 60.7527, 60.7896, 60.6705, 60.7288, 60.2803, 60.494, 59.8491, 59.8767, 59.8149, 59.5946, 59.5803, 59.3866, 59.4948, 58.9006, 59.0161, 59.1129, 58.7876, 58.6014, 58.5227]\n",
      "Validation Loss: [198.4098, 148.6956, 130.4552, 120.661, 115.9997, 112.1207, 106.3674, 105.0455, 103.2112, 99.6216, 97.1785, 97.1378, 93.2554, 93.8974, 90.4034, 89.2755, 88.2095, 93.4679, 86.692, 84.7401, 83.9403, 83.132, 82.4585, 83.9536, 80.69, 79.9504, 96.1212, 80.4459, 77.5486, 91.3546, 76.9194, 80.1351, 75.3722, 75.1581, 74.9715, 73.7299, 75.7796, 72.9218, 75.3452, 71.9094, 73.9861, 81.4345, 70.9062, 71.5515, 70.3591, 72.14, 69.8049, 73.2053, 69.1232, 69.8467, 68.4957, 70.769, 70.138, 68.16, 67.5931, 67.2601, 69.4606, 66.9787, 67.0383, 66.8411, 66.442, 66.0264, 66.2502, 66.7116, 66.3269, 65.064, 64.9555, 70.0698, 64.6159, 67.2066, 64.2851, 64.2851, 64.335, 64.2779, 63.5224, 63.4025, 63.5564, 63.4641, 63.6635, 63.1804, 62.5552, 62.999, 63.7718, 63.0437, 62.0281, 62.5458, 61.7229, 61.9209, 61.3168, 61.3438, 61.7409, 71.5435, 61.392, 61.0803, 63.1814, 60.8089, 61.2831, 60.6297, 61.1886, 60.8114]\n",
      "\n",
      "We are now training cross-validation set # 1\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 500us/step - loss: 575.5653 - mean_squared_error: 575.5656 - val_loss: 190.1341 - val_mean_squared_error: 190.1341\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 476us/step - loss: 155.6157 - mean_squared_error: 155.6158 - val_loss: 135.9927 - val_mean_squared_error: 135.9927\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 127.0758 - mean_squared_error: 127.0758 - val_loss: 122.5892 - val_mean_squared_error: 122.5892\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 116.0799 - mean_squared_error: 116.0799 - val_loss: 113.2500 - val_mean_squared_error: 113.2501\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 109.3738 - mean_squared_error: 109.3738 - val_loss: 108.9866 - val_mean_squared_error: 108.9866\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 104.7722 - mean_squared_error: 104.7722 - val_loss: 101.7331 - val_mean_squared_error: 101.7331\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 100.9249 - mean_squared_error: 100.9249 - val_loss: 99.2143 - val_mean_squared_error: 99.2143\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 491us/step - loss: 97.6382 - mean_squared_error: 97.6381 - val_loss: 94.8230 - val_mean_squared_error: 94.8230\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 94.6873 - mean_squared_error: 94.6873 - val_loss: 97.3894 - val_mean_squared_error: 97.3894\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 92.0867 - mean_squared_error: 92.0867 - val_loss: 101.0254 - val_mean_squared_error: 101.0254\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 89.6190 - mean_squared_error: 89.6190 - val_loss: 89.2116 - val_mean_squared_error: 89.2116\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 87.0631 - mean_squared_error: 87.0631 - val_loss: 87.1132 - val_mean_squared_error: 87.1132\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 85.1508 - mean_squared_error: 85.1507 - val_loss: 83.9644 - val_mean_squared_error: 83.9645\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 83.3251 - mean_squared_error: 83.3251 - val_loss: 82.6612 - val_mean_squared_error: 82.6612\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 81.5126 - mean_squared_error: 81.5126 - val_loss: 80.8155 - val_mean_squared_error: 80.8155\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 79.8653 - mean_squared_error: 79.8653 - val_loss: 86.1681 - val_mean_squared_error: 86.1681\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 78.4025 - mean_squared_error: 78.4025 - val_loss: 79.8839 - val_mean_squared_error: 79.8839\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 77.1085 - mean_squared_error: 77.1085 - val_loss: 78.5756 - val_mean_squared_error: 78.5756\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 75.5930 - mean_squared_error: 75.5931 - val_loss: 79.9970 - val_mean_squared_error: 79.9970\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 74.5937 - mean_squared_error: 74.5936 - val_loss: 74.7881 - val_mean_squared_error: 74.7881\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 73.5773 - mean_squared_error: 73.5773 - val_loss: 73.6557 - val_mean_squared_error: 73.6557\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 72.9911 - mean_squared_error: 72.9911 - val_loss: 72.2517 - val_mean_squared_error: 72.2517\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 71.8527 - mean_squared_error: 71.8526 - val_loss: 71.4138 - val_mean_squared_error: 71.4138\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 71.2025 - mean_squared_error: 71.2024 - val_loss: 70.9570 - val_mean_squared_error: 70.9570\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 70.1807 - mean_squared_error: 70.1808 - val_loss: 70.3467 - val_mean_squared_error: 70.3467\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.5242 - mean_squared_error: 69.5242 - val_loss: 69.5002 - val_mean_squared_error: 69.5002\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 68.9617 - mean_squared_error: 68.9617 - val_loss: 69.9560 - val_mean_squared_error: 69.9560\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 68.1190 - mean_squared_error: 68.1190 - val_loss: 69.2563 - val_mean_squared_error: 69.2563\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 67.7450 - mean_squared_error: 67.7450 - val_loss: 68.4738 - val_mean_squared_error: 68.4738\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 11s 488us/step - loss: 66.8162 - mean_squared_error: 66.8162 - val_loss: 67.6984 - val_mean_squared_error: 67.6984\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 66.2647 - mean_squared_error: 66.2648 - val_loss: 67.4384 - val_mean_squared_error: 67.4384\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 65.9009 - mean_squared_error: 65.9009 - val_loss: 68.4749 - val_mean_squared_error: 68.4749\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 65.3635 - mean_squared_error: 65.3635 - val_loss: 65.7852 - val_mean_squared_error: 65.7851\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 65.1611 - mean_squared_error: 65.1611 - val_loss: 65.3268 - val_mean_squared_error: 65.3267\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 64.2267 - mean_squared_error: 64.2268 - val_loss: 64.5399 - val_mean_squared_error: 64.5399\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 64.0678 - mean_squared_error: 64.0679 - val_loss: 67.2230 - val_mean_squared_error: 67.2230\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 63.8696 - mean_squared_error: 63.8696 - val_loss: 64.1862 - val_mean_squared_error: 64.1862\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 62.8146 - mean_squared_error: 62.8146 - val_loss: 64.0931 - val_mean_squared_error: 64.0931\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 62.8245 - mean_squared_error: 62.8246 - val_loss: 64.1821 - val_mean_squared_error: 64.1821\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 62.5208 - mean_squared_error: 62.5207 - val_loss: 66.4395 - val_mean_squared_error: 66.4395\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 62.0554 - mean_squared_error: 62.0554 - val_loss: 63.4022 - val_mean_squared_error: 63.4022\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.7693 - mean_squared_error: 61.7693 - val_loss: 63.3441 - val_mean_squared_error: 63.3440\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 61.3726 - mean_squared_error: 61.3726 - val_loss: 65.1855 - val_mean_squared_error: 65.1855\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 61.3963 - mean_squared_error: 61.3963 - val_loss: 62.2170 - val_mean_squared_error: 62.2170\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.7262 - mean_squared_error: 60.7262 - val_loss: 63.3918 - val_mean_squared_error: 63.3918\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 60.5821 - mean_squared_error: 60.5821 - val_loss: 66.8402 - val_mean_squared_error: 66.8402\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.3397 - mean_squared_error: 60.3397 - val_loss: 61.8145 - val_mean_squared_error: 61.8145\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 60.0576 - mean_squared_error: 60.0576 - val_loss: 61.1793 - val_mean_squared_error: 61.1793\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.8135 - mean_squared_error: 59.8135 - val_loss: 60.8487 - val_mean_squared_error: 60.8487\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 59.4619 - mean_squared_error: 59.4619 - val_loss: 62.6033 - val_mean_squared_error: 62.6032\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 11s 501us/step - loss: 59.6730 - mean_squared_error: 59.6729 - val_loss: 60.7959 - val_mean_squared_error: 60.7959\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 58.9527 - mean_squared_error: 58.9528 - val_loss: 63.0647 - val_mean_squared_error: 63.0647\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 58.7648 - mean_squared_error: 58.7648 - val_loss: 61.3406 - val_mean_squared_error: 61.3406\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 58.7562 - mean_squared_error: 58.7563 - val_loss: 60.3305 - val_mean_squared_error: 60.3305\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 58.2335 - mean_squared_error: 58.2335 - val_loss: 60.9897 - val_mean_squared_error: 60.9897\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 58.4320 - mean_squared_error: 58.4320 - val_loss: 62.0537 - val_mean_squared_error: 62.0537\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 58.0552 - mean_squared_error: 58.0552 - val_loss: 60.3872 - val_mean_squared_error: 60.3872\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 57.8312 - mean_squared_error: 57.8312 - val_loss: 59.2659 - val_mean_squared_error: 59.2659\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 57.6558 - mean_squared_error: 57.6558 - val_loss: 59.0121 - val_mean_squared_error: 59.0121\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 57.3708 - mean_squared_error: 57.3707 - val_loss: 61.0823 - val_mean_squared_error: 61.0823\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 57.2274 - mean_squared_error: 57.2274 - val_loss: 58.3754 - val_mean_squared_error: 58.3754\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 57.0303 - mean_squared_error: 57.0302 - val_loss: 58.1825 - val_mean_squared_error: 58.1825\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 56.8441 - mean_squared_error: 56.8441 - val_loss: 59.9847 - val_mean_squared_error: 59.9847\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 56.7630 - mean_squared_error: 56.7630 - val_loss: 59.9590 - val_mean_squared_error: 59.9591\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 11s 494us/step - loss: 56.5934 - mean_squared_error: 56.5934 - val_loss: 60.9700 - val_mean_squared_error: 60.9700\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 56.2266 - mean_squared_error: 56.2266 - val_loss: 57.4863 - val_mean_squared_error: 57.4863\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 56.2881 - mean_squared_error: 56.2881 - val_loss: 57.8243 - val_mean_squared_error: 57.8243\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 55.9793 - mean_squared_error: 55.9793 - val_loss: 58.7798 - val_mean_squared_error: 58.7798\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 56.0742 - mean_squared_error: 56.0742 - val_loss: 57.2642 - val_mean_squared_error: 57.2642\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.5180 - mean_squared_error: 55.5180 - val_loss: 58.0462 - val_mean_squared_error: 58.0462\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 55.7922 - mean_squared_error: 55.7923 - val_loss: 57.2092 - val_mean_squared_error: 57.2092\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 55.1706 - mean_squared_error: 55.1706 - val_loss: 58.7323 - val_mean_squared_error: 58.7323\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 55.2611 - mean_squared_error: 55.2611 - val_loss: 60.6006 - val_mean_squared_error: 60.6005\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 55.3630 - mean_squared_error: 55.3631 - val_loss: 57.0998 - val_mean_squared_error: 57.0998\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 55.0625 - mean_squared_error: 55.0625 - val_loss: 56.7256 - val_mean_squared_error: 56.7256\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.0017 - mean_squared_error: 55.0017 - val_loss: 62.5368 - val_mean_squared_error: 62.5368\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.6718 - mean_squared_error: 54.6718 - val_loss: 56.1610 - val_mean_squared_error: 56.1610\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.5485 - mean_squared_error: 54.5485 - val_loss: 57.2577 - val_mean_squared_error: 57.2577\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.5084 - mean_squared_error: 54.5084 - val_loss: 59.1277 - val_mean_squared_error: 59.1277\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 54.4049 - mean_squared_error: 54.4049 - val_loss: 56.3844 - val_mean_squared_error: 56.3843\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 54.2238 - mean_squared_error: 54.2238 - val_loss: 55.7644 - val_mean_squared_error: 55.7644\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 54.2963 - mean_squared_error: 54.2963 - val_loss: 55.7896 - val_mean_squared_error: 55.7896\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.8614 - mean_squared_error: 53.8614 - val_loss: 56.1799 - val_mean_squared_error: 56.1799\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.0339 - mean_squared_error: 54.0339 - val_loss: 56.1427 - val_mean_squared_error: 56.1427\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.8108 - mean_squared_error: 53.8108 - val_loss: 55.4877 - val_mean_squared_error: 55.4877\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.7219 - mean_squared_error: 53.7219 - val_loss: 55.3001 - val_mean_squared_error: 55.3001\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 53.5450 - mean_squared_error: 53.5450 - val_loss: 55.6654 - val_mean_squared_error: 55.6654\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.6068 - mean_squared_error: 53.6069 - val_loss: 57.7211 - val_mean_squared_error: 57.7211\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 53.5282 - mean_squared_error: 53.5282 - val_loss: 55.3108 - val_mean_squared_error: 55.3108\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 53.3202 - mean_squared_error: 53.3202 - val_loss: 64.7611 - val_mean_squared_error: 64.7611\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.0450 - mean_squared_error: 53.0450 - val_loss: 55.8832 - val_mean_squared_error: 55.8832\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 53.2478 - mean_squared_error: 53.2478 - val_loss: 56.9087 - val_mean_squared_error: 56.9087\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 52.9962 - mean_squared_error: 52.9962 - val_loss: 57.8583 - val_mean_squared_error: 57.8583\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.9431 - mean_squared_error: 52.9431 - val_loss: 54.7914 - val_mean_squared_error: 54.7914\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.9699 - mean_squared_error: 52.9699 - val_loss: 58.6818 - val_mean_squared_error: 58.6818\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 52.7055 - mean_squared_error: 52.7055 - val_loss: 54.6770 - val_mean_squared_error: 54.6770\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.5718 - mean_squared_error: 52.5718 - val_loss: 54.4177 - val_mean_squared_error: 54.4177\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 52.5732 - mean_squared_error: 52.5733 - val_loss: 54.9941 - val_mean_squared_error: 54.9941\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 52.4998 - mean_squared_error: 52.4998 - val_loss: 54.6928 - val_mean_squared_error: 54.6928\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 52.4452 - mean_squared_error: 52.4452 - val_loss: 56.3598 - val_mean_squared_error: 56.3598\n",
      "Training Loss: [575.5653, 155.6157, 127.0758, 116.0799, 109.3738, 104.7722, 100.9249, 97.6382, 94.6873, 92.0867, 89.619, 87.0631, 85.1508, 83.3251, 81.5126, 79.8653, 78.4025, 77.1085, 75.593, 74.5937, 73.5773, 72.9911, 71.8527, 71.2025, 70.1807, 69.5242, 68.9617, 68.119, 67.745, 66.8162, 66.2647, 65.9009, 65.3635, 65.1611, 64.2267, 64.0678, 63.8696, 62.8146, 62.8245, 62.5208, 62.0554, 61.7693, 61.3726, 61.3963, 60.7262, 60.5821, 60.3397, 60.0576, 59.8135, 59.4619, 59.673, 58.9527, 58.7648, 58.7562, 58.2335, 58.432, 58.0552, 57.8312, 57.6558, 57.3708, 57.2274, 57.0303, 56.8441, 56.763, 56.5934, 56.2266, 56.2881, 55.9793, 56.0742, 55.518, 55.7922, 55.1706, 55.2611, 55.363, 55.0625, 55.0017, 54.6718, 54.5485, 54.5084, 54.4049, 54.2238, 54.2963, 53.8614, 54.0339, 53.8108, 53.7219, 53.545, 53.6068, 53.5282, 53.3202, 53.045, 53.2478, 52.9962, 52.9431, 52.9699, 52.7055, 52.5718, 52.5732, 52.4998, 52.4452]\n",
      "Validation Loss: [190.1341, 135.9927, 122.5892, 113.25, 108.9866, 101.7331, 99.2143, 94.823, 97.3894, 101.0254, 89.2116, 87.1132, 83.9644, 82.6612, 80.8155, 86.1681, 79.8839, 78.5756, 79.997, 74.7881, 73.6557, 72.2517, 71.4138, 70.957, 70.3467, 69.5002, 69.956, 69.2563, 68.4738, 67.6984, 67.4384, 68.4749, 65.7852, 65.3268, 64.5399, 67.223, 64.1862, 64.0931, 64.1821, 66.4395, 63.4022, 63.3441, 65.1855, 62.217, 63.3918, 66.8402, 61.8145, 61.1793, 60.8487, 62.6033, 60.7959, 63.0647, 61.3406, 60.3305, 60.9897, 62.0537, 60.3872, 59.2659, 59.0121, 61.0823, 58.3754, 58.1825, 59.9847, 59.959, 60.97, 57.4863, 57.8243, 58.7798, 57.2642, 58.0462, 57.2092, 58.7323, 60.6006, 57.0998, 56.7256, 62.5368, 56.161, 57.2577, 59.1277, 56.3844, 55.7644, 55.7896, 56.1799, 56.1427, 55.4877, 55.3001, 55.6654, 57.7211, 55.3108, 64.7611, 55.8832, 56.9087, 57.8583, 54.7914, 58.6818, 54.677, 54.4177, 54.9941, 54.6928, 56.3598]\n",
      "\n",
      "We are now training cross-validation set # 2\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 586.3070 - mean_squared_error: 586.3071 - val_loss: 204.7723 - val_mean_squared_error: 204.7722\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 175.6353 - mean_squared_error: 175.6353 - val_loss: 157.1210 - val_mean_squared_error: 157.1210\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 143.3351 - mean_squared_error: 143.3352 - val_loss: 133.7444 - val_mean_squared_error: 133.7443\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 126.1850 - mean_squared_error: 126.1849 - val_loss: 119.9421 - val_mean_squared_error: 119.9421\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 116.0778 - mean_squared_error: 116.0779 - val_loss: 113.8692 - val_mean_squared_error: 113.8692\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 109.4240 - mean_squared_error: 109.4240 - val_loss: 118.3639 - val_mean_squared_error: 118.3639\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 104.5259 - mean_squared_error: 104.5260 - val_loss: 100.9042 - val_mean_squared_error: 100.9042\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 100.5742 - mean_squared_error: 100.5742 - val_loss: 98.1455 - val_mean_squared_error: 98.1454\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 97.1268 - mean_squared_error: 97.1268 - val_loss: 99.3081 - val_mean_squared_error: 99.3081\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 93.9974 - mean_squared_error: 93.9973 - val_loss: 92.5927 - val_mean_squared_error: 92.5928\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 90.9860 - mean_squared_error: 90.9861 - val_loss: 91.0776 - val_mean_squared_error: 91.0776\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 88.6363 - mean_squared_error: 88.6363 - val_loss: 88.4209 - val_mean_squared_error: 88.4209\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 86.6957 - mean_squared_error: 86.6956 - val_loss: 84.7783 - val_mean_squared_error: 84.7783\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 84.8073 - mean_squared_error: 84.8072 - val_loss: 83.4210 - val_mean_squared_error: 83.4211\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 82.9817 - mean_squared_error: 82.9817 - val_loss: 84.7655 - val_mean_squared_error: 84.7655\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 81.6778 - mean_squared_error: 81.6779 - val_loss: 82.5315 - val_mean_squared_error: 82.5315\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 80.0693 - mean_squared_error: 80.0693 - val_loss: 78.9494 - val_mean_squared_error: 78.9494\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 79.0301 - mean_squared_error: 79.0300 - val_loss: 95.7010 - val_mean_squared_error: 95.7010\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 77.8297 - mean_squared_error: 77.8297 - val_loss: 78.6906 - val_mean_squared_error: 78.6906\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 77.0076 - mean_squared_error: 77.0076 - val_loss: 75.9213 - val_mean_squared_error: 75.9213\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 75.9312 - mean_squared_error: 75.9312 - val_loss: 77.8123 - val_mean_squared_error: 77.8122\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 75.2011 - mean_squared_error: 75.2011 - val_loss: 75.5629 - val_mean_squared_error: 75.5630\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 74.0311 - mean_squared_error: 74.0311 - val_loss: 73.3948 - val_mean_squared_error: 73.3948\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 73.6154 - mean_squared_error: 73.6154 - val_loss: 72.5176 - val_mean_squared_error: 72.5176\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 72.8416 - mean_squared_error: 72.8416 - val_loss: 72.3227 - val_mean_squared_error: 72.3227\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 72.3159 - mean_squared_error: 72.3159 - val_loss: 72.5411 - val_mean_squared_error: 72.5411\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 71.2786 - mean_squared_error: 71.2786 - val_loss: 80.5287 - val_mean_squared_error: 80.5287\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 70.9971 - mean_squared_error: 70.9971 - val_loss: 74.6477 - val_mean_squared_error: 74.6477\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 70.0989 - mean_squared_error: 70.0990 - val_loss: 70.0726 - val_mean_squared_error: 70.0726\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 69.7072 - mean_squared_error: 69.7071 - val_loss: 69.8507 - val_mean_squared_error: 69.8507\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 69.4084 - mean_squared_error: 69.4085 - val_loss: 69.7786 - val_mean_squared_error: 69.7786\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 68.7324 - mean_squared_error: 68.7324 - val_loss: 68.7325 - val_mean_squared_error: 68.7325\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 68.2553 - mean_squared_error: 68.2553 - val_loss: 69.3557 - val_mean_squared_error: 69.3557\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 67.8306 - mean_squared_error: 67.8306 - val_loss: 70.0410 - val_mean_squared_error: 70.0410\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 67.3361 - mean_squared_error: 67.3361 - val_loss: 74.5924 - val_mean_squared_error: 74.5924\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 66.9347 - mean_squared_error: 66.9348 - val_loss: 69.6022 - val_mean_squared_error: 69.6022\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 66.4709 - mean_squared_error: 66.4709 - val_loss: 76.0270 - val_mean_squared_error: 76.0270\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 66.2953 - mean_squared_error: 66.2953 - val_loss: 66.1832 - val_mean_squared_error: 66.1833\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 65.5198 - mean_squared_error: 65.5199 - val_loss: 66.0264 - val_mean_squared_error: 66.0264\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 65.2968 - mean_squared_error: 65.2968 - val_loss: 65.9861 - val_mean_squared_error: 65.9860\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 64.9390 - mean_squared_error: 64.9390 - val_loss: 70.2711 - val_mean_squared_error: 70.2711\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 64.6794 - mean_squared_error: 64.6794 - val_loss: 65.5541 - val_mean_squared_error: 65.5541\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 64.3028 - mean_squared_error: 64.3028 - val_loss: 67.7653 - val_mean_squared_error: 67.7653\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 63.8832 - mean_squared_error: 63.8832 - val_loss: 65.9397 - val_mean_squared_error: 65.9397\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 63.5544 - mean_squared_error: 63.5544 - val_loss: 63.8886 - val_mean_squared_error: 63.8886\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.2009 - mean_squared_error: 63.2009 - val_loss: 67.0938 - val_mean_squared_error: 67.0938\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 63.0852 - mean_squared_error: 63.0852 - val_loss: 64.0829 - val_mean_squared_error: 64.0829\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 62.7693 - mean_squared_error: 62.7693 - val_loss: 63.1716 - val_mean_squared_error: 63.1716\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.2305 - mean_squared_error: 62.2305 - val_loss: 65.8485 - val_mean_squared_error: 65.8485\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 62.2853 - mean_squared_error: 62.2854 - val_loss: 62.7055 - val_mean_squared_error: 62.7055\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.9246 - mean_squared_error: 61.9246 - val_loss: 66.2188 - val_mean_squared_error: 66.2188\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 61.7302 - mean_squared_error: 61.7302 - val_loss: 62.9579 - val_mean_squared_error: 62.9580\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.2763 - mean_squared_error: 61.2763 - val_loss: 65.2272 - val_mean_squared_error: 65.2272\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.2006 - mean_squared_error: 61.2006 - val_loss: 62.7636 - val_mean_squared_error: 62.7636\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 60.9498 - mean_squared_error: 60.9498 - val_loss: 61.8614 - val_mean_squared_error: 61.8614\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 60.6894 - mean_squared_error: 60.6894 - val_loss: 61.8200 - val_mean_squared_error: 61.8200\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 60.3984 - mean_squared_error: 60.3984 - val_loss: 61.9617 - val_mean_squared_error: 61.9617\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.2993 - mean_squared_error: 60.2993 - val_loss: 64.0211 - val_mean_squared_error: 64.0211\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.1033 - mean_squared_error: 60.1033 - val_loss: 61.3566 - val_mean_squared_error: 61.3566\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 59.9029 - mean_squared_error: 59.9029 - val_loss: 61.2302 - val_mean_squared_error: 61.2302\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 59.5775 - mean_squared_error: 59.5775 - val_loss: 65.2782 - val_mean_squared_error: 65.2781\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 59.3978 - mean_squared_error: 59.3977 - val_loss: 61.1340 - val_mean_squared_error: 61.1340\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 59.5301 - mean_squared_error: 59.5302 - val_loss: 61.2563 - val_mean_squared_error: 61.2563\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.0844 - mean_squared_error: 59.0844 - val_loss: 60.0241 - val_mean_squared_error: 60.0240\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 59.0299 - mean_squared_error: 59.0299 - val_loss: 60.6006 - val_mean_squared_error: 60.6006\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 58.6325 - mean_squared_error: 58.6326 - val_loss: 60.4435 - val_mean_squared_error: 60.4435\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 488us/step - loss: 58.6948 - mean_squared_error: 58.6948 - val_loss: 59.6136 - val_mean_squared_error: 59.6136\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.4468 - mean_squared_error: 58.4468 - val_loss: 64.1591 - val_mean_squared_error: 64.1591\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 58.2420 - mean_squared_error: 58.2421 - val_loss: 64.1669 - val_mean_squared_error: 64.1669\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 58.4012 - mean_squared_error: 58.4013 - val_loss: 59.3162 - val_mean_squared_error: 59.3162\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 57.8775 - mean_squared_error: 57.8775 - val_loss: 59.0821 - val_mean_squared_error: 59.0821\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 57.7061 - mean_squared_error: 57.7061 - val_loss: 59.5138 - val_mean_squared_error: 59.5138\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 57.8902 - mean_squared_error: 57.8902 - val_loss: 59.3538 - val_mean_squared_error: 59.3538\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.3895 - mean_squared_error: 57.3895 - val_loss: 59.0701 - val_mean_squared_error: 59.0701\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.4544 - mean_squared_error: 57.4543 - val_loss: 60.4340 - val_mean_squared_error: 60.4340\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 57.1793 - mean_squared_error: 57.1793 - val_loss: 62.3685 - val_mean_squared_error: 62.3685\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 56.9046 - mean_squared_error: 56.9046 - val_loss: 59.0899 - val_mean_squared_error: 59.0899\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 56.9698 - mean_squared_error: 56.9698 - val_loss: 63.1414 - val_mean_squared_error: 63.1414\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 56.7809 - mean_squared_error: 56.7809 - val_loss: 65.3610 - val_mean_squared_error: 65.3610\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 56.6959 - mean_squared_error: 56.6959 - val_loss: 59.7298 - val_mean_squared_error: 59.7298\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 56.5189 - mean_squared_error: 56.5189 - val_loss: 59.8705 - val_mean_squared_error: 59.8705\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 56.4619 - mean_squared_error: 56.4619 - val_loss: 58.0994 - val_mean_squared_error: 58.0994\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 56.0715 - mean_squared_error: 56.0715 - val_loss: 63.2470 - val_mean_squared_error: 63.2470\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 56.1660 - mean_squared_error: 56.1660 - val_loss: 58.5640 - val_mean_squared_error: 58.5640\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.8687 - mean_squared_error: 55.8687 - val_loss: 58.5641 - val_mean_squared_error: 58.5641\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 55.9948 - mean_squared_error: 55.9948 - val_loss: 58.1178 - val_mean_squared_error: 58.1178\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 55.7018 - mean_squared_error: 55.7018 - val_loss: 57.7818 - val_mean_squared_error: 57.7818\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 55.7559 - mean_squared_error: 55.7559 - val_loss: 57.0158 - val_mean_squared_error: 57.0158\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 55.3630 - mean_squared_error: 55.3630 - val_loss: 56.9520 - val_mean_squared_error: 56.9520\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 55.3113 - mean_squared_error: 55.3113 - val_loss: 57.4621 - val_mean_squared_error: 57.4621\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 55.3317 - mean_squared_error: 55.3317 - val_loss: 58.3310 - val_mean_squared_error: 58.3310\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.2376 - mean_squared_error: 55.2376 - val_loss: 57.4526 - val_mean_squared_error: 57.4526\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 54.9012 - mean_squared_error: 54.9012 - val_loss: 57.0920 - val_mean_squared_error: 57.0920\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 55.0031 - mean_squared_error: 55.0031 - val_loss: 57.0708 - val_mean_squared_error: 57.0708\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.8559 - mean_squared_error: 54.8559 - val_loss: 58.3868 - val_mean_squared_error: 58.3868\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.8232 - mean_squared_error: 54.8232 - val_loss: 57.0175 - val_mean_squared_error: 57.0175\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 54.5257 - mean_squared_error: 54.5257 - val_loss: 57.7561 - val_mean_squared_error: 57.7561\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 54.5122 - mean_squared_error: 54.5122 - val_loss: 56.1885 - val_mean_squared_error: 56.1885\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.7161 - mean_squared_error: 54.7161 - val_loss: 56.2141 - val_mean_squared_error: 56.2141\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 54.3856 - mean_squared_error: 54.3856 - val_loss: 56.0668 - val_mean_squared_error: 56.0668\n",
      "Training Loss: [586.307, 175.6353, 143.3351, 126.185, 116.0778, 109.424, 104.5259, 100.5742, 97.1268, 93.9974, 90.986, 88.6363, 86.6957, 84.8073, 82.9817, 81.6778, 80.0693, 79.0301, 77.8297, 77.0076, 75.9312, 75.2011, 74.0311, 73.6154, 72.8416, 72.3159, 71.2786, 70.9971, 70.0989, 69.7072, 69.4084, 68.7324, 68.2553, 67.8306, 67.3361, 66.9347, 66.4709, 66.2953, 65.5198, 65.2968, 64.939, 64.6794, 64.3028, 63.8832, 63.5544, 63.2009, 63.0852, 62.7693, 62.2305, 62.2853, 61.9246, 61.7302, 61.2763, 61.2006, 60.9498, 60.6894, 60.3984, 60.2993, 60.1033, 59.9029, 59.5775, 59.3978, 59.5301, 59.0844, 59.0299, 58.6325, 58.6948, 58.4468, 58.242, 58.4012, 57.8775, 57.7061, 57.8902, 57.3895, 57.4544, 57.1793, 56.9046, 56.9698, 56.7809, 56.6959, 56.5189, 56.4619, 56.0715, 56.166, 55.8687, 55.9948, 55.7018, 55.7559, 55.363, 55.3113, 55.3317, 55.2376, 54.9012, 55.0031, 54.8559, 54.8232, 54.5257, 54.5122, 54.7161, 54.3856]\n",
      "Validation Loss: [204.7723, 157.121, 133.7444, 119.9421, 113.8692, 118.3639, 100.9042, 98.1455, 99.3081, 92.5927, 91.0776, 88.4209, 84.7783, 83.421, 84.7655, 82.5315, 78.9494, 95.701, 78.6906, 75.9213, 77.8123, 75.5629, 73.3948, 72.5176, 72.3227, 72.5411, 80.5287, 74.6477, 70.0726, 69.8507, 69.7786, 68.7325, 69.3557, 70.041, 74.5924, 69.6022, 76.027, 66.1832, 66.0264, 65.9861, 70.2711, 65.5541, 67.7653, 65.9397, 63.8886, 67.0938, 64.0829, 63.1716, 65.8485, 62.7055, 66.2188, 62.9579, 65.2272, 62.7636, 61.8614, 61.82, 61.9617, 64.0211, 61.3566, 61.2302, 65.2782, 61.134, 61.2563, 60.0241, 60.6006, 60.4435, 59.6136, 64.1591, 64.1669, 59.3162, 59.0821, 59.5138, 59.3538, 59.0701, 60.434, 62.3685, 59.0899, 63.1414, 65.361, 59.7298, 59.8705, 58.0994, 63.247, 58.564, 58.5641, 58.1178, 57.7818, 57.0158, 56.952, 57.4621, 58.331, 57.4526, 57.092, 57.0708, 58.3868, 57.0175, 57.7561, 56.1885, 56.2141, 56.0668]\n",
      "\n",
      "We are now training cross-validation set # 3\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 580.1410 - mean_squared_error: 580.1406 - val_loss: 188.0361 - val_mean_squared_error: 188.0362\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 161.5205 - mean_squared_error: 161.5205 - val_loss: 143.2977 - val_mean_squared_error: 143.2977\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 131.9265 - mean_squared_error: 131.9265 - val_loss: 122.2392 - val_mean_squared_error: 122.2392\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 115.9566 - mean_squared_error: 115.9566 - val_loss: 109.8741 - val_mean_squared_error: 109.8741\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 107.4270 - mean_squared_error: 107.4269 - val_loss: 103.5413 - val_mean_squared_error: 103.5413\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 101.5490 - mean_squared_error: 101.5489 - val_loss: 98.6632 - val_mean_squared_error: 98.6632\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 97.0374 - mean_squared_error: 97.0373 - val_loss: 101.7251 - val_mean_squared_error: 101.7251\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 93.5128 - mean_squared_error: 93.5129 - val_loss: 90.7270 - val_mean_squared_error: 90.7270\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 454us/step - loss: 89.5201 - mean_squared_error: 89.5201 - val_loss: 92.2719 - val_mean_squared_error: 92.2719\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 86.1780 - mean_squared_error: 86.1779 - val_loss: 84.4883 - val_mean_squared_error: 84.4883\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 83.4394 - mean_squared_error: 83.4394 - val_loss: 82.9663 - val_mean_squared_error: 82.9663\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 80.5188 - mean_squared_error: 80.5188 - val_loss: 106.0005 - val_mean_squared_error: 106.0005\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 78.1372 - mean_squared_error: 78.1372 - val_loss: 79.6063 - val_mean_squared_error: 79.6063\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 76.0948 - mean_squared_error: 76.0947 - val_loss: 80.5435 - val_mean_squared_error: 80.5435\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 74.2478 - mean_squared_error: 74.2477 - val_loss: 74.2424 - val_mean_squared_error: 74.2424\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 72.8392 - mean_squared_error: 72.8392 - val_loss: 74.7246 - val_mean_squared_error: 74.7246\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 71.4755 - mean_squared_error: 71.4755 - val_loss: 73.1710 - val_mean_squared_error: 73.1710\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 70.5536 - mean_squared_error: 70.5536 - val_loss: 69.6301 - val_mean_squared_error: 69.6301\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 69.3120 - mean_squared_error: 69.3120 - val_loss: 68.9390 - val_mean_squared_error: 68.9390\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 68.5779 - mean_squared_error: 68.5779 - val_loss: 93.8395 - val_mean_squared_error: 93.8395\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 67.8382 - mean_squared_error: 67.8383 - val_loss: 67.2340 - val_mean_squared_error: 67.2340\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 66.8458 - mean_squared_error: 66.8457 - val_loss: 69.6744 - val_mean_squared_error: 69.6744\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 66.2000 - mean_squared_error: 66.2000 - val_loss: 68.0114 - val_mean_squared_error: 68.0114\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 65.3464 - mean_squared_error: 65.3464 - val_loss: 66.3879 - val_mean_squared_error: 66.3879\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 453us/step - loss: 65.0905 - mean_squared_error: 65.0905 - val_loss: 66.2712 - val_mean_squared_error: 66.2712\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 64.7455 - mean_squared_error: 64.7455 - val_loss: 66.7794 - val_mean_squared_error: 66.7793\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 64.1985 - mean_squared_error: 64.1986 - val_loss: 64.9518 - val_mean_squared_error: 64.9517\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 63.3046 - mean_squared_error: 63.3046 - val_loss: 64.3160 - val_mean_squared_error: 64.3160\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 63.2392 - mean_squared_error: 63.2391 - val_loss: 63.7566 - val_mean_squared_error: 63.7566\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 62.5901 - mean_squared_error: 62.5901 - val_loss: 63.1812 - val_mean_squared_error: 63.1812\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 62.3009 - mean_squared_error: 62.3009 - val_loss: 63.2406 - val_mean_squared_error: 63.2406\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 62.0056 - mean_squared_error: 62.0056 - val_loss: 62.7398 - val_mean_squared_error: 62.7398\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 61.5318 - mean_squared_error: 61.5318 - val_loss: 73.4281 - val_mean_squared_error: 73.4281\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 61.3080 - mean_squared_error: 61.3081 - val_loss: 61.9523 - val_mean_squared_error: 61.9523\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 60.8144 - mean_squared_error: 60.8144 - val_loss: 61.3499 - val_mean_squared_error: 61.3498\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 60.6729 - mean_squared_error: 60.6729 - val_loss: 61.2769 - val_mean_squared_error: 61.2769\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 60.9140 - mean_squared_error: 60.9140 - val_loss: 61.2392 - val_mean_squared_error: 61.2392\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 59.5028 - mean_squared_error: 59.5028 - val_loss: 62.7319 - val_mean_squared_error: 62.7319\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 59.8106 - mean_squared_error: 59.8106 - val_loss: 61.0997 - val_mean_squared_error: 61.0997\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 453us/step - loss: 59.5351 - mean_squared_error: 59.5351 - val_loss: 60.4240 - val_mean_squared_error: 60.4240\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 59.0383 - mean_squared_error: 59.0383 - val_loss: 61.0150 - val_mean_squared_error: 61.0150\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 452us/step - loss: 59.2609 - mean_squared_error: 59.2609 - val_loss: 60.7365 - val_mean_squared_error: 60.7365\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 58.4415 - mean_squared_error: 58.4415 - val_loss: 60.9337 - val_mean_squared_error: 60.9337\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 58.5853 - mean_squared_error: 58.5853 - val_loss: 59.6414 - val_mean_squared_error: 59.6414\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 58.4631 - mean_squared_error: 58.4630 - val_loss: 60.0145 - val_mean_squared_error: 60.0145\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 57.9070 - mean_squared_error: 57.9070 - val_loss: 59.2038 - val_mean_squared_error: 59.2038\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 57.7576 - mean_squared_error: 57.7576 - val_loss: 59.6741 - val_mean_squared_error: 59.6741\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 57.6236 - mean_squared_error: 57.6236 - val_loss: 59.8679 - val_mean_squared_error: 59.8679\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 57.4946 - mean_squared_error: 57.4945 - val_loss: 59.4170 - val_mean_squared_error: 59.4170\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 57.4501 - mean_squared_error: 57.4501 - val_loss: 58.8375 - val_mean_squared_error: 58.8375\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 56.8447 - mean_squared_error: 56.8447 - val_loss: 58.1528 - val_mean_squared_error: 58.1528\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 57.0419 - mean_squared_error: 57.0419 - val_loss: 58.6869 - val_mean_squared_error: 58.6869\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 56.5389 - mean_squared_error: 56.5389 - val_loss: 60.7580 - val_mean_squared_error: 60.7580\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 56.6677 - mean_squared_error: 56.6678 - val_loss: 58.0939 - val_mean_squared_error: 58.0939\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 56.2371 - mean_squared_error: 56.2370 - val_loss: 61.4261 - val_mean_squared_error: 61.4261\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 56.4164 - mean_squared_error: 56.4164 - val_loss: 57.7816 - val_mean_squared_error: 57.7816\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 56.1387 - mean_squared_error: 56.1387 - val_loss: 57.4889 - val_mean_squared_error: 57.4890\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 55.7906 - mean_squared_error: 55.7906 - val_loss: 57.3525 - val_mean_squared_error: 57.3525\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 55.7735 - mean_squared_error: 55.7735 - val_loss: 58.3189 - val_mean_squared_error: 58.3189\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 55.4521 - mean_squared_error: 55.4521 - val_loss: 57.0442 - val_mean_squared_error: 57.0442\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 55.4033 - mean_squared_error: 55.4034 - val_loss: 63.1179 - val_mean_squared_error: 63.1179\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 55.2522 - mean_squared_error: 55.2522 - val_loss: 58.0161 - val_mean_squared_error: 58.0160\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 55.0210 - mean_squared_error: 55.0210 - val_loss: 58.0418 - val_mean_squared_error: 58.0418\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 55.0340 - mean_squared_error: 55.0340 - val_loss: 57.0897 - val_mean_squared_error: 57.0897\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 55.2524 - mean_squared_error: 55.2523 - val_loss: 56.5876 - val_mean_squared_error: 56.5876\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 54.2507 - mean_squared_error: 54.2507 - val_loss: 57.1717 - val_mean_squared_error: 57.1717\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 54.6622 - mean_squared_error: 54.6622 - val_loss: 56.1794 - val_mean_squared_error: 56.1795\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 54.3765 - mean_squared_error: 54.3765 - val_loss: 57.3227 - val_mean_squared_error: 57.3227\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 54.3565 - mean_squared_error: 54.3565 - val_loss: 56.3834 - val_mean_squared_error: 56.3834\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 54.0923 - mean_squared_error: 54.0923 - val_loss: 55.9111 - val_mean_squared_error: 55.9111\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 53.9385 - mean_squared_error: 53.9385 - val_loss: 61.9180 - val_mean_squared_error: 61.9180\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 53.8247 - mean_squared_error: 53.8247 - val_loss: 55.7712 - val_mean_squared_error: 55.7712\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 53.8446 - mean_squared_error: 53.8446 - val_loss: 55.6094 - val_mean_squared_error: 55.6094\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 53.6399 - mean_squared_error: 53.6399 - val_loss: 55.7030 - val_mean_squared_error: 55.7031\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 53.5266 - mean_squared_error: 53.5267 - val_loss: 55.4332 - val_mean_squared_error: 55.4332\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 53.4511 - mean_squared_error: 53.4511 - val_loss: 56.9969 - val_mean_squared_error: 56.9969\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 53.4285 - mean_squared_error: 53.4285 - val_loss: 59.2575 - val_mean_squared_error: 59.2575\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 53.1833 - mean_squared_error: 53.1833 - val_loss: 57.0101 - val_mean_squared_error: 57.0101\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 53.1090 - mean_squared_error: 53.1090 - val_loss: 55.6407 - val_mean_squared_error: 55.6407\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 52.9823 - mean_squared_error: 52.9822 - val_loss: 55.1965 - val_mean_squared_error: 55.1965\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 53.0255 - mean_squared_error: 53.0255 - val_loss: 55.3377 - val_mean_squared_error: 55.3377\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 52.7730 - mean_squared_error: 52.7730 - val_loss: 55.2543 - val_mean_squared_error: 55.2543\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 52.6290 - mean_squared_error: 52.6290 - val_loss: 59.5849 - val_mean_squared_error: 59.5849\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 52.4864 - mean_squared_error: 52.4865 - val_loss: 57.0710 - val_mean_squared_error: 57.0710\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 52.4582 - mean_squared_error: 52.4582 - val_loss: 54.8038 - val_mean_squared_error: 54.8038\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 452us/step - loss: 52.4994 - mean_squared_error: 52.4994 - val_loss: 55.2033 - val_mean_squared_error: 55.2033\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 52.2755 - mean_squared_error: 52.2755 - val_loss: 54.4171 - val_mean_squared_error: 54.4171\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 52.2027 - mean_squared_error: 52.2027 - val_loss: 54.3006 - val_mean_squared_error: 54.3006\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 52.3172 - mean_squared_error: 52.3172 - val_loss: 54.2466 - val_mean_squared_error: 54.2466\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 51.7266 - mean_squared_error: 51.7267 - val_loss: 54.9938 - val_mean_squared_error: 54.9938\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 51.8187 - mean_squared_error: 51.8187 - val_loss: 55.9598 - val_mean_squared_error: 55.9598\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 52.0220 - mean_squared_error: 52.0220 - val_loss: 54.0494 - val_mean_squared_error: 54.0494\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 51.7131 - mean_squared_error: 51.7130 - val_loss: 54.1032 - val_mean_squared_error: 54.1032\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 51.7178 - mean_squared_error: 51.7178 - val_loss: 54.0154 - val_mean_squared_error: 54.0154\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 51.4368 - mean_squared_error: 51.4369 - val_loss: 53.8926 - val_mean_squared_error: 53.8926\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 51.3688 - mean_squared_error: 51.3688 - val_loss: 53.9890 - val_mean_squared_error: 53.9890\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 51.5850 - mean_squared_error: 51.5850 - val_loss: 54.8888 - val_mean_squared_error: 54.8888\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 51.2093 - mean_squared_error: 51.2093 - val_loss: 55.3986 - val_mean_squared_error: 55.3986\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 51.2213 - mean_squared_error: 51.2213 - val_loss: 53.5030 - val_mean_squared_error: 53.5030\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 51.1754 - mean_squared_error: 51.1754 - val_loss: 53.8739 - val_mean_squared_error: 53.8739\n",
      "Training Loss: [580.141, 161.5205, 131.9265, 115.9566, 107.427, 101.549, 97.0374, 93.5128, 89.5201, 86.178, 83.4394, 80.5188, 78.1372, 76.0948, 74.2478, 72.8392, 71.4755, 70.5536, 69.312, 68.5779, 67.8382, 66.8458, 66.2, 65.3464, 65.0905, 64.7455, 64.1985, 63.3046, 63.2392, 62.5901, 62.3009, 62.0056, 61.5318, 61.308, 60.8144, 60.6729, 60.914, 59.5028, 59.8106, 59.5351, 59.0383, 59.2609, 58.4415, 58.5853, 58.4631, 57.907, 57.7576, 57.6236, 57.4946, 57.4501, 56.8447, 57.0419, 56.5389, 56.6677, 56.2371, 56.4164, 56.1387, 55.7906, 55.7735, 55.4521, 55.4033, 55.2522, 55.021, 55.034, 55.2524, 54.2507, 54.6622, 54.3765, 54.3565, 54.0923, 53.9385, 53.8247, 53.8446, 53.6399, 53.5266, 53.4511, 53.4285, 53.1833, 53.109, 52.9823, 53.0255, 52.773, 52.629, 52.4864, 52.4582, 52.4994, 52.2755, 52.2027, 52.3172, 51.7266, 51.8187, 52.022, 51.7131, 51.7178, 51.4368, 51.3688, 51.585, 51.2093, 51.2213, 51.1754]\n",
      "Validation Loss: [188.0361, 143.2977, 122.2392, 109.8741, 103.5413, 98.6632, 101.7251, 90.727, 92.2719, 84.4883, 82.9663, 106.0005, 79.6063, 80.5435, 74.2424, 74.7246, 73.171, 69.6301, 68.939, 93.8395, 67.234, 69.6744, 68.0114, 66.3879, 66.2712, 66.7794, 64.9518, 64.316, 63.7566, 63.1812, 63.2406, 62.7398, 73.4281, 61.9523, 61.3499, 61.2769, 61.2392, 62.7319, 61.0997, 60.424, 61.015, 60.7365, 60.9337, 59.6414, 60.0145, 59.2038, 59.6741, 59.8679, 59.417, 58.8375, 58.1528, 58.6869, 60.758, 58.0939, 61.4261, 57.7816, 57.4889, 57.3525, 58.3189, 57.0442, 63.1179, 58.0161, 58.0418, 57.0897, 56.5876, 57.1717, 56.1794, 57.3227, 56.3834, 55.9111, 61.918, 55.7712, 55.6094, 55.703, 55.4332, 56.9969, 59.2575, 57.0101, 55.6407, 55.1965, 55.3377, 55.2543, 59.5849, 57.071, 54.8038, 55.2033, 54.4171, 54.3006, 54.2466, 54.9938, 55.9598, 54.0494, 54.1032, 54.0154, 53.8926, 53.989, 54.8888, 55.3986, 53.503, 53.8739]\n",
      "\n",
      "We are now training cross-validation set # 4\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 536.5086 - mean_squared_error: 536.5087 - val_loss: 178.2068 - val_mean_squared_error: 178.2069\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 153.5489 - mean_squared_error: 153.5489 - val_loss: 147.1774 - val_mean_squared_error: 147.1774\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 128.5664 - mean_squared_error: 128.5663 - val_loss: 120.7353 - val_mean_squared_error: 120.7352\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 116.6076 - mean_squared_error: 116.6076 - val_loss: 114.8731 - val_mean_squared_error: 114.8731\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 109.3874 - mean_squared_error: 109.3875 - val_loss: 108.4349 - val_mean_squared_error: 108.4350\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 104.2932 - mean_squared_error: 104.2932 - val_loss: 101.0464 - val_mean_squared_error: 101.0463\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 99.5302 - mean_squared_error: 99.5301 - val_loss: 96.5581 - val_mean_squared_error: 96.5581\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 96.8210 - mean_squared_error: 96.8210 - val_loss: 95.8699 - val_mean_squared_error: 95.8699\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 94.5127 - mean_squared_error: 94.5127 - val_loss: 91.3065 - val_mean_squared_error: 91.3065\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 91.6177 - mean_squared_error: 91.6177 - val_loss: 89.2432 - val_mean_squared_error: 89.2432\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 89.7978 - mean_squared_error: 89.7978 - val_loss: 88.8666 - val_mean_squared_error: 88.8666\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 88.0808 - mean_squared_error: 88.0808 - val_loss: 86.0936 - val_mean_squared_error: 86.0937\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 85.9672 - mean_squared_error: 85.9673 - val_loss: 91.4476 - val_mean_squared_error: 91.4476\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 84.0886 - mean_squared_error: 84.0886 - val_loss: 82.6262 - val_mean_squared_error: 82.6262\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 452us/step - loss: 82.8041 - mean_squared_error: 82.8041 - val_loss: 81.5088 - val_mean_squared_error: 81.5088\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 81.3309 - mean_squared_error: 81.3309 - val_loss: 92.1116 - val_mean_squared_error: 92.1116\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 79.8836 - mean_squared_error: 79.8835 - val_loss: 79.3662 - val_mean_squared_error: 79.3662\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 78.8363 - mean_squared_error: 78.8363 - val_loss: 79.4087 - val_mean_squared_error: 79.4087\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 77.5264 - mean_squared_error: 77.5264 - val_loss: 89.6104 - val_mean_squared_error: 89.6104\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 76.6907 - mean_squared_error: 76.6907 - val_loss: 80.8542 - val_mean_squared_error: 80.8541\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 75.2380 - mean_squared_error: 75.2379 - val_loss: 75.1370 - val_mean_squared_error: 75.1370\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 74.6336 - mean_squared_error: 74.6336 - val_loss: 73.9860 - val_mean_squared_error: 73.9860\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 74.2925 - mean_squared_error: 74.2925 - val_loss: 73.1297 - val_mean_squared_error: 73.1297\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 71.9932 - mean_squared_error: 71.9932 - val_loss: 73.1372 - val_mean_squared_error: 73.1373\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 72.0928 - mean_squared_error: 72.0928 - val_loss: 71.3185 - val_mean_squared_error: 71.3185\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 70.6308 - mean_squared_error: 70.6308 - val_loss: 75.2908 - val_mean_squared_error: 75.2908\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 70.5869 - mean_squared_error: 70.5869 - val_loss: 71.6906 - val_mean_squared_error: 71.6906\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 454us/step - loss: 69.2944 - mean_squared_error: 69.2944 - val_loss: 83.5738 - val_mean_squared_error: 83.5738\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 69.2012 - mean_squared_error: 69.2011 - val_loss: 69.1035 - val_mean_squared_error: 69.1035\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 68.4356 - mean_squared_error: 68.4356 - val_loss: 69.2181 - val_mean_squared_error: 69.2181\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 68.0588 - mean_squared_error: 68.0588 - val_loss: 68.6320 - val_mean_squared_error: 68.6320\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 67.5974 - mean_squared_error: 67.5975 - val_loss: 67.5014 - val_mean_squared_error: 67.5014\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 66.6439 - mean_squared_error: 66.6440 - val_loss: 71.7387 - val_mean_squared_error: 71.7387\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 66.5997 - mean_squared_error: 66.5997 - val_loss: 79.0776 - val_mean_squared_error: 79.0776\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 66.0825 - mean_squared_error: 66.0825 - val_loss: 66.9729 - val_mean_squared_error: 66.9729\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 449us/step - loss: 65.6381 - mean_squared_error: 65.6381 - val_loss: 67.5404 - val_mean_squared_error: 67.5404\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 65.2711 - mean_squared_error: 65.2711 - val_loss: 66.1833 - val_mean_squared_error: 66.1833\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 64.9997 - mean_squared_error: 64.9997 - val_loss: 66.0575 - val_mean_squared_error: 66.0575\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 64.4883 - mean_squared_error: 64.4883 - val_loss: 65.1666 - val_mean_squared_error: 65.1666\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 64.4620 - mean_squared_error: 64.4620 - val_loss: 65.0811 - val_mean_squared_error: 65.0811\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 63.6806 - mean_squared_error: 63.6806 - val_loss: 67.6158 - val_mean_squared_error: 67.6157\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 63.6311 - mean_squared_error: 63.6311 - val_loss: 66.0690 - val_mean_squared_error: 66.0690\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 63.0401 - mean_squared_error: 63.0401 - val_loss: 64.7828 - val_mean_squared_error: 64.7828\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 62.9144 - mean_squared_error: 62.9144 - val_loss: 64.0913 - val_mean_squared_error: 64.0913\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 453us/step - loss: 62.5430 - mean_squared_error: 62.5431 - val_loss: 63.9151 - val_mean_squared_error: 63.9150\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 62.5470 - mean_squared_error: 62.5470 - val_loss: 63.3993 - val_mean_squared_error: 63.3993\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 61.6962 - mean_squared_error: 61.6962 - val_loss: 64.1207 - val_mean_squared_error: 64.1207\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 61.7059 - mean_squared_error: 61.7059 - val_loss: 63.2077 - val_mean_squared_error: 63.2077\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 61.3296 - mean_squared_error: 61.3296 - val_loss: 62.3210 - val_mean_squared_error: 62.3210\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 443us/step - loss: 61.3892 - mean_squared_error: 61.3892 - val_loss: 63.2641 - val_mean_squared_error: 63.2642\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 60.7046 - mean_squared_error: 60.7046 - val_loss: 62.3377 - val_mean_squared_error: 62.3377\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 60.6391 - mean_squared_error: 60.6391 - val_loss: 82.1435 - val_mean_squared_error: 82.1435\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 60.2315 - mean_squared_error: 60.2314 - val_loss: 71.3679 - val_mean_squared_error: 71.3679\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 60.1315 - mean_squared_error: 60.1315 - val_loss: 61.4357 - val_mean_squared_error: 61.4357\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 59.7439 - mean_squared_error: 59.7439 - val_loss: 61.8294 - val_mean_squared_error: 61.8294\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 59.7290 - mean_squared_error: 59.7290 - val_loss: 64.2461 - val_mean_squared_error: 64.2461\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 59.3822 - mean_squared_error: 59.3822 - val_loss: 60.5510 - val_mean_squared_error: 60.5510\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 59.2472 - mean_squared_error: 59.2472 - val_loss: 64.1164 - val_mean_squared_error: 64.1164\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 453us/step - loss: 58.8291 - mean_squared_error: 58.8291 - val_loss: 63.7562 - val_mean_squared_error: 63.7563\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 58.7782 - mean_squared_error: 58.7782 - val_loss: 61.0072 - val_mean_squared_error: 61.0073\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 58.3880 - mean_squared_error: 58.3880 - val_loss: 59.9983 - val_mean_squared_error: 59.9983\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 58.2288 - mean_squared_error: 58.2288 - val_loss: 59.7359 - val_mean_squared_error: 59.7359\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 58.0602 - mean_squared_error: 58.0602 - val_loss: 60.1758 - val_mean_squared_error: 60.1758\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 57.9334 - mean_squared_error: 57.9333 - val_loss: 60.4544 - val_mean_squared_error: 60.4544\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 448us/step - loss: 57.8243 - mean_squared_error: 57.8243 - val_loss: 60.2067 - val_mean_squared_error: 60.2066\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 57.3376 - mean_squared_error: 57.3376 - val_loss: 59.7567 - val_mean_squared_error: 59.7567\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 57.3031 - mean_squared_error: 57.3030 - val_loss: 59.5647 - val_mean_squared_error: 59.5646\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 57.6308 - mean_squared_error: 57.6308 - val_loss: 58.8420 - val_mean_squared_error: 58.8420\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 56.7231 - mean_squared_error: 56.7231 - val_loss: 58.6202 - val_mean_squared_error: 58.6202\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 56.9922 - mean_squared_error: 56.9922 - val_loss: 59.1935 - val_mean_squared_error: 59.1934\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 56.6572 - mean_squared_error: 56.6572 - val_loss: 59.0800 - val_mean_squared_error: 59.0800\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 56.4032 - mean_squared_error: 56.4032 - val_loss: 58.4183 - val_mean_squared_error: 58.4183\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 443us/step - loss: 56.5207 - mean_squared_error: 56.5207 - val_loss: 58.4748 - val_mean_squared_error: 58.4748\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 56.0744 - mean_squared_error: 56.0744 - val_loss: 57.9162 - val_mean_squared_error: 57.9162\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 56.0618 - mean_squared_error: 56.0618 - val_loss: 62.9826 - val_mean_squared_error: 62.9826\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 55.9962 - mean_squared_error: 55.9962 - val_loss: 57.6906 - val_mean_squared_error: 57.6906\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 55.6597 - mean_squared_error: 55.6597 - val_loss: 58.3280 - val_mean_squared_error: 58.3280\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 452us/step - loss: 55.7980 - mean_squared_error: 55.7980 - val_loss: 58.8548 - val_mean_squared_error: 58.8548\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 55.6816 - mean_squared_error: 55.6816 - val_loss: 59.6395 - val_mean_squared_error: 59.6394\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 55.4782 - mean_squared_error: 55.4782 - val_loss: 63.8849 - val_mean_squared_error: 63.8849\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 55.2099 - mean_squared_error: 55.2098 - val_loss: 58.8699 - val_mean_squared_error: 58.8699\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 55.1261 - mean_squared_error: 55.1261 - val_loss: 59.1621 - val_mean_squared_error: 59.1621\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 447us/step - loss: 55.1524 - mean_squared_error: 55.1524 - val_loss: 57.8950 - val_mean_squared_error: 57.8950\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 54.8444 - mean_squared_error: 54.8443 - val_loss: 57.3069 - val_mean_squared_error: 57.3069\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 54.9279 - mean_squared_error: 54.9279 - val_loss: 56.6057 - val_mean_squared_error: 56.6057\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 443us/step - loss: 54.6919 - mean_squared_error: 54.6919 - val_loss: 57.1787 - val_mean_squared_error: 57.1787\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 54.5748 - mean_squared_error: 54.5748 - val_loss: 57.6470 - val_mean_squared_error: 57.6470\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 443us/step - loss: 54.4853 - mean_squared_error: 54.4853 - val_loss: 56.7982 - val_mean_squared_error: 56.7982\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 54.2145 - mean_squared_error: 54.2146 - val_loss: 56.6147 - val_mean_squared_error: 56.6147\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 451us/step - loss: 54.2366 - mean_squared_error: 54.2366 - val_loss: 56.5388 - val_mean_squared_error: 56.5388\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 53.9542 - mean_squared_error: 53.9542 - val_loss: 56.4864 - val_mean_squared_error: 56.4864\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 442us/step - loss: 54.0112 - mean_squared_error: 54.0112 - val_loss: 56.2553 - val_mean_squared_error: 56.2553\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 443us/step - loss: 53.9906 - mean_squared_error: 53.9906 - val_loss: 55.8677 - val_mean_squared_error: 55.8677\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 53.5845 - mean_squared_error: 53.5845 - val_loss: 56.6965 - val_mean_squared_error: 56.6965\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 53.6036 - mean_squared_error: 53.6036 - val_loss: 63.9278 - val_mean_squared_error: 63.9278\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 53.5722 - mean_squared_error: 53.5722 - val_loss: 57.5831 - val_mean_squared_error: 57.5831\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 53.4522 - mean_squared_error: 53.4522 - val_loss: 56.0082 - val_mean_squared_error: 56.0082\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 445us/step - loss: 53.2764 - mean_squared_error: 53.2764 - val_loss: 57.1024 - val_mean_squared_error: 57.1024\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 53.4215 - mean_squared_error: 53.4215 - val_loss: 59.1215 - val_mean_squared_error: 59.1216\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 446us/step - loss: 53.3244 - mean_squared_error: 53.3243 - val_loss: 55.6189 - val_mean_squared_error: 55.6189\n",
      "Training Loss: [536.5086, 153.5489, 128.5664, 116.6076, 109.3874, 104.2932, 99.5302, 96.821, 94.5127, 91.6177, 89.7978, 88.0808, 85.9672, 84.0886, 82.8041, 81.3309, 79.8836, 78.8363, 77.5264, 76.6907, 75.238, 74.6336, 74.2925, 71.9932, 72.0928, 70.6308, 70.5869, 69.2944, 69.2012, 68.4356, 68.0588, 67.5974, 66.6439, 66.5997, 66.0825, 65.6381, 65.2711, 64.9997, 64.4883, 64.462, 63.6806, 63.6311, 63.0401, 62.9144, 62.543, 62.547, 61.6962, 61.7059, 61.3296, 61.3892, 60.7046, 60.6391, 60.2315, 60.1315, 59.7439, 59.729, 59.3822, 59.2472, 58.8291, 58.7782, 58.388, 58.2288, 58.0602, 57.9334, 57.8243, 57.3376, 57.3031, 57.6308, 56.7231, 56.9922, 56.6572, 56.4032, 56.5207, 56.0744, 56.0618, 55.9962, 55.6597, 55.798, 55.6816, 55.4782, 55.2099, 55.1261, 55.1524, 54.8444, 54.9279, 54.6919, 54.5748, 54.4853, 54.2145, 54.2366, 53.9542, 54.0112, 53.9906, 53.5845, 53.6036, 53.5722, 53.4522, 53.2764, 53.4215, 53.3244]\n",
      "Validation Loss: [178.2068, 147.1774, 120.7353, 114.8731, 108.4349, 101.0464, 96.5581, 95.8699, 91.3065, 89.2432, 88.8666, 86.0936, 91.4476, 82.6262, 81.5088, 92.1116, 79.3662, 79.4087, 89.6104, 80.8542, 75.137, 73.986, 73.1297, 73.1372, 71.3185, 75.2908, 71.6906, 83.5738, 69.1035, 69.2181, 68.632, 67.5014, 71.7387, 79.0776, 66.9729, 67.5404, 66.1833, 66.0575, 65.1666, 65.0811, 67.6158, 66.069, 64.7828, 64.0913, 63.9151, 63.3993, 64.1207, 63.2077, 62.321, 63.2641, 62.3377, 82.1435, 71.3679, 61.4357, 61.8294, 64.2461, 60.551, 64.1164, 63.7562, 61.0072, 59.9983, 59.7359, 60.1758, 60.4544, 60.2067, 59.7567, 59.5647, 58.842, 58.6202, 59.1935, 59.08, 58.4183, 58.4748, 57.9162, 62.9826, 57.6906, 58.328, 58.8548, 59.6395, 63.8849, 58.8699, 59.1621, 57.895, 57.3069, 56.6057, 57.1787, 57.647, 56.7982, 56.6147, 56.5388, 56.4864, 56.2553, 55.8677, 56.6965, 63.9278, 57.5831, 56.0082, 57.1024, 59.1215, 55.6189]\n",
      "\n",
      "We are now training cross-validation set # 5\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 494us/step - loss: 583.3771 - mean_squared_error: 583.3771 - val_loss: 189.4383 - val_mean_squared_error: 189.4383\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 164.3397 - mean_squared_error: 164.3398 - val_loss: 148.3623 - val_mean_squared_error: 148.3623\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 138.9619 - mean_squared_error: 138.9619 - val_loss: 134.5301 - val_mean_squared_error: 134.5300\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 125.8641 - mean_squared_error: 125.8641 - val_loss: 124.1224 - val_mean_squared_error: 124.1224\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 116.4018 - mean_squared_error: 116.4017 - val_loss: 117.6349 - val_mean_squared_error: 117.6349\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 110.2267 - mean_squared_error: 110.2266 - val_loss: 125.6681 - val_mean_squared_error: 125.6682\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 105.7971 - mean_squared_error: 105.7971 - val_loss: 104.2454 - val_mean_squared_error: 104.2454\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 101.6323 - mean_squared_error: 101.6324 - val_loss: 98.6378 - val_mean_squared_error: 98.6378\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 98.4493 - mean_squared_error: 98.4492 - val_loss: 101.1424 - val_mean_squared_error: 101.1424\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 95.0857 - mean_squared_error: 95.0857 - val_loss: 93.7660 - val_mean_squared_error: 93.7660\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 91.9795 - mean_squared_error: 91.9795 - val_loss: 91.9756 - val_mean_squared_error: 91.9756\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 89.5839 - mean_squared_error: 89.5839 - val_loss: 99.1548 - val_mean_squared_error: 99.1548\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 87.4600 - mean_squared_error: 87.4599 - val_loss: 87.8975 - val_mean_squared_error: 87.8975\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 84.8994 - mean_squared_error: 84.8995 - val_loss: 88.6883 - val_mean_squared_error: 88.6883\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 83.2469 - mean_squared_error: 83.2468 - val_loss: 81.6057 - val_mean_squared_error: 81.6056\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 81.3164 - mean_squared_error: 81.3164 - val_loss: 80.8841 - val_mean_squared_error: 80.8841\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 80.1257 - mean_squared_error: 80.1257 - val_loss: 79.6262 - val_mean_squared_error: 79.6262\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 78.4167 - mean_squared_error: 78.4167 - val_loss: 77.6371 - val_mean_squared_error: 77.6371\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 77.2736 - mean_squared_error: 77.2737 - val_loss: 77.7809 - val_mean_squared_error: 77.7809\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 76.3431 - mean_squared_error: 76.3431 - val_loss: 75.6560 - val_mean_squared_error: 75.6560\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 74.8835 - mean_squared_error: 74.8835 - val_loss: 75.8322 - val_mean_squared_error: 75.8322\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 74.1982 - mean_squared_error: 74.1982 - val_loss: 73.7618 - val_mean_squared_error: 73.7618\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 73.5308 - mean_squared_error: 73.5308 - val_loss: 73.2085 - val_mean_squared_error: 73.2085\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 72.8264 - mean_squared_error: 72.8264 - val_loss: 71.7831 - val_mean_squared_error: 71.7831\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 71.4404 - mean_squared_error: 71.4404 - val_loss: 71.2541 - val_mean_squared_error: 71.2541\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 71.0013 - mean_squared_error: 71.0013 - val_loss: 70.0271 - val_mean_squared_error: 70.0271\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 70.1679 - mean_squared_error: 70.1679 - val_loss: 69.4220 - val_mean_squared_error: 69.4220\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 69.6890 - mean_squared_error: 69.6890 - val_loss: 68.8267 - val_mean_squared_error: 68.8267\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 68.6545 - mean_squared_error: 68.6545 - val_loss: 68.5771 - val_mean_squared_error: 68.5771\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 68.3416 - mean_squared_error: 68.3416 - val_loss: 69.9835 - val_mean_squared_error: 69.9835\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 68.1679 - mean_squared_error: 68.1679 - val_loss: 67.7816 - val_mean_squared_error: 67.7817\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 67.1237 - mean_squared_error: 67.1237 - val_loss: 72.1788 - val_mean_squared_error: 72.1788\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 66.6493 - mean_squared_error: 66.6493 - val_loss: 66.3879 - val_mean_squared_error: 66.3879\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 66.4314 - mean_squared_error: 66.4314 - val_loss: 67.7628 - val_mean_squared_error: 67.7628\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 65.6258 - mean_squared_error: 65.6258 - val_loss: 66.2221 - val_mean_squared_error: 66.2221\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 65.3427 - mean_squared_error: 65.3426 - val_loss: 65.0375 - val_mean_squared_error: 65.0375\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 65.0675 - mean_squared_error: 65.0675 - val_loss: 67.3077 - val_mean_squared_error: 67.3077\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 64.5991 - mean_squared_error: 64.5991 - val_loss: 64.8224 - val_mean_squared_error: 64.8224\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 64.2870 - mean_squared_error: 64.2870 - val_loss: 64.3731 - val_mean_squared_error: 64.3731\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 63.7956 - mean_squared_error: 63.7955 - val_loss: 65.2397 - val_mean_squared_error: 65.2397\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 63.7288 - mean_squared_error: 63.7289 - val_loss: 66.2137 - val_mean_squared_error: 66.2137\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 63.2487 - mean_squared_error: 63.2487 - val_loss: 63.1702 - val_mean_squared_error: 63.1701\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 62.6664 - mean_squared_error: 62.6664 - val_loss: 68.7883 - val_mean_squared_error: 68.7883\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.5735 - mean_squared_error: 62.5735 - val_loss: 63.5223 - val_mean_squared_error: 63.5223\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.2681 - mean_squared_error: 62.2681 - val_loss: 62.7144 - val_mean_squared_error: 62.7144\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 62.2560 - mean_squared_error: 62.2561 - val_loss: 64.7985 - val_mean_squared_error: 64.7985\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 61.4917 - mean_squared_error: 61.4917 - val_loss: 62.9862 - val_mean_squared_error: 62.9862\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 61.4521 - mean_squared_error: 61.4522 - val_loss: 62.7585 - val_mean_squared_error: 62.7585\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 61.5310 - mean_squared_error: 61.5309 - val_loss: 64.2501 - val_mean_squared_error: 64.2501\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 60.7507 - mean_squared_error: 60.7507 - val_loss: 63.8402 - val_mean_squared_error: 63.8402\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 60.8316 - mean_squared_error: 60.8316 - val_loss: 62.5105 - val_mean_squared_error: 62.5105\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 60.3595 - mean_squared_error: 60.3594 - val_loss: 63.4055 - val_mean_squared_error: 63.4055\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 60.3167 - mean_squared_error: 60.3167 - val_loss: 63.2326 - val_mean_squared_error: 63.2326\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.9933 - mean_squared_error: 59.9932 - val_loss: 65.6007 - val_mean_squared_error: 65.6007\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 59.7722 - mean_squared_error: 59.7722 - val_loss: 60.9525 - val_mean_squared_error: 60.9525\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.5817 - mean_squared_error: 59.5817 - val_loss: 63.7463 - val_mean_squared_error: 63.7463\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 59.2839 - mean_squared_error: 59.2839 - val_loss: 60.8082 - val_mean_squared_error: 60.8081\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 59.3028 - mean_squared_error: 59.3028 - val_loss: 63.7202 - val_mean_squared_error: 63.7202\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.0299 - mean_squared_error: 59.0299 - val_loss: 61.1050 - val_mean_squared_error: 61.1050\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 58.9853 - mean_squared_error: 58.9853 - val_loss: 60.6387 - val_mean_squared_error: 60.6387\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 58.6258 - mean_squared_error: 58.6257 - val_loss: 60.7032 - val_mean_squared_error: 60.7032\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 58.4916 - mean_squared_error: 58.4916 - val_loss: 59.9789 - val_mean_squared_error: 59.9789\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 58.3553 - mean_squared_error: 58.3553 - val_loss: 59.3324 - val_mean_squared_error: 59.3324\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 58.1304 - mean_squared_error: 58.1305 - val_loss: 59.8414 - val_mean_squared_error: 59.8414\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 57.9718 - mean_squared_error: 57.9718 - val_loss: 60.1869 - val_mean_squared_error: 60.1869\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 57.8615 - mean_squared_error: 57.8615 - val_loss: 59.3707 - val_mean_squared_error: 59.3708\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 57.6171 - mean_squared_error: 57.6171 - val_loss: 60.3457 - val_mean_squared_error: 60.3457\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 57.4870 - mean_squared_error: 57.4870 - val_loss: 59.0354 - val_mean_squared_error: 59.0354\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 57.7573 - mean_squared_error: 57.7574 - val_loss: 60.3173 - val_mean_squared_error: 60.3172\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 56.8425 - mean_squared_error: 56.8425 - val_loss: 59.8865 - val_mean_squared_error: 59.8865\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 57.1173 - mean_squared_error: 57.1173 - val_loss: 58.4265 - val_mean_squared_error: 58.4264\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 56.8499 - mean_squared_error: 56.8499 - val_loss: 58.2170 - val_mean_squared_error: 58.2170\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 56.9103 - mean_squared_error: 56.9103 - val_loss: 59.1192 - val_mean_squared_error: 59.1192\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 56.7436 - mean_squared_error: 56.7436 - val_loss: 60.7295 - val_mean_squared_error: 60.7295\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 56.4465 - mean_squared_error: 56.4465 - val_loss: 60.6482 - val_mean_squared_error: 60.6482\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 56.1890 - mean_squared_error: 56.1890 - val_loss: 64.0288 - val_mean_squared_error: 64.0288\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 56.3601 - mean_squared_error: 56.3602 - val_loss: 60.2646 - val_mean_squared_error: 60.2646\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 56.1752 - mean_squared_error: 56.1752 - val_loss: 57.7883 - val_mean_squared_error: 57.7883\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 55.8948 - mean_squared_error: 55.8948 - val_loss: 58.6743 - val_mean_squared_error: 58.6743\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 55.9156 - mean_squared_error: 55.9156 - val_loss: 57.2772 - val_mean_squared_error: 57.2771\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.6429 - mean_squared_error: 55.6429 - val_loss: 60.2348 - val_mean_squared_error: 60.2347\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 55.6086 - mean_squared_error: 55.6085 - val_loss: 57.9660 - val_mean_squared_error: 57.9660\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.7755 - mean_squared_error: 55.7755 - val_loss: 56.7707 - val_mean_squared_error: 56.7708\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 55.2651 - mean_squared_error: 55.2651 - val_loss: 76.9590 - val_mean_squared_error: 76.9590\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 55.5816 - mean_squared_error: 55.5816 - val_loss: 56.8540 - val_mean_squared_error: 56.8540\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 55.0801 - mean_squared_error: 55.0801 - val_loss: 57.0097 - val_mean_squared_error: 57.0097\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 54.9225 - mean_squared_error: 54.9225 - val_loss: 60.7359 - val_mean_squared_error: 60.7359\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 54.9537 - mean_squared_error: 54.9537 - val_loss: 56.8798 - val_mean_squared_error: 56.8798\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.7515 - mean_squared_error: 54.7515 - val_loss: 56.7713 - val_mean_squared_error: 56.7713\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.9060 - mean_squared_error: 54.9060 - val_loss: 59.7314 - val_mean_squared_error: 59.7314\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.9693 - mean_squared_error: 54.9693 - val_loss: 56.4445 - val_mean_squared_error: 56.4445\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 54.4021 - mean_squared_error: 54.4021 - val_loss: 56.3595 - val_mean_squared_error: 56.3595\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.5064 - mean_squared_error: 54.5064 - val_loss: 56.8958 - val_mean_squared_error: 56.8958\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 54.3197 - mean_squared_error: 54.3197 - val_loss: 60.3193 - val_mean_squared_error: 60.3192\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 54.2832 - mean_squared_error: 54.2832 - val_loss: 56.1602 - val_mean_squared_error: 56.1602\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 54.3927 - mean_squared_error: 54.3927 - val_loss: 55.8443 - val_mean_squared_error: 55.8443\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 53.8830 - mean_squared_error: 53.8830 - val_loss: 57.9681 - val_mean_squared_error: 57.9681\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.0918 - mean_squared_error: 54.0917 - val_loss: 55.7590 - val_mean_squared_error: 55.7590\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 53.8879 - mean_squared_error: 53.8879 - val_loss: 55.7633 - val_mean_squared_error: 55.7633\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 53.7289 - mean_squared_error: 53.7289 - val_loss: 55.7339 - val_mean_squared_error: 55.7339\n",
      "Training Loss: [583.3771, 164.3397, 138.9619, 125.8641, 116.4018, 110.2267, 105.7971, 101.6323, 98.4493, 95.0857, 91.9795, 89.5839, 87.46, 84.8994, 83.2469, 81.3164, 80.1257, 78.4167, 77.2736, 76.3431, 74.8835, 74.1982, 73.5308, 72.8264, 71.4404, 71.0013, 70.1679, 69.689, 68.6545, 68.3416, 68.1679, 67.1237, 66.6493, 66.4314, 65.6258, 65.3427, 65.0675, 64.5991, 64.287, 63.7956, 63.7288, 63.2487, 62.6664, 62.5735, 62.2681, 62.256, 61.4917, 61.4521, 61.531, 60.7507, 60.8316, 60.3595, 60.3167, 59.9933, 59.7722, 59.5817, 59.2839, 59.3028, 59.0299, 58.9853, 58.6258, 58.4916, 58.3553, 58.1304, 57.9718, 57.8615, 57.6171, 57.487, 57.7573, 56.8425, 57.1173, 56.8499, 56.9103, 56.7436, 56.4465, 56.189, 56.3601, 56.1752, 55.8948, 55.9156, 55.6429, 55.6086, 55.7755, 55.2651, 55.5816, 55.0801, 54.9225, 54.9537, 54.7515, 54.906, 54.9693, 54.4021, 54.5064, 54.3197, 54.2832, 54.3927, 53.883, 54.0918, 53.8879, 53.7289]\n",
      "Validation Loss: [189.4383, 148.3623, 134.5301, 124.1224, 117.6349, 125.6681, 104.2454, 98.6378, 101.1424, 93.766, 91.9756, 99.1548, 87.8975, 88.6883, 81.6057, 80.8841, 79.6262, 77.6371, 77.7809, 75.656, 75.8322, 73.7618, 73.2085, 71.7831, 71.2541, 70.0271, 69.422, 68.8267, 68.5771, 69.9835, 67.7816, 72.1788, 66.3879, 67.7628, 66.2221, 65.0375, 67.3077, 64.8224, 64.3731, 65.2397, 66.2137, 63.1702, 68.7883, 63.5223, 62.7144, 64.7985, 62.9862, 62.7585, 64.2501, 63.8402, 62.5105, 63.4055, 63.2326, 65.6007, 60.9525, 63.7463, 60.8082, 63.7202, 61.105, 60.6387, 60.7032, 59.9789, 59.3324, 59.8414, 60.1869, 59.3707, 60.3457, 59.0354, 60.3173, 59.8865, 58.4265, 58.217, 59.1192, 60.7295, 60.6482, 64.0288, 60.2646, 57.7883, 58.6743, 57.2772, 60.2348, 57.966, 56.7707, 76.959, 56.854, 57.0097, 60.7359, 56.8798, 56.7713, 59.7314, 56.4445, 56.3595, 56.8958, 60.3193, 56.1602, 55.8443, 57.9681, 55.759, 55.7633, 55.7339]\n",
      "\n",
      "We are now training cross-validation set # 1\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 601.9350 - mean_squared_error: 601.9348 - val_loss: 223.5342 - val_mean_squared_error: 223.5343\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 188.2108 - mean_squared_error: 188.2109 - val_loss: 166.4576 - val_mean_squared_error: 166.4576\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 155.6936 - mean_squared_error: 155.6937 - val_loss: 148.0520 - val_mean_squared_error: 148.0520\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 140.4897 - mean_squared_error: 140.4897 - val_loss: 137.4597 - val_mean_squared_error: 137.4597\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 130.0486 - mean_squared_error: 130.0485 - val_loss: 124.6557 - val_mean_squared_error: 124.6557\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 123.0674 - mean_squared_error: 123.0675 - val_loss: 119.1472 - val_mean_squared_error: 119.1472\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 117.1410 - mean_squared_error: 117.1409 - val_loss: 126.7025 - val_mean_squared_error: 126.7024\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 112.3093 - mean_squared_error: 112.3092 - val_loss: 110.1998 - val_mean_squared_error: 110.1997\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 108.6138 - mean_squared_error: 108.6138 - val_loss: 105.6603 - val_mean_squared_error: 105.6603\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 105.3435 - mean_squared_error: 105.3435 - val_loss: 102.0659 - val_mean_squared_error: 102.0659\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 102.2044 - mean_squared_error: 102.2044 - val_loss: 100.4736 - val_mean_squared_error: 100.4736\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 100.0433 - mean_squared_error: 100.0432 - val_loss: 103.3484 - val_mean_squared_error: 103.3484\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 98.0163 - mean_squared_error: 98.0162 - val_loss: 100.0711 - val_mean_squared_error: 100.0711\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 96.2485 - mean_squared_error: 96.2484 - val_loss: 94.9878 - val_mean_squared_error: 94.9878\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 11s 490us/step - loss: 94.0653 - mean_squared_error: 94.0653 - val_loss: 95.7285 - val_mean_squared_error: 95.7285\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 92.4237 - mean_squared_error: 92.4237 - val_loss: 91.5396 - val_mean_squared_error: 91.5396\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 90.9243 - mean_squared_error: 90.9242 - val_loss: 89.8491 - val_mean_squared_error: 89.8491\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 88.9363 - mean_squared_error: 88.9363 - val_loss: 88.7805 - val_mean_squared_error: 88.7805\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 87.9170 - mean_squared_error: 87.9170 - val_loss: 86.4727 - val_mean_squared_error: 86.4727\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 86.9276 - mean_squared_error: 86.9276 - val_loss: 84.9229 - val_mean_squared_error: 84.9229\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 85.1779 - mean_squared_error: 85.1779 - val_loss: 84.7529 - val_mean_squared_error: 84.7529\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 84.2140 - mean_squared_error: 84.2140 - val_loss: 85.6223 - val_mean_squared_error: 85.6223\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 83.2687 - mean_squared_error: 83.2687 - val_loss: 82.1923 - val_mean_squared_error: 82.1923\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 82.3732 - mean_squared_error: 82.3732 - val_loss: 81.4232 - val_mean_squared_error: 81.4232\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 81.2573 - mean_squared_error: 81.2573 - val_loss: 80.3628 - val_mean_squared_error: 80.3628\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 80.3947 - mean_squared_error: 80.3948 - val_loss: 80.5910 - val_mean_squared_error: 80.5909\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 79.5218 - mean_squared_error: 79.5218 - val_loss: 81.5812 - val_mean_squared_error: 81.5812\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 78.5924 - mean_squared_error: 78.5925 - val_loss: 79.1535 - val_mean_squared_error: 79.1535\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 77.9211 - mean_squared_error: 77.9211 - val_loss: 81.1056 - val_mean_squared_error: 81.1055\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 77.5143 - mean_squared_error: 77.5143 - val_loss: 95.1034 - val_mean_squared_error: 95.1034\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 76.5795 - mean_squared_error: 76.5795 - val_loss: 76.1747 - val_mean_squared_error: 76.1747\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 75.6633 - mean_squared_error: 75.6633 - val_loss: 76.4583 - val_mean_squared_error: 76.4583\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 75.3200 - mean_squared_error: 75.3201 - val_loss: 75.0505 - val_mean_squared_error: 75.0505\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 74.4743 - mean_squared_error: 74.4743 - val_loss: 75.2201 - val_mean_squared_error: 75.2201\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 73.9190 - mean_squared_error: 73.9190 - val_loss: 76.2603 - val_mean_squared_error: 76.2603\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 73.3913 - mean_squared_error: 73.3913 - val_loss: 76.2189 - val_mean_squared_error: 76.2189\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 72.6734 - mean_squared_error: 72.6734 - val_loss: 72.5828 - val_mean_squared_error: 72.5828\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 72.0674 - mean_squared_error: 72.0674 - val_loss: 75.0986 - val_mean_squared_error: 75.0985\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 71.6187 - mean_squared_error: 71.6187 - val_loss: 72.2468 - val_mean_squared_error: 72.2468\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 71.3267 - mean_squared_error: 71.3268 - val_loss: 71.8372 - val_mean_squared_error: 71.8371\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 70.4899 - mean_squared_error: 70.4898 - val_loss: 74.6352 - val_mean_squared_error: 74.6352\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 70.4312 - mean_squared_error: 70.4311 - val_loss: 76.6117 - val_mean_squared_error: 76.6117\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 69.8619 - mean_squared_error: 69.8619 - val_loss: 70.9182 - val_mean_squared_error: 70.9182\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 69.4304 - mean_squared_error: 69.4304 - val_loss: 76.3160 - val_mean_squared_error: 76.3160\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 69.0030 - mean_squared_error: 69.0030 - val_loss: 69.6456 - val_mean_squared_error: 69.6457\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 68.4699 - mean_squared_error: 68.4698 - val_loss: 70.8641 - val_mean_squared_error: 70.8640\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 68.3932 - mean_squared_error: 68.3933 - val_loss: 71.2087 - val_mean_squared_error: 71.2087\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 67.8756 - mean_squared_error: 67.8756 - val_loss: 68.8077 - val_mean_squared_error: 68.8077\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 67.4460 - mean_squared_error: 67.4460 - val_loss: 69.3621 - val_mean_squared_error: 69.3621\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 67.4150 - mean_squared_error: 67.4150 - val_loss: 68.1291 - val_mean_squared_error: 68.1291\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 67.3223 - mean_squared_error: 67.3224 - val_loss: 67.5477 - val_mean_squared_error: 67.5477\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 11s 493us/step - loss: 66.2426 - mean_squared_error: 66.2426 - val_loss: 67.2897 - val_mean_squared_error: 67.2897\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 66.3417 - mean_squared_error: 66.3416 - val_loss: 67.9344 - val_mean_squared_error: 67.9344\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 65.9548 - mean_squared_error: 65.9548 - val_loss: 68.6789 - val_mean_squared_error: 68.6789\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 65.5381 - mean_squared_error: 65.5381 - val_loss: 66.6113 - val_mean_squared_error: 66.6113\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 65.4277 - mean_squared_error: 65.4278 - val_loss: 66.5253 - val_mean_squared_error: 66.5253\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 65.0695 - mean_squared_error: 65.0696 - val_loss: 71.1844 - val_mean_squared_error: 71.1844\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 64.8343 - mean_squared_error: 64.8343 - val_loss: 67.2803 - val_mean_squared_error: 67.2803\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 64.4231 - mean_squared_error: 64.4231 - val_loss: 65.5883 - val_mean_squared_error: 65.5883\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.3236 - mean_squared_error: 64.3236 - val_loss: 66.0539 - val_mean_squared_error: 66.0539\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 64.0791 - mean_squared_error: 64.0791 - val_loss: 65.7402 - val_mean_squared_error: 65.7402\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 63.9650 - mean_squared_error: 63.9650 - val_loss: 67.2694 - val_mean_squared_error: 67.2695\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 63.4330 - mean_squared_error: 63.4330 - val_loss: 68.5942 - val_mean_squared_error: 68.5942\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 63.2646 - mean_squared_error: 63.2646 - val_loss: 71.3398 - val_mean_squared_error: 71.3398\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 11s 492us/step - loss: 63.2068 - mean_squared_error: 63.2068 - val_loss: 64.2902 - val_mean_squared_error: 64.2903\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 62.9214 - mean_squared_error: 62.9213 - val_loss: 64.7783 - val_mean_squared_error: 64.7783\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 491us/step - loss: 62.8116 - mean_squared_error: 62.8116 - val_loss: 64.5249 - val_mean_squared_error: 64.5249\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 62.4671 - mean_squared_error: 62.4671 - val_loss: 64.1045 - val_mean_squared_error: 64.1045\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 62.4151 - mean_squared_error: 62.4151 - val_loss: 64.2548 - val_mean_squared_error: 64.2548\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 62.0624 - mean_squared_error: 62.0624 - val_loss: 65.1894 - val_mean_squared_error: 65.1894\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 62.0173 - mean_squared_error: 62.0173 - val_loss: 64.6212 - val_mean_squared_error: 64.6212\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.7931 - mean_squared_error: 61.7931 - val_loss: 63.1938 - val_mean_squared_error: 63.1938\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 61.6531 - mean_squared_error: 61.6532 - val_loss: 64.9017 - val_mean_squared_error: 64.9017\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 61.3246 - mean_squared_error: 61.3246 - val_loss: 65.1613 - val_mean_squared_error: 65.1613\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 61.1761 - mean_squared_error: 61.1761 - val_loss: 63.2238 - val_mean_squared_error: 63.2238\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 61.0872 - mean_squared_error: 61.0872 - val_loss: 62.9058 - val_mean_squared_error: 62.9058\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 60.8083 - mean_squared_error: 60.8083 - val_loss: 66.7313 - val_mean_squared_error: 66.7312\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.7699 - mean_squared_error: 60.7698 - val_loss: 62.1245 - val_mean_squared_error: 62.1245\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 60.6458 - mean_squared_error: 60.6458 - val_loss: 64.2762 - val_mean_squared_error: 64.2762\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 60.4882 - mean_squared_error: 60.4882 - val_loss: 62.0540 - val_mean_squared_error: 62.0540\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 60.2783 - mean_squared_error: 60.2783 - val_loss: 61.9151 - val_mean_squared_error: 61.9151\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 60.2837 - mean_squared_error: 60.2837 - val_loss: 61.8210 - val_mean_squared_error: 61.8210\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.7710 - mean_squared_error: 59.7711 - val_loss: 64.4078 - val_mean_squared_error: 64.4078\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 59.8850 - mean_squared_error: 59.8850 - val_loss: 61.8739 - val_mean_squared_error: 61.8738\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 59.7485 - mean_squared_error: 59.7485 - val_loss: 62.4580 - val_mean_squared_error: 62.4580\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 59.8691 - mean_squared_error: 59.8691 - val_loss: 63.2815 - val_mean_squared_error: 63.2815\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 59.2063 - mean_squared_error: 59.2063 - val_loss: 63.7751 - val_mean_squared_error: 63.7751\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 59.8936 - mean_squared_error: 59.8936 - val_loss: 61.1041 - val_mean_squared_error: 61.1041\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 58.9371 - mean_squared_error: 58.9372 - val_loss: 67.6932 - val_mean_squared_error: 67.6932\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.9639 - mean_squared_error: 58.9639 - val_loss: 62.5693 - val_mean_squared_error: 62.5693\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 59.1939 - mean_squared_error: 59.1939 - val_loss: 62.1288 - val_mean_squared_error: 62.1288\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 58.8775 - mean_squared_error: 58.8775 - val_loss: 60.7644 - val_mean_squared_error: 60.7644\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.5909 - mean_squared_error: 58.5909 - val_loss: 61.5077 - val_mean_squared_error: 61.5077\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 58.7798 - mean_squared_error: 58.7799 - val_loss: 61.8469 - val_mean_squared_error: 61.8469\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.3620 - mean_squared_error: 58.3620 - val_loss: 61.8543 - val_mean_squared_error: 61.8543\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 58.4403 - mean_squared_error: 58.4403 - val_loss: 60.7061 - val_mean_squared_error: 60.7061\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 58.1715 - mean_squared_error: 58.1715 - val_loss: 60.3560 - val_mean_squared_error: 60.3561\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.1850 - mean_squared_error: 58.1850 - val_loss: 60.6177 - val_mean_squared_error: 60.6177\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 58.1595 - mean_squared_error: 58.1595 - val_loss: 60.4573 - val_mean_squared_error: 60.4573\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.9117 - mean_squared_error: 57.9117 - val_loss: 61.2332 - val_mean_squared_error: 61.2332\n",
      "Training Loss: [601.935, 188.2108, 155.6936, 140.4897, 130.0486, 123.0674, 117.141, 112.3093, 108.6138, 105.3435, 102.2044, 100.0433, 98.0163, 96.2485, 94.0653, 92.4237, 90.9243, 88.9363, 87.917, 86.9276, 85.1779, 84.214, 83.2687, 82.3732, 81.2573, 80.3947, 79.5218, 78.5924, 77.9211, 77.5143, 76.5795, 75.6633, 75.32, 74.4743, 73.919, 73.3913, 72.6734, 72.0674, 71.6187, 71.3267, 70.4899, 70.4312, 69.8619, 69.4304, 69.003, 68.4699, 68.3932, 67.8756, 67.446, 67.415, 67.3223, 66.2426, 66.3417, 65.9548, 65.5381, 65.4277, 65.0695, 64.8343, 64.4231, 64.3236, 64.0791, 63.965, 63.433, 63.2646, 63.2068, 62.9214, 62.8116, 62.4671, 62.4151, 62.0624, 62.0173, 61.7931, 61.6531, 61.3246, 61.1761, 61.0872, 60.8083, 60.7699, 60.6458, 60.4882, 60.2783, 60.2837, 59.771, 59.885, 59.7485, 59.8691, 59.2063, 59.8936, 58.9371, 58.9639, 59.1939, 58.8775, 58.5909, 58.7798, 58.362, 58.4403, 58.1715, 58.185, 58.1595, 57.9117]\n",
      "Validation Loss: [223.5342, 166.4576, 148.052, 137.4597, 124.6557, 119.1472, 126.7025, 110.1998, 105.6603, 102.0659, 100.4736, 103.3484, 100.0711, 94.9878, 95.7285, 91.5396, 89.8491, 88.7805, 86.4727, 84.9229, 84.7529, 85.6223, 82.1923, 81.4232, 80.3628, 80.591, 81.5812, 79.1535, 81.1056, 95.1034, 76.1747, 76.4583, 75.0505, 75.2201, 76.2603, 76.2189, 72.5828, 75.0986, 72.2468, 71.8372, 74.6352, 76.6117, 70.9182, 76.316, 69.6456, 70.8641, 71.2087, 68.8077, 69.3621, 68.1291, 67.5477, 67.2897, 67.9344, 68.6789, 66.6113, 66.5253, 71.1844, 67.2803, 65.5883, 66.0539, 65.7402, 67.2694, 68.5942, 71.3398, 64.2902, 64.7783, 64.5249, 64.1045, 64.2548, 65.1894, 64.6212, 63.1938, 64.9017, 65.1613, 63.2238, 62.9058, 66.7313, 62.1245, 64.2762, 62.054, 61.9151, 61.821, 64.4078, 61.8739, 62.458, 63.2815, 63.7751, 61.1041, 67.6932, 62.5693, 62.1288, 60.7644, 61.5077, 61.8469, 61.8543, 60.7061, 60.356, 60.6177, 60.4573, 61.2332]\n",
      "\n",
      "We are now training cross-validation set # 2\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 12s 557us/step - loss: 477.9667 - mean_squared_error: 477.9663 - val_loss: 196.7804 - val_mean_squared_error: 196.7805\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 175.3751 - mean_squared_error: 175.3752 - val_loss: 159.2348 - val_mean_squared_error: 159.2348\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 149.8603 - mean_squared_error: 149.8603 - val_loss: 138.9417 - val_mean_squared_error: 138.9417\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 134.3503 - mean_squared_error: 134.3502 - val_loss: 128.1606 - val_mean_squared_error: 128.1606\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 12s 544us/step - loss: 124.6392 - mean_squared_error: 124.6392 - val_loss: 126.0140 - val_mean_squared_error: 126.0140\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 118.4798 - mean_squared_error: 118.4798 - val_loss: 118.7377 - val_mean_squared_error: 118.7377\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 113.8729 - mean_squared_error: 113.8729 - val_loss: 112.5892 - val_mean_squared_error: 112.5892\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 110.1023 - mean_squared_error: 110.1023 - val_loss: 106.9291 - val_mean_squared_error: 106.9291\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 107.2391 - mean_squared_error: 107.2391 - val_loss: 105.7432 - val_mean_squared_error: 105.7432\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 104.7190 - mean_squared_error: 104.7189 - val_loss: 107.1554 - val_mean_squared_error: 107.1554\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 102.4794 - mean_squared_error: 102.4793 - val_loss: 111.0660 - val_mean_squared_error: 111.0660\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 100.1517 - mean_squared_error: 100.1517 - val_loss: 97.7223 - val_mean_squared_error: 97.7223\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 98.1007 - mean_squared_error: 98.1007 - val_loss: 96.2876 - val_mean_squared_error: 96.2876\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 96.5493 - mean_squared_error: 96.5493 - val_loss: 97.5475 - val_mean_squared_error: 97.5475\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 94.2227 - mean_squared_error: 94.2227 - val_loss: 107.7442 - val_mean_squared_error: 107.7442\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 92.7406 - mean_squared_error: 92.7405 - val_loss: 90.8545 - val_mean_squared_error: 90.8545\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 91.1363 - mean_squared_error: 91.1363 - val_loss: 93.5703 - val_mean_squared_error: 93.5703\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 89.4043 - mean_squared_error: 89.4044 - val_loss: 88.8384 - val_mean_squared_error: 88.8384\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 88.4837 - mean_squared_error: 88.4837 - val_loss: 87.0096 - val_mean_squared_error: 87.0096\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 12s 533us/step - loss: 87.5575 - mean_squared_error: 87.5575 - val_loss: 86.5117 - val_mean_squared_error: 86.5117\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 85.2670 - mean_squared_error: 85.2670 - val_loss: 109.6907 - val_mean_squared_error: 109.6907\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 85.0572 - mean_squared_error: 85.0572 - val_loss: 83.4476 - val_mean_squared_error: 83.4477\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 83.8187 - mean_squared_error: 83.8187 - val_loss: 83.1615 - val_mean_squared_error: 83.1615\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 82.7999 - mean_squared_error: 82.7999 - val_loss: 84.6384 - val_mean_squared_error: 84.6384\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 82.1749 - mean_squared_error: 82.1750 - val_loss: 81.0360 - val_mean_squared_error: 81.0360\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 80.9230 - mean_squared_error: 80.9229 - val_loss: 82.4902 - val_mean_squared_error: 82.4902\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 80.3254 - mean_squared_error: 80.3254 - val_loss: 85.5303 - val_mean_squared_error: 85.5303\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 79.6638 - mean_squared_error: 79.6638 - val_loss: 79.4272 - val_mean_squared_error: 79.4272\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 78.8697 - mean_squared_error: 78.8698 - val_loss: 78.2470 - val_mean_squared_error: 78.2470\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 78.0575 - mean_squared_error: 78.0575 - val_loss: 78.6971 - val_mean_squared_error: 78.6971\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 12s 533us/step - loss: 77.5897 - mean_squared_error: 77.5898 - val_loss: 76.9365 - val_mean_squared_error: 76.9365\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 76.7506 - mean_squared_error: 76.7507 - val_loss: 85.5268 - val_mean_squared_error: 85.5267\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 76.2663 - mean_squared_error: 76.2663 - val_loss: 75.5004 - val_mean_squared_error: 75.5004\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 75.4509 - mean_squared_error: 75.4509 - val_loss: 74.9233 - val_mean_squared_error: 74.9233\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 74.8467 - mean_squared_error: 74.8466 - val_loss: 74.6638 - val_mean_squared_error: 74.6638\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 74.2809 - mean_squared_error: 74.2810 - val_loss: 73.9875 - val_mean_squared_error: 73.9875\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 12s 530us/step - loss: 73.5411 - mean_squared_error: 73.5411 - val_loss: 73.2308 - val_mean_squared_error: 73.2309\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 11s 516us/step - loss: 73.0898 - mean_squared_error: 73.0898 - val_loss: 77.3246 - val_mean_squared_error: 77.3246\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 72.6822 - mean_squared_error: 72.6822 - val_loss: 76.0904 - val_mean_squared_error: 76.0904\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 72.1297 - mean_squared_error: 72.1297 - val_loss: 72.4076 - val_mean_squared_error: 72.4076\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 71.7546 - mean_squared_error: 71.7547 - val_loss: 71.9688 - val_mean_squared_error: 71.9688\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 70.8749 - mean_squared_error: 70.8748 - val_loss: 71.6000 - val_mean_squared_error: 71.6000\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 70.8996 - mean_squared_error: 70.8996 - val_loss: 70.6254 - val_mean_squared_error: 70.6254\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 69.9518 - mean_squared_error: 69.9518 - val_loss: 71.2494 - val_mean_squared_error: 71.2494\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 69.6738 - mean_squared_error: 69.6738 - val_loss: 70.2948 - val_mean_squared_error: 70.2948\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 69.2817 - mean_squared_error: 69.2817 - val_loss: 69.3487 - val_mean_squared_error: 69.3487\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 68.9797 - mean_squared_error: 68.9797 - val_loss: 72.7723 - val_mean_squared_error: 72.7723\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 68.5940 - mean_squared_error: 68.5940 - val_loss: 69.3008 - val_mean_squared_error: 69.3008\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 68.2657 - mean_squared_error: 68.2657 - val_loss: 68.9617 - val_mean_squared_error: 68.9617\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 67.7863 - mean_squared_error: 67.7864 - val_loss: 71.8843 - val_mean_squared_error: 71.8843\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 67.5444 - mean_squared_error: 67.5444 - val_loss: 69.8383 - val_mean_squared_error: 69.8383\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 67.3050 - mean_squared_error: 67.3050 - val_loss: 70.3216 - val_mean_squared_error: 70.3216\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 66.8723 - mean_squared_error: 66.8723 - val_loss: 74.2839 - val_mean_squared_error: 74.2839\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 66.7260 - mean_squared_error: 66.7260 - val_loss: 68.7126 - val_mean_squared_error: 68.7126\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 66.4614 - mean_squared_error: 66.4614 - val_loss: 69.6123 - val_mean_squared_error: 69.6124\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 66.1185 - mean_squared_error: 66.1185 - val_loss: 67.0318 - val_mean_squared_error: 67.0318\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 65.7969 - mean_squared_error: 65.7969 - val_loss: 67.8857 - val_mean_squared_error: 67.8857\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 11s 514us/step - loss: 65.6173 - mean_squared_error: 65.6173 - val_loss: 68.0503 - val_mean_squared_error: 68.0503\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 12s 538us/step - loss: 65.4465 - mean_squared_error: 65.4464 - val_loss: 66.0097 - val_mean_squared_error: 66.0097\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 12s 536us/step - loss: 65.1330 - mean_squared_error: 65.1330 - val_loss: 66.6964 - val_mean_squared_error: 66.6964\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 12s 530us/step - loss: 64.8352 - mean_squared_error: 64.8353 - val_loss: 66.0654 - val_mean_squared_error: 66.0654\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 64.7470 - mean_squared_error: 64.7470 - val_loss: 67.2984 - val_mean_squared_error: 67.2984\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 64.4931 - mean_squared_error: 64.4931 - val_loss: 66.6888 - val_mean_squared_error: 66.6888\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 64.6032 - mean_squared_error: 64.6032 - val_loss: 68.1593 - val_mean_squared_error: 68.1594\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.8195 - mean_squared_error: 63.8195 - val_loss: 65.4167 - val_mean_squared_error: 65.4167\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 63.7735 - mean_squared_error: 63.7735 - val_loss: 69.2442 - val_mean_squared_error: 69.2442\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.9170 - mean_squared_error: 63.9171 - val_loss: 64.9959 - val_mean_squared_error: 64.9959\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 11s 515us/step - loss: 63.4588 - mean_squared_error: 63.4587 - val_loss: 64.9888 - val_mean_squared_error: 64.9888\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.3035 - mean_squared_error: 63.3035 - val_loss: 65.8333 - val_mean_squared_error: 65.8333\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 63.3300 - mean_squared_error: 63.3300 - val_loss: 68.4084 - val_mean_squared_error: 68.4084\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 63.1474 - mean_squared_error: 63.1473 - val_loss: 64.5784 - val_mean_squared_error: 64.5784\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 62.4635 - mean_squared_error: 62.4635 - val_loss: 65.6435 - val_mean_squared_error: 65.6435\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 62.4840 - mean_squared_error: 62.4839 - val_loss: 65.0427 - val_mean_squared_error: 65.0427\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 62.3740 - mean_squared_error: 62.3741 - val_loss: 64.1226 - val_mean_squared_error: 64.1226\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 62.2987 - mean_squared_error: 62.2987 - val_loss: 64.2768 - val_mean_squared_error: 64.2768\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 62.6072 - mean_squared_error: 62.6072 - val_loss: 63.8071 - val_mean_squared_error: 63.8071\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 61.4938 - mean_squared_error: 61.4938 - val_loss: 63.0523 - val_mean_squared_error: 63.0523\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 61.9717 - mean_squared_error: 61.9717 - val_loss: 63.1180 - val_mean_squared_error: 63.1180\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 61.4784 - mean_squared_error: 61.4784 - val_loss: 63.8831 - val_mean_squared_error: 63.8831\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 61.5778 - mean_squared_error: 61.5778 - val_loss: 63.1283 - val_mean_squared_error: 63.1283\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 61.2906 - mean_squared_error: 61.2906 - val_loss: 63.6305 - val_mean_squared_error: 63.6305\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 61.1350 - mean_squared_error: 61.1351 - val_loss: 62.9033 - val_mean_squared_error: 62.9033\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 61.0975 - mean_squared_error: 61.0976 - val_loss: 62.5437 - val_mean_squared_error: 62.5437\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 61.0402 - mean_squared_error: 61.0402 - val_loss: 62.3970 - val_mean_squared_error: 62.3970\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 12s 527us/step - loss: 60.6990 - mean_squared_error: 60.6990 - val_loss: 63.1583 - val_mean_squared_error: 63.1583\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 60.5843 - mean_squared_error: 60.5844 - val_loss: 62.9796 - val_mean_squared_error: 62.9796\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 60.4908 - mean_squared_error: 60.4908 - val_loss: 62.8622 - val_mean_squared_error: 62.8622\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 60.5053 - mean_squared_error: 60.5053 - val_loss: 62.3227 - val_mean_squared_error: 62.3227\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 11s 516us/step - loss: 60.1803 - mean_squared_error: 60.1803 - val_loss: 61.8733 - val_mean_squared_error: 61.8734\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 60.0865 - mean_squared_error: 60.0865 - val_loss: 62.8287 - val_mean_squared_error: 62.8287\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 60.0539 - mean_squared_error: 60.0539 - val_loss: 64.8841 - val_mean_squared_error: 64.8841\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 60.0141 - mean_squared_error: 60.0141 - val_loss: 65.2551 - val_mean_squared_error: 65.2551\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 59.9743 - mean_squared_error: 59.9743 - val_loss: 61.9595 - val_mean_squared_error: 61.9595\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 59.5449 - mean_squared_error: 59.5449 - val_loss: 61.6968 - val_mean_squared_error: 61.6968\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 59.5035 - mean_squared_error: 59.5035 - val_loss: 62.1016 - val_mean_squared_error: 62.1016\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 59.5324 - mean_squared_error: 59.5324 - val_loss: 61.2316 - val_mean_squared_error: 61.2316\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 59.2588 - mean_squared_error: 59.2588 - val_loss: 61.9122 - val_mean_squared_error: 61.9122\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 59.1990 - mean_squared_error: 59.1990 - val_loss: 62.6285 - val_mean_squared_error: 62.6285\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 59.1966 - mean_squared_error: 59.1966 - val_loss: 61.3857 - val_mean_squared_error: 61.3858\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 58.9166 - mean_squared_error: 58.9165 - val_loss: 74.5219 - val_mean_squared_error: 74.5219\n",
      "Training Loss: [477.9667, 175.3751, 149.8603, 134.3503, 124.6392, 118.4798, 113.8729, 110.1023, 107.2391, 104.719, 102.4794, 100.1517, 98.1007, 96.5493, 94.2227, 92.7406, 91.1363, 89.4043, 88.4837, 87.5575, 85.267, 85.0572, 83.8187, 82.7999, 82.1749, 80.923, 80.3254, 79.6638, 78.8697, 78.0575, 77.5897, 76.7506, 76.2663, 75.4509, 74.8467, 74.2809, 73.5411, 73.0898, 72.6822, 72.1297, 71.7546, 70.8749, 70.8996, 69.9518, 69.6738, 69.2817, 68.9797, 68.594, 68.2657, 67.7863, 67.5444, 67.305, 66.8723, 66.726, 66.4614, 66.1185, 65.7969, 65.6173, 65.4465, 65.133, 64.8352, 64.747, 64.4931, 64.6032, 63.8195, 63.7735, 63.917, 63.4588, 63.3035, 63.33, 63.1474, 62.4635, 62.484, 62.374, 62.2987, 62.6072, 61.4938, 61.9717, 61.4784, 61.5778, 61.2906, 61.135, 61.0975, 61.0402, 60.699, 60.5843, 60.4908, 60.5053, 60.1803, 60.0865, 60.0539, 60.0141, 59.9743, 59.5449, 59.5035, 59.5324, 59.2588, 59.199, 59.1966, 58.9166]\n",
      "Validation Loss: [196.7804, 159.2348, 138.9417, 128.1606, 126.014, 118.7377, 112.5892, 106.9291, 105.7432, 107.1554, 111.066, 97.7223, 96.2876, 97.5475, 107.7442, 90.8545, 93.5703, 88.8384, 87.0096, 86.5117, 109.6907, 83.4476, 83.1615, 84.6384, 81.036, 82.4902, 85.5303, 79.4272, 78.247, 78.6971, 76.9365, 85.5268, 75.5004, 74.9233, 74.6638, 73.9875, 73.2308, 77.3246, 76.0904, 72.4076, 71.9688, 71.6, 70.6254, 71.2494, 70.2948, 69.3487, 72.7723, 69.3008, 68.9617, 71.8843, 69.8383, 70.3216, 74.2839, 68.7126, 69.6123, 67.0318, 67.8857, 68.0503, 66.0097, 66.6964, 66.0654, 67.2984, 66.6888, 68.1593, 65.4167, 69.2442, 64.9959, 64.9888, 65.8333, 68.4084, 64.5784, 65.6435, 65.0427, 64.1226, 64.2768, 63.8071, 63.0523, 63.118, 63.8831, 63.1283, 63.6305, 62.9033, 62.5437, 62.397, 63.1583, 62.9796, 62.8622, 62.3227, 61.8733, 62.8287, 64.8841, 65.2551, 61.9595, 61.6968, 62.1016, 61.2316, 61.9122, 62.6285, 61.3857, 74.5219]\n",
      "\n",
      "We are now training cross-validation set # 3\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 12s 552us/step - loss: 568.6077 - mean_squared_error: 568.6078 - val_loss: 181.5859 - val_mean_squared_error: 181.5859\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 158.0966 - mean_squared_error: 158.0968 - val_loss: 146.3592 - val_mean_squared_error: 146.3592\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 134.6946 - mean_squared_error: 134.6947 - val_loss: 129.3194 - val_mean_squared_error: 129.3194\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 125.1523 - mean_squared_error: 125.1523 - val_loss: 121.1580 - val_mean_squared_error: 121.1580\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 119.1968 - mean_squared_error: 119.1968 - val_loss: 115.0678 - val_mean_squared_error: 115.0678\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 114.2413 - mean_squared_error: 114.2413 - val_loss: 110.9052 - val_mean_squared_error: 110.9051\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 110.6507 - mean_squared_error: 110.6507 - val_loss: 107.8495 - val_mean_squared_error: 107.8495\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 107.4347 - mean_squared_error: 107.4346 - val_loss: 116.3108 - val_mean_squared_error: 116.3108\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 105.4419 - mean_squared_error: 105.4418 - val_loss: 102.5233 - val_mean_squared_error: 102.5233\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 102.9646 - mean_squared_error: 102.9646 - val_loss: 101.6851 - val_mean_squared_error: 101.6851\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 516us/step - loss: 101.0281 - mean_squared_error: 101.0281 - val_loss: 98.0242 - val_mean_squared_error: 98.0242\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 11s 488us/step - loss: 98.8922 - mean_squared_error: 98.8922 - val_loss: 97.1235 - val_mean_squared_error: 97.1235\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 97.3357 - mean_squared_error: 97.3357 - val_loss: 95.4780 - val_mean_squared_error: 95.4781\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 95.8909 - mean_squared_error: 95.8909 - val_loss: 95.3722 - val_mean_squared_error: 95.3721\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 94.7275 - mean_squared_error: 94.7275 - val_loss: 100.3248 - val_mean_squared_error: 100.3248\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 93.0789 - mean_squared_error: 93.0789 - val_loss: 95.4847 - val_mean_squared_error: 95.4846\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 92.0660 - mean_squared_error: 92.0660 - val_loss: 91.6369 - val_mean_squared_error: 91.6369\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 90.6659 - mean_squared_error: 90.6659 - val_loss: 89.9805 - val_mean_squared_error: 89.9804\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 89.3419 - mean_squared_error: 89.3419 - val_loss: 90.9703 - val_mean_squared_error: 90.9703\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 88.4613 - mean_squared_error: 88.4613 - val_loss: 87.0620 - val_mean_squared_error: 87.0620\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 87.1949 - mean_squared_error: 87.1948 - val_loss: 85.5846 - val_mean_squared_error: 85.5846\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 86.4626 - mean_squared_error: 86.4625 - val_loss: 86.2589 - val_mean_squared_error: 86.2589\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 84.7927 - mean_squared_error: 84.7927 - val_loss: 83.9536 - val_mean_squared_error: 83.9536\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 84.3527 - mean_squared_error: 84.3527 - val_loss: 83.1230 - val_mean_squared_error: 83.1229\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 83.2744 - mean_squared_error: 83.2744 - val_loss: 82.2888 - val_mean_squared_error: 82.2888\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 82.3904 - mean_squared_error: 82.3904 - val_loss: 82.1236 - val_mean_squared_error: 82.1236\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 11s 488us/step - loss: 81.8071 - mean_squared_error: 81.8071 - val_loss: 81.2759 - val_mean_squared_error: 81.2759\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 80.7159 - mean_squared_error: 80.7159 - val_loss: 80.2754 - val_mean_squared_error: 80.2754\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 80.0341 - mean_squared_error: 80.0341 - val_loss: 80.0535 - val_mean_squared_error: 80.0535\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 79.2385 - mean_squared_error: 79.2384 - val_loss: 81.2652 - val_mean_squared_error: 81.2651\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 78.8616 - mean_squared_error: 78.8615 - val_loss: 81.1165 - val_mean_squared_error: 81.1165\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 77.7899 - mean_squared_error: 77.7898 - val_loss: 77.5715 - val_mean_squared_error: 77.5714\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 76.9035 - mean_squared_error: 76.9035 - val_loss: 76.8798 - val_mean_squared_error: 76.8798\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 76.6273 - mean_squared_error: 76.6272 - val_loss: 76.3899 - val_mean_squared_error: 76.3899\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 75.8509 - mean_squared_error: 75.8509 - val_loss: 76.4110 - val_mean_squared_error: 76.4110\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 75.3184 - mean_squared_error: 75.3184 - val_loss: 77.0226 - val_mean_squared_error: 77.0226\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 12s 539us/step - loss: 75.0774 - mean_squared_error: 75.0774 - val_loss: 76.6442 - val_mean_squared_error: 76.6442\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 74.5997 - mean_squared_error: 74.5998 - val_loss: 74.2513 - val_mean_squared_error: 74.2513\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 74.3675 - mean_squared_error: 74.3675 - val_loss: 82.2673 - val_mean_squared_error: 82.2672\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 73.1303 - mean_squared_error: 73.1302 - val_loss: 74.1409 - val_mean_squared_error: 74.1409\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 73.0371 - mean_squared_error: 73.0371 - val_loss: 73.7306 - val_mean_squared_error: 73.7306\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 72.5452 - mean_squared_error: 72.5452 - val_loss: 73.5944 - val_mean_squared_error: 73.5944\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 72.7825 - mean_squared_error: 72.7826 - val_loss: 80.8188 - val_mean_squared_error: 80.8188\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 71.5864 - mean_squared_error: 71.5864 - val_loss: 72.4081 - val_mean_squared_error: 72.4081\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 71.1554 - mean_squared_error: 71.1554 - val_loss: 73.1493 - val_mean_squared_error: 73.1493\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 71.3538 - mean_squared_error: 71.3538 - val_loss: 71.6217 - val_mean_squared_error: 71.6217\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 70.5270 - mean_squared_error: 70.5270 - val_loss: 73.1392 - val_mean_squared_error: 73.1392\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 70.5664 - mean_squared_error: 70.5664 - val_loss: 71.7512 - val_mean_squared_error: 71.7512\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 70.2673 - mean_squared_error: 70.2673 - val_loss: 70.2742 - val_mean_squared_error: 70.2742\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 69.6543 - mean_squared_error: 69.6543 - val_loss: 72.5627 - val_mean_squared_error: 72.5628\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 69.4411 - mean_squared_error: 69.4411 - val_loss: 70.3295 - val_mean_squared_error: 70.3295\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 69.0680 - mean_squared_error: 69.0680 - val_loss: 74.2224 - val_mean_squared_error: 74.2224\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 69.0868 - mean_squared_error: 69.0867 - val_loss: 70.6892 - val_mean_squared_error: 70.6892\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 68.8617 - mean_squared_error: 68.8617 - val_loss: 69.3094 - val_mean_squared_error: 69.3094\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 68.1614 - mean_squared_error: 68.1614 - val_loss: 72.6055 - val_mean_squared_error: 72.6055\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 68.1198 - mean_squared_error: 68.1199 - val_loss: 68.7856 - val_mean_squared_error: 68.7856\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 67.8311 - mean_squared_error: 67.8312 - val_loss: 70.3095 - val_mean_squared_error: 70.3095\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 67.7625 - mean_squared_error: 67.7626 - val_loss: 68.3546 - val_mean_squared_error: 68.3546\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 67.4190 - mean_squared_error: 67.4190 - val_loss: 69.2630 - val_mean_squared_error: 69.2630\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 67.0628 - mean_squared_error: 67.0628 - val_loss: 68.1408 - val_mean_squared_error: 68.1408\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 66.8649 - mean_squared_error: 66.8649 - val_loss: 68.1432 - val_mean_squared_error: 68.1432\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 66.7892 - mean_squared_error: 66.7892 - val_loss: 69.2352 - val_mean_squared_error: 69.2352\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 66.6196 - mean_squared_error: 66.6197 - val_loss: 67.7406 - val_mean_squared_error: 67.7406\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 12s 534us/step - loss: 66.2616 - mean_squared_error: 66.2616 - val_loss: 67.8356 - val_mean_squared_error: 67.8356\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 66.3603 - mean_squared_error: 66.3603 - val_loss: 68.9506 - val_mean_squared_error: 68.9506\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 65.7481 - mean_squared_error: 65.7481 - val_loss: 67.5087 - val_mean_squared_error: 67.5087\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 65.6780 - mean_squared_error: 65.6780 - val_loss: 74.3281 - val_mean_squared_error: 74.3281\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 65.4468 - mean_squared_error: 65.4468 - val_loss: 67.0379 - val_mean_squared_error: 67.0379\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 65.5117 - mean_squared_error: 65.5117 - val_loss: 66.5661 - val_mean_squared_error: 66.5661\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 12s 526us/step - loss: 65.1688 - mean_squared_error: 65.1689 - val_loss: 70.3802 - val_mean_squared_error: 70.3802\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 65.0821 - mean_squared_error: 65.0821 - val_loss: 68.0049 - val_mean_squared_error: 68.0049\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 64.8779 - mean_squared_error: 64.8780 - val_loss: 67.9134 - val_mean_squared_error: 67.9134\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 64.6608 - mean_squared_error: 64.6608 - val_loss: 66.9847 - val_mean_squared_error: 66.9847\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 64.4686 - mean_squared_error: 64.4686 - val_loss: 66.2988 - val_mean_squared_error: 66.2988\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 64.4619 - mean_squared_error: 64.4620 - val_loss: 67.2729 - val_mean_squared_error: 67.2729\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 64.1702 - mean_squared_error: 64.1702 - val_loss: 68.3146 - val_mean_squared_error: 68.3146\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 64.1331 - mean_squared_error: 64.1331 - val_loss: 66.6313 - val_mean_squared_error: 66.6313\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 63.9115 - mean_squared_error: 63.9115 - val_loss: 65.5503 - val_mean_squared_error: 65.5503\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 64.0329 - mean_squared_error: 64.0329 - val_loss: 65.9283 - val_mean_squared_error: 65.9283\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 63.4419 - mean_squared_error: 63.4419 - val_loss: 66.1721 - val_mean_squared_error: 66.1721\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 63.8265 - mean_squared_error: 63.8266 - val_loss: 64.9856 - val_mean_squared_error: 64.9856\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 63.1830 - mean_squared_error: 63.1830 - val_loss: 67.3795 - val_mean_squared_error: 67.3795\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 63.4254 - mean_squared_error: 63.4254 - val_loss: 65.0452 - val_mean_squared_error: 65.0452\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 63.2350 - mean_squared_error: 63.2350 - val_loss: 65.4526 - val_mean_squared_error: 65.4526\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 62.8901 - mean_squared_error: 62.8902 - val_loss: 64.8499 - val_mean_squared_error: 64.8500\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 62.7042 - mean_squared_error: 62.7042 - val_loss: 66.4750 - val_mean_squared_error: 66.4749\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 62.8404 - mean_squared_error: 62.8404 - val_loss: 76.7781 - val_mean_squared_error: 76.7781\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 62.5595 - mean_squared_error: 62.5595 - val_loss: 64.6590 - val_mean_squared_error: 64.6591\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 62.4299 - mean_squared_error: 62.4299 - val_loss: 65.1954 - val_mean_squared_error: 65.1955\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 62.8784 - mean_squared_error: 62.8784 - val_loss: 67.3685 - val_mean_squared_error: 67.3685\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 62.1349 - mean_squared_error: 62.1349 - val_loss: 63.7966 - val_mean_squared_error: 63.7966\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 62.0916 - mean_squared_error: 62.0916 - val_loss: 65.2644 - val_mean_squared_error: 65.2644\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 61.8985 - mean_squared_error: 61.8985 - val_loss: 67.6269 - val_mean_squared_error: 67.6268\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 61.9242 - mean_squared_error: 61.9242 - val_loss: 65.4091 - val_mean_squared_error: 65.4091\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 61.7362 - mean_squared_error: 61.7362 - val_loss: 63.7310 - val_mean_squared_error: 63.7310\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 61.7111 - mean_squared_error: 61.7111 - val_loss: 63.6752 - val_mean_squared_error: 63.6752\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 61.4432 - mean_squared_error: 61.4432 - val_loss: 63.0618 - val_mean_squared_error: 63.0618\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 61.2685 - mean_squared_error: 61.2685 - val_loss: 65.5803 - val_mean_squared_error: 65.5803\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 61.1491 - mean_squared_error: 61.1491 - val_loss: 63.2303 - val_mean_squared_error: 63.2303\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 61.4577 - mean_squared_error: 61.4578 - val_loss: 62.9539 - val_mean_squared_error: 62.9539\n",
      "Training Loss: [568.6077, 158.0966, 134.6946, 125.1523, 119.1968, 114.2413, 110.6507, 107.4347, 105.4419, 102.9646, 101.0281, 98.8922, 97.3357, 95.8909, 94.7275, 93.0789, 92.066, 90.6659, 89.3419, 88.4613, 87.1949, 86.4626, 84.7927, 84.3527, 83.2744, 82.3904, 81.8071, 80.7159, 80.0341, 79.2385, 78.8616, 77.7899, 76.9035, 76.6273, 75.8509, 75.3184, 75.0774, 74.5997, 74.3675, 73.1303, 73.0371, 72.5452, 72.7825, 71.5864, 71.1554, 71.3538, 70.527, 70.5664, 70.2673, 69.6543, 69.4411, 69.068, 69.0868, 68.8617, 68.1614, 68.1198, 67.8311, 67.7625, 67.419, 67.0628, 66.8649, 66.7892, 66.6196, 66.2616, 66.3603, 65.7481, 65.678, 65.4468, 65.5117, 65.1688, 65.0821, 64.8779, 64.6608, 64.4686, 64.4619, 64.1702, 64.1331, 63.9115, 64.0329, 63.4419, 63.8265, 63.183, 63.4254, 63.235, 62.8901, 62.7042, 62.8404, 62.5595, 62.4299, 62.8784, 62.1349, 62.0916, 61.8985, 61.9242, 61.7362, 61.7111, 61.4432, 61.2685, 61.1491, 61.4577]\n",
      "Validation Loss: [181.5859, 146.3592, 129.3194, 121.158, 115.0678, 110.9052, 107.8495, 116.3108, 102.5233, 101.6851, 98.0242, 97.1235, 95.478, 95.3722, 100.3248, 95.4847, 91.6369, 89.9805, 90.9703, 87.062, 85.5846, 86.2589, 83.9536, 83.123, 82.2888, 82.1236, 81.2759, 80.2754, 80.0535, 81.2652, 81.1165, 77.5715, 76.8798, 76.3899, 76.411, 77.0226, 76.6442, 74.2513, 82.2673, 74.1409, 73.7306, 73.5944, 80.8188, 72.4081, 73.1493, 71.6217, 73.1392, 71.7512, 70.2742, 72.5627, 70.3295, 74.2224, 70.6892, 69.3094, 72.6055, 68.7856, 70.3095, 68.3546, 69.263, 68.1408, 68.1432, 69.2352, 67.7406, 67.8356, 68.9506, 67.5087, 74.3281, 67.0379, 66.5661, 70.3802, 68.0049, 67.9134, 66.9847, 66.2988, 67.2729, 68.3146, 66.6313, 65.5503, 65.9283, 66.1721, 64.9856, 67.3795, 65.0452, 65.4526, 64.8499, 66.475, 76.7781, 64.659, 65.1954, 67.3685, 63.7966, 65.2644, 67.6269, 65.4091, 63.731, 63.6752, 63.0618, 65.5803, 63.2303, 62.9539]\n",
      "\n",
      "We are now training cross-validation set # 4\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 12s 547us/step - loss: 502.7647 - mean_squared_error: 502.7647 - val_loss: 186.4632 - val_mean_squared_error: 186.4632\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 499us/step - loss: 158.9478 - mean_squared_error: 158.9479 - val_loss: 144.5423 - val_mean_squared_error: 144.5423\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 132.2744 - mean_squared_error: 132.2744 - val_loss: 124.9097 - val_mean_squared_error: 124.9097\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 120.0074 - mean_squared_error: 120.0074 - val_loss: 115.1829 - val_mean_squared_error: 115.1829\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 113.6233 - mean_squared_error: 113.6233 - val_loss: 114.0601 - val_mean_squared_error: 114.0601\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 108.3427 - mean_squared_error: 108.3428 - val_loss: 105.7677 - val_mean_squared_error: 105.7677\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 105.2477 - mean_squared_error: 105.2477 - val_loss: 105.8306 - val_mean_squared_error: 105.8306\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 101.7269 - mean_squared_error: 101.7270 - val_loss: 101.8777 - val_mean_squared_error: 101.8777\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 98.8529 - mean_squared_error: 98.8529 - val_loss: 96.8781 - val_mean_squared_error: 96.8781\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 96.4256 - mean_squared_error: 96.4256 - val_loss: 98.3690 - val_mean_squared_error: 98.3690\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 94.1462 - mean_squared_error: 94.1461 - val_loss: 94.6653 - val_mean_squared_error: 94.6653\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 92.2767 - mean_squared_error: 92.2767 - val_loss: 91.1345 - val_mean_squared_error: 91.1345\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 90.4689 - mean_squared_error: 90.4689 - val_loss: 92.6405 - val_mean_squared_error: 92.6404\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 88.7135 - mean_squared_error: 88.7134 - val_loss: 87.3639 - val_mean_squared_error: 87.3640\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 87.3927 - mean_squared_error: 87.3926 - val_loss: 92.1147 - val_mean_squared_error: 92.1147\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 12s 535us/step - loss: 85.6750 - mean_squared_error: 85.6750 - val_loss: 85.3727 - val_mean_squared_error: 85.3727\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 85.1876 - mean_squared_error: 85.1876 - val_loss: 83.5568 - val_mean_squared_error: 83.5568\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 83.2395 - mean_squared_error: 83.2395 - val_loss: 83.3333 - val_mean_squared_error: 83.3333\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 82.5188 - mean_squared_error: 82.5189 - val_loss: 81.5047 - val_mean_squared_error: 81.5047\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 81.7761 - mean_squared_error: 81.7762 - val_loss: 81.3961 - val_mean_squared_error: 81.3961\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 80.4760 - mean_squared_error: 80.4760 - val_loss: 81.5607 - val_mean_squared_error: 81.5607\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 80.5300 - mean_squared_error: 80.5300 - val_loss: 79.3866 - val_mean_squared_error: 79.3866\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 78.5001 - mean_squared_error: 78.5001 - val_loss: 78.3801 - val_mean_squared_error: 78.3801\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 78.4984 - mean_squared_error: 78.4984 - val_loss: 78.1900 - val_mean_squared_error: 78.1900\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 78.0627 - mean_squared_error: 78.0627 - val_loss: 81.4645 - val_mean_squared_error: 81.4645\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 76.6672 - mean_squared_error: 76.6672 - val_loss: 79.9704 - val_mean_squared_error: 79.9704\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 11s 516us/step - loss: 76.3594 - mean_squared_error: 76.3595 - val_loss: 76.7050 - val_mean_squared_error: 76.7050\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 75.8516 - mean_squared_error: 75.8516 - val_loss: 78.3503 - val_mean_squared_error: 78.3503\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 11s 500us/step - loss: 74.8519 - mean_squared_error: 74.8519 - val_loss: 77.6506 - val_mean_squared_error: 77.6506\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 74.5448 - mean_squared_error: 74.5448 - val_loss: 77.7557 - val_mean_squared_error: 77.7557\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 74.1912 - mean_squared_error: 74.1913 - val_loss: 84.0257 - val_mean_squared_error: 84.0257\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 73.0378 - mean_squared_error: 73.0378 - val_loss: 74.1280 - val_mean_squared_error: 74.1280\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 73.1282 - mean_squared_error: 73.1282 - val_loss: 81.7968 - val_mean_squared_error: 81.7968\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 72.0359 - mean_squared_error: 72.0359 - val_loss: 72.6325 - val_mean_squared_error: 72.6324\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 71.9725 - mean_squared_error: 71.9725 - val_loss: 75.2642 - val_mean_squared_error: 75.2642\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 71.5221 - mean_squared_error: 71.5222 - val_loss: 72.7021 - val_mean_squared_error: 72.7021\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 71.1866 - mean_squared_error: 71.1867 - val_loss: 74.6487 - val_mean_squared_error: 74.6487\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 70.4843 - mean_squared_error: 70.4843 - val_loss: 70.9200 - val_mean_squared_error: 70.9200\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 70.1602 - mean_squared_error: 70.1602 - val_loss: 72.1991 - val_mean_squared_error: 72.1990\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 70.4457 - mean_squared_error: 70.4457 - val_loss: 70.7106 - val_mean_squared_error: 70.7106\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 69.0489 - mean_squared_error: 69.0490 - val_loss: 69.7021 - val_mean_squared_error: 69.7021\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 68.8016 - mean_squared_error: 68.8015 - val_loss: 72.3906 - val_mean_squared_error: 72.3906\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 12s 530us/step - loss: 68.6536 - mean_squared_error: 68.6536 - val_loss: 73.9623 - val_mean_squared_error: 73.9623\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 68.3812 - mean_squared_error: 68.3812 - val_loss: 69.0405 - val_mean_squared_error: 69.0406\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 12s 525us/step - loss: 67.9614 - mean_squared_error: 67.9614 - val_loss: 68.4725 - val_mean_squared_error: 68.4725\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 67.5700 - mean_squared_error: 67.5700 - val_loss: 70.0443 - val_mean_squared_error: 70.0442\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 67.1354 - mean_squared_error: 67.1354 - val_loss: 69.0610 - val_mean_squared_error: 69.0610\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 67.0371 - mean_squared_error: 67.0371 - val_loss: 69.6224 - val_mean_squared_error: 69.6224\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 11s 498us/step - loss: 66.6775 - mean_squared_error: 66.6775 - val_loss: 71.9929 - val_mean_squared_error: 71.9929\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 66.4616 - mean_squared_error: 66.4616 - val_loss: 67.9186 - val_mean_squared_error: 67.9186\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 66.1159 - mean_squared_error: 66.1159 - val_loss: 68.4553 - val_mean_squared_error: 68.4553\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 11s 500us/step - loss: 65.8513 - mean_squared_error: 65.8513 - val_loss: 72.5871 - val_mean_squared_error: 72.5871\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 65.5593 - mean_squared_error: 65.5592 - val_loss: 67.2232 - val_mean_squared_error: 67.2232\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 65.3058 - mean_squared_error: 65.3058 - val_loss: 66.2662 - val_mean_squared_error: 66.2662\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 64.8783 - mean_squared_error: 64.8783 - val_loss: 66.5989 - val_mean_squared_error: 66.5989\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 64.7664 - mean_squared_error: 64.7663 - val_loss: 65.8094 - val_mean_squared_error: 65.8094\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 64.4877 - mean_squared_error: 64.4876 - val_loss: 65.9276 - val_mean_squared_error: 65.9277\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 64.5962 - mean_squared_error: 64.5963 - val_loss: 69.5660 - val_mean_squared_error: 69.5660\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 63.9238 - mean_squared_error: 63.9238 - val_loss: 65.4534 - val_mean_squared_error: 65.4534\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 64.0077 - mean_squared_error: 64.0077 - val_loss: 64.9686 - val_mean_squared_error: 64.9685\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 63.4870 - mean_squared_error: 63.4870 - val_loss: 70.2550 - val_mean_squared_error: 70.2550\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 63.8203 - mean_squared_error: 63.8202 - val_loss: 64.1779 - val_mean_squared_error: 64.1779\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 63.0803 - mean_squared_error: 63.0803 - val_loss: 65.2219 - val_mean_squared_error: 65.2219\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 63.0995 - mean_squared_error: 63.0995 - val_loss: 64.8332 - val_mean_squared_error: 64.8332\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 62.8140 - mean_squared_error: 62.8140 - val_loss: 63.9766 - val_mean_squared_error: 63.9766\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 62.9586 - mean_squared_error: 62.9585 - val_loss: 64.9522 - val_mean_squared_error: 64.9522\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 62.1088 - mean_squared_error: 62.1088 - val_loss: 63.4877 - val_mean_squared_error: 63.4877\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 62.2360 - mean_squared_error: 62.2360 - val_loss: 63.9849 - val_mean_squared_error: 63.9849\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 62.1543 - mean_squared_error: 62.1543 - val_loss: 64.9695 - val_mean_squared_error: 64.9695\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 61.7331 - mean_squared_error: 61.7331 - val_loss: 63.3299 - val_mean_squared_error: 63.3299\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 61.7155 - mean_squared_error: 61.7155 - val_loss: 63.1560 - val_mean_squared_error: 63.1560\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 11s 515us/step - loss: 61.4577 - mean_squared_error: 61.4577 - val_loss: 67.8141 - val_mean_squared_error: 67.8141\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 61.7319 - mean_squared_error: 61.7319 - val_loss: 63.8155 - val_mean_squared_error: 63.8155\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 12s 528us/step - loss: 61.0254 - mean_squared_error: 61.0254 - val_loss: 65.6509 - val_mean_squared_error: 65.6509\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 60.9711 - mean_squared_error: 60.9712 - val_loss: 62.8954 - val_mean_squared_error: 62.8954\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 61.0591 - mean_squared_error: 61.0591 - val_loss: 62.1165 - val_mean_squared_error: 62.1165\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 60.6354 - mean_squared_error: 60.6353 - val_loss: 65.1113 - val_mean_squared_error: 65.1113\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 60.7663 - mean_squared_error: 60.7663 - val_loss: 63.6122 - val_mean_squared_error: 63.6122\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 60.4410 - mean_squared_error: 60.4410 - val_loss: 62.3076 - val_mean_squared_error: 62.3076\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 60.8060 - mean_squared_error: 60.8059 - val_loss: 63.2036 - val_mean_squared_error: 63.2036\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 59.8265 - mean_squared_error: 59.8265 - val_loss: 62.7748 - val_mean_squared_error: 62.7748\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 60.1132 - mean_squared_error: 60.1132 - val_loss: 62.7787 - val_mean_squared_error: 62.7787\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 59.9136 - mean_squared_error: 59.9137 - val_loss: 61.3949 - val_mean_squared_error: 61.3949\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 59.9842 - mean_squared_error: 59.9842 - val_loss: 61.1910 - val_mean_squared_error: 61.1910\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 59.2827 - mean_squared_error: 59.2827 - val_loss: 62.0271 - val_mean_squared_error: 62.0271\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 59.6360 - mean_squared_error: 59.6360 - val_loss: 61.9046 - val_mean_squared_error: 61.9046\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 522us/step - loss: 59.4468 - mean_squared_error: 59.4468 - val_loss: 61.4345 - val_mean_squared_error: 61.4345\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 59.1326 - mean_squared_error: 59.1326 - val_loss: 61.4483 - val_mean_squared_error: 61.4483\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 59.0620 - mean_squared_error: 59.0619 - val_loss: 62.5084 - val_mean_squared_error: 62.5084\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 59.1885 - mean_squared_error: 59.1885 - val_loss: 62.8359 - val_mean_squared_error: 62.8359\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 58.8012 - mean_squared_error: 58.8012 - val_loss: 60.9646 - val_mean_squared_error: 60.9646\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 58.8092 - mean_squared_error: 58.8092 - val_loss: 63.6216 - val_mean_squared_error: 63.6216\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 58.6877 - mean_squared_error: 58.6877 - val_loss: 60.6409 - val_mean_squared_error: 60.6409\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 58.6090 - mean_squared_error: 58.6090 - val_loss: 62.5058 - val_mean_squared_error: 62.5058\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 58.4613 - mean_squared_error: 58.4613 - val_loss: 61.1453 - val_mean_squared_error: 61.1453\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 501us/step - loss: 58.2736 - mean_squared_error: 58.2735 - val_loss: 59.9347 - val_mean_squared_error: 59.9347\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 58.6858 - mean_squared_error: 58.6858 - val_loss: 59.7559 - val_mean_squared_error: 59.7559\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 57.9736 - mean_squared_error: 57.9736 - val_loss: 61.8588 - val_mean_squared_error: 61.8588\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 12s 531us/step - loss: 57.9403 - mean_squared_error: 57.9402 - val_loss: 60.1386 - val_mean_squared_error: 60.1386\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 57.9353 - mean_squared_error: 57.9353 - val_loss: 62.3497 - val_mean_squared_error: 62.3497\n",
      "Training Loss: [502.7647, 158.9478, 132.2744, 120.0074, 113.6233, 108.3427, 105.2477, 101.7269, 98.8529, 96.4256, 94.1462, 92.2767, 90.4689, 88.7135, 87.3927, 85.675, 85.1876, 83.2395, 82.5188, 81.7761, 80.476, 80.53, 78.5001, 78.4984, 78.0627, 76.6672, 76.3594, 75.8516, 74.8519, 74.5448, 74.1912, 73.0378, 73.1282, 72.0359, 71.9725, 71.5221, 71.1866, 70.4843, 70.1602, 70.4457, 69.0489, 68.8016, 68.6536, 68.3812, 67.9614, 67.57, 67.1354, 67.0371, 66.6775, 66.4616, 66.1159, 65.8513, 65.5593, 65.3058, 64.8783, 64.7664, 64.4877, 64.5962, 63.9238, 64.0077, 63.487, 63.8203, 63.0803, 63.0995, 62.814, 62.9586, 62.1088, 62.236, 62.1543, 61.7331, 61.7155, 61.4577, 61.7319, 61.0254, 60.9711, 61.0591, 60.6354, 60.7663, 60.441, 60.806, 59.8265, 60.1132, 59.9136, 59.9842, 59.2827, 59.636, 59.4468, 59.1326, 59.062, 59.1885, 58.8012, 58.8092, 58.6877, 58.609, 58.4613, 58.2736, 58.6858, 57.9736, 57.9403, 57.9353]\n",
      "Validation Loss: [186.4632, 144.5423, 124.9097, 115.1829, 114.0601, 105.7677, 105.8306, 101.8777, 96.8781, 98.369, 94.6653, 91.1345, 92.6405, 87.3639, 92.1147, 85.3727, 83.5568, 83.3333, 81.5047, 81.3961, 81.5607, 79.3866, 78.3801, 78.19, 81.4645, 79.9704, 76.705, 78.3503, 77.6506, 77.7557, 84.0257, 74.128, 81.7968, 72.6325, 75.2642, 72.7021, 74.6487, 70.92, 72.1991, 70.7106, 69.7021, 72.3906, 73.9623, 69.0405, 68.4725, 70.0443, 69.061, 69.6224, 71.9929, 67.9186, 68.4553, 72.5871, 67.2232, 66.2662, 66.5989, 65.8094, 65.9276, 69.566, 65.4534, 64.9686, 70.255, 64.1779, 65.2219, 64.8332, 63.9766, 64.9522, 63.4877, 63.9849, 64.9695, 63.3299, 63.156, 67.8141, 63.8155, 65.6509, 62.8954, 62.1165, 65.1113, 63.6122, 62.3076, 63.2036, 62.7748, 62.7787, 61.3949, 61.191, 62.0271, 61.9046, 61.4345, 61.4483, 62.5084, 62.8359, 60.9646, 63.6216, 60.6409, 62.5058, 61.1453, 59.9347, 59.7559, 61.8588, 60.1386, 62.3497]\n",
      "\n",
      "We are now training cross-validation set # 5\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 12s 547us/step - loss: 597.8493 - mean_squared_error: 597.8494 - val_loss: 217.5055 - val_mean_squared_error: 217.5055\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 191.4123 - mean_squared_error: 191.4125 - val_loss: 182.8024 - val_mean_squared_error: 182.8024\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 160.6171 - mean_squared_error: 160.6171 - val_loss: 144.6140 - val_mean_squared_error: 144.6140\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 137.6410 - mean_squared_error: 137.6411 - val_loss: 130.2457 - val_mean_squared_error: 130.2457\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 12s 524us/step - loss: 127.3065 - mean_squared_error: 127.3065 - val_loss: 122.0695 - val_mean_squared_error: 122.0695\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 121.0453 - mean_squared_error: 121.0453 - val_loss: 116.8010 - val_mean_squared_error: 116.8010\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 115.9549 - mean_squared_error: 115.9549 - val_loss: 112.7620 - val_mean_squared_error: 112.7620\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 112.1642 - mean_squared_error: 112.1643 - val_loss: 112.7494 - val_mean_squared_error: 112.7494\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 110.0203 - mean_squared_error: 110.0203 - val_loss: 108.4858 - val_mean_squared_error: 108.4859\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 106.5517 - mean_squared_error: 106.5517 - val_loss: 104.3778 - val_mean_squared_error: 104.3778\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 514us/step - loss: 104.6305 - mean_squared_error: 104.6305 - val_loss: 106.3101 - val_mean_squared_error: 106.3100\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 11s 514us/step - loss: 103.1621 - mean_squared_error: 103.1621 - val_loss: 110.4464 - val_mean_squared_error: 110.4464\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 101.0215 - mean_squared_error: 101.0215 - val_loss: 103.5949 - val_mean_squared_error: 103.5949\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 99.6174 - mean_squared_error: 99.6174 - val_loss: 98.1204 - val_mean_squared_error: 98.1204\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 98.2248 - mean_squared_error: 98.2248 - val_loss: 102.3315 - val_mean_squared_error: 102.3315\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 97.0149 - mean_squared_error: 97.0150 - val_loss: 96.0961 - val_mean_squared_error: 96.0961\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 95.6245 - mean_squared_error: 95.6245 - val_loss: 94.7628 - val_mean_squared_error: 94.7628\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 94.4707 - mean_squared_error: 94.4707 - val_loss: 93.8950 - val_mean_squared_error: 93.8950\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 93.2083 - mean_squared_error: 93.2083 - val_loss: 92.4795 - val_mean_squared_error: 92.4795\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 92.3876 - mean_squared_error: 92.3876 - val_loss: 92.5507 - val_mean_squared_error: 92.5507\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 91.2829 - mean_squared_error: 91.2829 - val_loss: 92.8118 - val_mean_squared_error: 92.8118\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 12s 536us/step - loss: 90.2365 - mean_squared_error: 90.2364 - val_loss: 90.0813 - val_mean_squared_error: 90.0813\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 89.3931 - mean_squared_error: 89.3931 - val_loss: 89.0192 - val_mean_squared_error: 89.0192\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 516us/step - loss: 88.9059 - mean_squared_error: 88.9059 - val_loss: 92.5372 - val_mean_squared_error: 92.5372\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 87.5127 - mean_squared_error: 87.5127 - val_loss: 87.0824 - val_mean_squared_error: 87.0824\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 86.7396 - mean_squared_error: 86.7396 - val_loss: 98.0604 - val_mean_squared_error: 98.0604\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 11s 498us/step - loss: 86.3057 - mean_squared_error: 86.3057 - val_loss: 85.8945 - val_mean_squared_error: 85.8945\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 85.4348 - mean_squared_error: 85.4348 - val_loss: 85.2563 - val_mean_squared_error: 85.2563\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 84.9764 - mean_squared_error: 84.9764 - val_loss: 84.9287 - val_mean_squared_error: 84.9287\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 84.1328 - mean_squared_error: 84.1329 - val_loss: 85.7578 - val_mean_squared_error: 85.7578\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 83.5122 - mean_squared_error: 83.5123 - val_loss: 84.2656 - val_mean_squared_error: 84.2655\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 82.9056 - mean_squared_error: 82.9056 - val_loss: 82.6475 - val_mean_squared_error: 82.6476\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 82.2862 - mean_squared_error: 82.2862 - val_loss: 83.6467 - val_mean_squared_error: 83.6467\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 81.4262 - mean_squared_error: 81.4262 - val_loss: 81.6596 - val_mean_squared_error: 81.6596\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 81.0127 - mean_squared_error: 81.0127 - val_loss: 83.2984 - val_mean_squared_error: 83.2983\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 502us/step - loss: 80.3136 - mean_squared_error: 80.3135 - val_loss: 82.4188 - val_mean_squared_error: 82.4188\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 79.9775 - mean_squared_error: 79.9775 - val_loss: 81.2880 - val_mean_squared_error: 81.2880\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 79.2635 - mean_squared_error: 79.2635 - val_loss: 80.1501 - val_mean_squared_error: 80.1501\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 11s 513us/step - loss: 78.8168 - mean_squared_error: 78.8169 - val_loss: 86.9459 - val_mean_squared_error: 86.9459\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 11s 493us/step - loss: 78.4590 - mean_squared_error: 78.4590 - val_loss: 79.0342 - val_mean_squared_error: 79.0342\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 11s 509us/step - loss: 78.0066 - mean_squared_error: 78.0066 - val_loss: 78.3113 - val_mean_squared_error: 78.3113\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 77.6723 - mean_squared_error: 77.6723 - val_loss: 78.1160 - val_mean_squared_error: 78.1160\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 77.0884 - mean_squared_error: 77.0884 - val_loss: 77.6677 - val_mean_squared_error: 77.6676\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 76.7947 - mean_squared_error: 76.7947 - val_loss: 77.0893 - val_mean_squared_error: 77.0893\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 76.3888 - mean_squared_error: 76.3888 - val_loss: 77.5984 - val_mean_squared_error: 77.5984\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 76.0783 - mean_squared_error: 76.0783 - val_loss: 76.4637 - val_mean_squared_error: 76.4637\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 75.8275 - mean_squared_error: 75.8275 - val_loss: 87.7231 - val_mean_squared_error: 87.7231\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 75.2048 - mean_squared_error: 75.2048 - val_loss: 78.5898 - val_mean_squared_error: 78.5898\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 75.2770 - mean_squared_error: 75.2770 - val_loss: 83.1233 - val_mean_squared_error: 83.1233\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 74.8295 - mean_squared_error: 74.8294 - val_loss: 75.2430 - val_mean_squared_error: 75.2430\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 74.1105 - mean_squared_error: 74.1105 - val_loss: 75.0346 - val_mean_squared_error: 75.0345\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 73.9769 - mean_squared_error: 73.9770 - val_loss: 75.5970 - val_mean_squared_error: 75.5970\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 73.6705 - mean_squared_error: 73.6704 - val_loss: 75.1020 - val_mean_squared_error: 75.1020\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 73.5215 - mean_squared_error: 73.5214 - val_loss: 73.7644 - val_mean_squared_error: 73.7644\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 11s 521us/step - loss: 73.1031 - mean_squared_error: 73.1031 - val_loss: 74.2431 - val_mean_squared_error: 74.2431\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 11s 506us/step - loss: 73.6396 - mean_squared_error: 73.6396 - val_loss: 78.6108 - val_mean_squared_error: 78.6108\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 72.4735 - mean_squared_error: 72.4735 - val_loss: 73.8260 - val_mean_squared_error: 73.8260\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 72.5035 - mean_squared_error: 72.5035 - val_loss: 73.2499 - val_mean_squared_error: 73.2499\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 71.9243 - mean_squared_error: 71.9244 - val_loss: 76.3945 - val_mean_squared_error: 76.3945\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 72.2210 - mean_squared_error: 72.2209 - val_loss: 73.6308 - val_mean_squared_error: 73.6308\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 71.1509 - mean_squared_error: 71.1509 - val_loss: 72.3285 - val_mean_squared_error: 72.3285\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 11s 507us/step - loss: 71.5568 - mean_squared_error: 71.5568 - val_loss: 72.6436 - val_mean_squared_error: 72.6436\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 70.7838 - mean_squared_error: 70.7838 - val_loss: 73.2319 - val_mean_squared_error: 73.2319\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 71.0821 - mean_squared_error: 71.0820 - val_loss: 71.5554 - val_mean_squared_error: 71.5554\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 70.3519 - mean_squared_error: 70.3518 - val_loss: 74.4994 - val_mean_squared_error: 74.4994\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 70.3445 - mean_squared_error: 70.3445 - val_loss: 72.9871 - val_mean_squared_error: 72.9871\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 70.2751 - mean_squared_error: 70.2750 - val_loss: 71.7354 - val_mean_squared_error: 71.7355\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 12s 522us/step - loss: 69.8848 - mean_squared_error: 69.8847 - val_loss: 71.2586 - val_mean_squared_error: 71.2586\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 69.8094 - mean_squared_error: 69.8094 - val_loss: 70.8111 - val_mean_squared_error: 70.8111\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 69.5050 - mean_squared_error: 69.5050 - val_loss: 72.6196 - val_mean_squared_error: 72.6196\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 11s 510us/step - loss: 69.5582 - mean_squared_error: 69.5582 - val_loss: 71.1079 - val_mean_squared_error: 71.1079\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 11s 505us/step - loss: 68.9429 - mean_squared_error: 68.9428 - val_loss: 70.8166 - val_mean_squared_error: 70.8166\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 69.1337 - mean_squared_error: 69.1337 - val_loss: 70.7280 - val_mean_squared_error: 70.7280\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 68.8034 - mean_squared_error: 68.8034 - val_loss: 70.1084 - val_mean_squared_error: 70.1084\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 68.7683 - mean_squared_error: 68.7684 - val_loss: 70.0235 - val_mean_squared_error: 70.0235\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 11s 512us/step - loss: 68.4340 - mean_squared_error: 68.4340 - val_loss: 69.7296 - val_mean_squared_error: 69.7296\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 12s 533us/step - loss: 68.1839 - mean_squared_error: 68.1839 - val_loss: 69.7372 - val_mean_squared_error: 69.7372\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 12s 529us/step - loss: 68.0469 - mean_squared_error: 68.0468 - val_loss: 69.4656 - val_mean_squared_error: 69.4656\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 514us/step - loss: 68.0067 - mean_squared_error: 68.0067 - val_loss: 68.9051 - val_mean_squared_error: 68.9051\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 67.6919 - mean_squared_error: 67.6920 - val_loss: 69.8799 - val_mean_squared_error: 69.8799\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 67.7191 - mean_squared_error: 67.7191 - val_loss: 72.8317 - val_mean_squared_error: 72.8317\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 67.3483 - mean_squared_error: 67.3484 - val_loss: 68.9197 - val_mean_squared_error: 68.9197\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 67.3441 - mean_squared_error: 67.3441 - val_loss: 70.9907 - val_mean_squared_error: 70.9907\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 67.2609 - mean_squared_error: 67.2608 - val_loss: 68.6449 - val_mean_squared_error: 68.6449\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 11s 517us/step - loss: 66.9615 - mean_squared_error: 66.9615 - val_loss: 70.4166 - val_mean_squared_error: 70.4166\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 66.8842 - mean_squared_error: 66.8842 - val_loss: 68.9050 - val_mean_squared_error: 68.9050\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 497us/step - loss: 66.6489 - mean_squared_error: 66.6489 - val_loss: 68.2996 - val_mean_squared_error: 68.2996\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 66.4985 - mean_squared_error: 66.4985 - val_loss: 75.8364 - val_mean_squared_error: 75.8364\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 66.2510 - mean_squared_error: 66.2510 - val_loss: 71.4124 - val_mean_squared_error: 71.4124\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 66.1082 - mean_squared_error: 66.1082 - val_loss: 69.1351 - val_mean_squared_error: 69.1351\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 11s 501us/step - loss: 66.1386 - mean_squared_error: 66.1386 - val_loss: 72.4510 - val_mean_squared_error: 72.4510\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 65.8150 - mean_squared_error: 65.8150 - val_loss: 67.6137 - val_mean_squared_error: 67.6138\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 11s 508us/step - loss: 65.9433 - mean_squared_error: 65.9432 - val_loss: 66.9055 - val_mean_squared_error: 66.9055\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 65.4404 - mean_squared_error: 65.4403 - val_loss: 66.9153 - val_mean_squared_error: 66.9154\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 65.4669 - mean_squared_error: 65.4669 - val_loss: 67.0476 - val_mean_squared_error: 67.0476\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 11s 499us/step - loss: 65.3482 - mean_squared_error: 65.3481 - val_loss: 69.3342 - val_mean_squared_error: 69.3341\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 65.2970 - mean_squared_error: 65.2970 - val_loss: 77.4828 - val_mean_squared_error: 77.4828\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 11s 500us/step - loss: 64.9200 - mean_squared_error: 64.9200 - val_loss: 67.2825 - val_mean_squared_error: 67.2826\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 11s 504us/step - loss: 64.8831 - mean_squared_error: 64.8831 - val_loss: 66.7344 - val_mean_squared_error: 66.7343\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 64.7467 - mean_squared_error: 64.7467 - val_loss: 67.6278 - val_mean_squared_error: 67.6278\n",
      "Training Loss: [597.8493, 191.4123, 160.6171, 137.641, 127.3065, 121.0453, 115.9549, 112.1642, 110.0203, 106.5517, 104.6305, 103.1621, 101.0215, 99.6174, 98.2248, 97.0149, 95.6245, 94.4707, 93.2083, 92.3876, 91.2829, 90.2365, 89.3931, 88.9059, 87.5127, 86.7396, 86.3057, 85.4348, 84.9764, 84.1328, 83.5122, 82.9056, 82.2862, 81.4262, 81.0127, 80.3136, 79.9775, 79.2635, 78.8168, 78.459, 78.0066, 77.6723, 77.0884, 76.7947, 76.3888, 76.0783, 75.8275, 75.2048, 75.277, 74.8295, 74.1105, 73.9769, 73.6705, 73.5215, 73.1031, 73.6396, 72.4735, 72.5035, 71.9243, 72.221, 71.1509, 71.5568, 70.7838, 71.0821, 70.3519, 70.3445, 70.2751, 69.8848, 69.8094, 69.505, 69.5582, 68.9429, 69.1337, 68.8034, 68.7683, 68.434, 68.1839, 68.0469, 68.0067, 67.6919, 67.7191, 67.3483, 67.3441, 67.2609, 66.9615, 66.8842, 66.6489, 66.4985, 66.251, 66.1082, 66.1386, 65.815, 65.9433, 65.4404, 65.4669, 65.3482, 65.297, 64.92, 64.8831, 64.7467]\n",
      "Validation Loss: [217.5055, 182.8024, 144.614, 130.2457, 122.0695, 116.801, 112.762, 112.7494, 108.4858, 104.3778, 106.3101, 110.4464, 103.5949, 98.1204, 102.3315, 96.0961, 94.7628, 93.895, 92.4795, 92.5507, 92.8118, 90.0813, 89.0192, 92.5372, 87.0824, 98.0604, 85.8945, 85.2563, 84.9287, 85.7578, 84.2656, 82.6475, 83.6467, 81.6596, 83.2984, 82.4188, 81.288, 80.1501, 86.9459, 79.0342, 78.3113, 78.116, 77.6677, 77.0893, 77.5984, 76.4637, 87.7231, 78.5898, 83.1233, 75.243, 75.0346, 75.597, 75.102, 73.7644, 74.2431, 78.6108, 73.826, 73.2499, 76.3945, 73.6308, 72.3285, 72.6436, 73.2319, 71.5554, 74.4994, 72.9871, 71.7354, 71.2586, 70.8111, 72.6196, 71.1079, 70.8166, 70.728, 70.1084, 70.0235, 69.7296, 69.7372, 69.4656, 68.9051, 69.8799, 72.8317, 68.9197, 70.9907, 68.6449, 70.4166, 68.905, 68.2996, 75.8364, 71.4124, 69.1351, 72.451, 67.6137, 66.9055, 66.9153, 67.0476, 69.3342, 77.4828, 67.2825, 66.7344, 67.6278]\n",
      "\n",
      "We are now training cross-validation set # 1\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 511us/step - loss: 542.1162 - mean_squared_error: 542.1169 - val_loss: 199.4823 - val_mean_squared_error: 199.4823\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 169.4071 - mean_squared_error: 169.4071 - val_loss: 152.8279 - val_mean_squared_error: 152.8279\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 143.8466 - mean_squared_error: 143.8465 - val_loss: 135.4214 - val_mean_squared_error: 135.4214\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 130.4941 - mean_squared_error: 130.4940 - val_loss: 124.0689 - val_mean_squared_error: 124.0689\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 121.1812 - mean_squared_error: 121.1812 - val_loss: 115.5655 - val_mean_squared_error: 115.5655\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 112.7205 - mean_squared_error: 112.7206 - val_loss: 109.3706 - val_mean_squared_error: 109.3706\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 107.7930 - mean_squared_error: 107.7931 - val_loss: 104.6314 - val_mean_squared_error: 104.6314\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 103.0808 - mean_squared_error: 103.0808 - val_loss: 99.3420 - val_mean_squared_error: 99.3420\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 99.3232 - mean_squared_error: 99.3231 - val_loss: 97.8756 - val_mean_squared_error: 97.8756\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 94.9117 - mean_squared_error: 94.9117 - val_loss: 92.7753 - val_mean_squared_error: 92.7752\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 92.2304 - mean_squared_error: 92.2303 - val_loss: 91.1439 - val_mean_squared_error: 91.1439\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 89.1484 - mean_squared_error: 89.1484 - val_loss: 86.8967 - val_mean_squared_error: 86.8967\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 86.8186 - mean_squared_error: 86.8186 - val_loss: 85.7727 - val_mean_squared_error: 85.7727\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 84.5134 - mean_squared_error: 84.5135 - val_loss: 83.8664 - val_mean_squared_error: 83.8664\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 82.4925 - mean_squared_error: 82.4925 - val_loss: 80.9115 - val_mean_squared_error: 80.9116\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 80.8440 - mean_squared_error: 80.8440 - val_loss: 96.6093 - val_mean_squared_error: 96.6093\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 79.0307 - mean_squared_error: 79.0308 - val_loss: 78.4908 - val_mean_squared_error: 78.4909\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 77.1939 - mean_squared_error: 77.1939 - val_loss: 76.6249 - val_mean_squared_error: 76.6249\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 76.1444 - mean_squared_error: 76.1444 - val_loss: 75.0538 - val_mean_squared_error: 75.0537\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 74.7662 - mean_squared_error: 74.7662 - val_loss: 74.5046 - val_mean_squared_error: 74.5046\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 73.3914 - mean_squared_error: 73.3914 - val_loss: 73.5461 - val_mean_squared_error: 73.5461\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 72.3368 - mean_squared_error: 72.3368 - val_loss: 71.7367 - val_mean_squared_error: 71.7367\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 71.5911 - mean_squared_error: 71.5911 - val_loss: 71.5392 - val_mean_squared_error: 71.5392\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 70.7900 - mean_squared_error: 70.7900 - val_loss: 75.7322 - val_mean_squared_error: 75.7323\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 69.4625 - mean_squared_error: 69.4624 - val_loss: 69.2777 - val_mean_squared_error: 69.2777\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 68.8633 - mean_squared_error: 68.8633 - val_loss: 75.1336 - val_mean_squared_error: 75.1336\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 68.4084 - mean_squared_error: 68.4084 - val_loss: 67.9667 - val_mean_squared_error: 67.9667\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 67.4038 - mean_squared_error: 67.4038 - val_loss: 68.4426 - val_mean_squared_error: 68.4426\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 66.9134 - mean_squared_error: 66.9134 - val_loss: 67.3149 - val_mean_squared_error: 67.3149\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 66.2327 - mean_squared_error: 66.2327 - val_loss: 66.5456 - val_mean_squared_error: 66.5456\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 11s 491us/step - loss: 65.4871 - mean_squared_error: 65.4871 - val_loss: 69.8986 - val_mean_squared_error: 69.8986\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 64.9766 - mean_squared_error: 64.9766 - val_loss: 66.0246 - val_mean_squared_error: 66.0246\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.4368 - mean_squared_error: 64.4368 - val_loss: 65.4910 - val_mean_squared_error: 65.4910\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.1466 - mean_squared_error: 64.1466 - val_loss: 65.5118 - val_mean_squared_error: 65.5118\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 63.6351 - mean_squared_error: 63.6351 - val_loss: 64.5460 - val_mean_squared_error: 64.5460\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 63.0287 - mean_squared_error: 63.0286 - val_loss: 66.3186 - val_mean_squared_error: 66.3186\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.7589 - mean_squared_error: 62.7589 - val_loss: 63.9060 - val_mean_squared_error: 63.9060\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 62.4590 - mean_squared_error: 62.4590 - val_loss: 62.7810 - val_mean_squared_error: 62.7810\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 62.0420 - mean_squared_error: 62.0421 - val_loss: 62.7851 - val_mean_squared_error: 62.7851\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 61.4499 - mean_squared_error: 61.4499 - val_loss: 62.9949 - val_mean_squared_error: 62.9949\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 61.1464 - mean_squared_error: 61.1463 - val_loss: 62.8209 - val_mean_squared_error: 62.8209\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 60.9378 - mean_squared_error: 60.9378 - val_loss: 61.6679 - val_mean_squared_error: 61.6679\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 60.4332 - mean_squared_error: 60.4333 - val_loss: 61.3792 - val_mean_squared_error: 61.3792\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 60.1610 - mean_squared_error: 60.1610 - val_loss: 62.3268 - val_mean_squared_error: 62.3268\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 59.9518 - mean_squared_error: 59.9518 - val_loss: 64.1941 - val_mean_squared_error: 64.1941\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 59.7536 - mean_squared_error: 59.7536 - val_loss: 61.1258 - val_mean_squared_error: 61.1259\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 59.1462 - mean_squared_error: 59.1462 - val_loss: 60.7346 - val_mean_squared_error: 60.7346\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.9156 - mean_squared_error: 58.9156 - val_loss: 62.8663 - val_mean_squared_error: 62.8663\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 58.9305 - mean_squared_error: 58.9305 - val_loss: 60.3805 - val_mean_squared_error: 60.3805\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 58.4833 - mean_squared_error: 58.4832 - val_loss: 60.8114 - val_mean_squared_error: 60.8114\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 58.1367 - mean_squared_error: 58.1367 - val_loss: 60.9896 - val_mean_squared_error: 60.9896\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 57.8794 - mean_squared_error: 57.8794 - val_loss: 60.0102 - val_mean_squared_error: 60.0101\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.7634 - mean_squared_error: 57.7634 - val_loss: 60.7443 - val_mean_squared_error: 60.7443\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 57.6635 - mean_squared_error: 57.6635 - val_loss: 58.8024 - val_mean_squared_error: 58.8024\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 57.1135 - mean_squared_error: 57.1135 - val_loss: 58.6295 - val_mean_squared_error: 58.6294\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 57.0894 - mean_squared_error: 57.0894 - val_loss: 58.8385 - val_mean_squared_error: 58.8385\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 56.9609 - mean_squared_error: 56.9609 - val_loss: 58.1705 - val_mean_squared_error: 58.1705\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 56.7456 - mean_squared_error: 56.7456 - val_loss: 58.7620 - val_mean_squared_error: 58.7620\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 56.4376 - mean_squared_error: 56.4376 - val_loss: 60.0744 - val_mean_squared_error: 60.0744\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 56.5254 - mean_squared_error: 56.5254 - val_loss: 57.9479 - val_mean_squared_error: 57.9479\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 493us/step - loss: 55.9081 - mean_squared_error: 55.9082 - val_loss: 63.1952 - val_mean_squared_error: 63.1952\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.8659 - mean_squared_error: 55.8660 - val_loss: 58.8652 - val_mean_squared_error: 58.8652\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.7858 - mean_squared_error: 55.7858 - val_loss: 58.3123 - val_mean_squared_error: 58.3123\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 55.6020 - mean_squared_error: 55.6020 - val_loss: 58.1657 - val_mean_squared_error: 58.1657\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 55.6082 - mean_squared_error: 55.6082 - val_loss: 57.0044 - val_mean_squared_error: 57.0044\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.2309 - mean_squared_error: 55.2309 - val_loss: 57.1959 - val_mean_squared_error: 57.1959\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.0423 - mean_squared_error: 55.0423 - val_loss: 58.1504 - val_mean_squared_error: 58.1504\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 54.9859 - mean_squared_error: 54.9858 - val_loss: 57.4602 - val_mean_squared_error: 57.4602\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 54.8652 - mean_squared_error: 54.8651 - val_loss: 57.5448 - val_mean_squared_error: 57.5448\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 54.8749 - mean_squared_error: 54.8749 - val_loss: 57.8543 - val_mean_squared_error: 57.8543\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 54.3261 - mean_squared_error: 54.3261 - val_loss: 61.5203 - val_mean_squared_error: 61.5203\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.4334 - mean_squared_error: 54.4334 - val_loss: 56.8349 - val_mean_squared_error: 56.8349\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.1863 - mean_squared_error: 54.1863 - val_loss: 62.0356 - val_mean_squared_error: 62.0356\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.1190 - mean_squared_error: 54.1190 - val_loss: 57.0902 - val_mean_squared_error: 57.0902\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.0240 - mean_squared_error: 54.0240 - val_loss: 56.3955 - val_mean_squared_error: 56.3955\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 53.7482 - mean_squared_error: 53.7482 - val_loss: 59.1174 - val_mean_squared_error: 59.1174\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 53.6930 - mean_squared_error: 53.6931 - val_loss: 55.8418 - val_mean_squared_error: 55.8418\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 53.5484 - mean_squared_error: 53.5484 - val_loss: 57.3090 - val_mean_squared_error: 57.3090\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 53.4770 - mean_squared_error: 53.4770 - val_loss: 56.0854 - val_mean_squared_error: 56.0854\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 53.3940 - mean_squared_error: 53.3939 - val_loss: 57.4204 - val_mean_squared_error: 57.4204\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.0028 - mean_squared_error: 53.0028 - val_loss: 56.8589 - val_mean_squared_error: 56.8589\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 53.1413 - mean_squared_error: 53.1413 - val_loss: 55.3459 - val_mean_squared_error: 55.3459\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 52.9059 - mean_squared_error: 52.9059 - val_loss: 58.7609 - val_mean_squared_error: 58.7609\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 52.8810 - mean_squared_error: 52.8810 - val_loss: 55.4591 - val_mean_squared_error: 55.4591\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.7419 - mean_squared_error: 52.7419 - val_loss: 56.3253 - val_mean_squared_error: 56.3253\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.5792 - mean_squared_error: 52.5792 - val_loss: 55.7482 - val_mean_squared_error: 55.7482\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.5024 - mean_squared_error: 52.5024 - val_loss: 54.9551 - val_mean_squared_error: 54.9550\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.3514 - mean_squared_error: 52.3514 - val_loss: 55.4876 - val_mean_squared_error: 55.4876\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 52.3221 - mean_squared_error: 52.3221 - val_loss: 55.3782 - val_mean_squared_error: 55.3782\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 52.2453 - mean_squared_error: 52.2453 - val_loss: 58.3559 - val_mean_squared_error: 58.3559\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 51.9936 - mean_squared_error: 51.9936 - val_loss: 54.4479 - val_mean_squared_error: 54.4479\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 51.9693 - mean_squared_error: 51.9693 - val_loss: 55.9095 - val_mean_squared_error: 55.9095\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 52.3477 - mean_squared_error: 52.3477 - val_loss: 54.0516 - val_mean_squared_error: 54.0516\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 51.3948 - mean_squared_error: 51.3948 - val_loss: 57.0940 - val_mean_squared_error: 57.0940\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 51.6903 - mean_squared_error: 51.6903 - val_loss: 57.0508 - val_mean_squared_error: 57.0508\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 51.4843 - mean_squared_error: 51.4843 - val_loss: 55.0514 - val_mean_squared_error: 55.0514\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 51.5115 - mean_squared_error: 51.5115 - val_loss: 54.0433 - val_mean_squared_error: 54.0433\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 51.2004 - mean_squared_error: 51.2004 - val_loss: 54.1266 - val_mean_squared_error: 54.1266\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 51.2530 - mean_squared_error: 51.2530 - val_loss: 53.6555 - val_mean_squared_error: 53.6555\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 51.0972 - mean_squared_error: 51.0972 - val_loss: 54.3134 - val_mean_squared_error: 54.3135\n",
      "Training Loss: [542.1162, 169.4071, 143.8466, 130.4941, 121.1812, 112.7205, 107.793, 103.0808, 99.3232, 94.9117, 92.2304, 89.1484, 86.8186, 84.5134, 82.4925, 80.844, 79.0307, 77.1939, 76.1444, 74.7662, 73.3914, 72.3368, 71.5911, 70.79, 69.4625, 68.8633, 68.4084, 67.4038, 66.9134, 66.2327, 65.4871, 64.9766, 64.4368, 64.1466, 63.6351, 63.0287, 62.7589, 62.459, 62.042, 61.4499, 61.1464, 60.9378, 60.4332, 60.161, 59.9518, 59.7536, 59.1462, 58.9156, 58.9305, 58.4833, 58.1367, 57.8794, 57.7634, 57.6635, 57.1135, 57.0894, 56.9609, 56.7456, 56.4376, 56.5254, 55.9081, 55.8659, 55.7858, 55.602, 55.6082, 55.2309, 55.0423, 54.9859, 54.8652, 54.8749, 54.3261, 54.4334, 54.1863, 54.119, 54.024, 53.7482, 53.693, 53.5484, 53.477, 53.394, 53.0028, 53.1413, 52.9059, 52.881, 52.7419, 52.5792, 52.5024, 52.3514, 52.3221, 52.2453, 51.9936, 51.9693, 52.3477, 51.3948, 51.6903, 51.4843, 51.5115, 51.2004, 51.253, 51.0972]\n",
      "Validation Loss: [199.4823, 152.8279, 135.4214, 124.0689, 115.5655, 109.3706, 104.6314, 99.342, 97.8756, 92.7753, 91.1439, 86.8967, 85.7727, 83.8664, 80.9115, 96.6093, 78.4908, 76.6249, 75.0538, 74.5046, 73.5461, 71.7367, 71.5392, 75.7322, 69.2777, 75.1336, 67.9667, 68.4426, 67.3149, 66.5456, 69.8986, 66.0246, 65.491, 65.5118, 64.546, 66.3186, 63.906, 62.781, 62.7851, 62.9949, 62.8209, 61.6679, 61.3792, 62.3268, 64.1941, 61.1258, 60.7346, 62.8663, 60.3805, 60.8114, 60.9896, 60.0102, 60.7443, 58.8024, 58.6295, 58.8385, 58.1705, 58.762, 60.0744, 57.9479, 63.1952, 58.8652, 58.3123, 58.1657, 57.0044, 57.1959, 58.1504, 57.4602, 57.5448, 57.8543, 61.5203, 56.8349, 62.0356, 57.0902, 56.3955, 59.1174, 55.8418, 57.309, 56.0854, 57.4204, 56.8589, 55.3459, 58.7609, 55.4591, 56.3253, 55.7482, 54.9551, 55.4876, 55.3782, 58.3559, 54.4479, 55.9095, 54.0516, 57.094, 57.0508, 55.0514, 54.0433, 54.1266, 53.6555, 54.3134]\n",
      "\n",
      "We are now training cross-validation set # 2\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 687.7567 - mean_squared_error: 687.7567 - val_loss: 337.5062 - val_mean_squared_error: 337.5062\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 212.3794 - mean_squared_error: 212.3795 - val_loss: 170.1528 - val_mean_squared_error: 170.1528\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 151.6733 - mean_squared_error: 151.6733 - val_loss: 145.8259 - val_mean_squared_error: 145.8259\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 134.8478 - mean_squared_error: 134.8478 - val_loss: 130.9465 - val_mean_squared_error: 130.9465\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 123.9333 - mean_squared_error: 123.9333 - val_loss: 127.9625 - val_mean_squared_error: 127.9625\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 114.0680 - mean_squared_error: 114.0680 - val_loss: 107.6077 - val_mean_squared_error: 107.6077\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 105.0626 - mean_squared_error: 105.0626 - val_loss: 101.0245 - val_mean_squared_error: 101.0245\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 99.0053 - mean_squared_error: 99.0053 - val_loss: 96.9606 - val_mean_squared_error: 96.9605\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 94.5523 - mean_squared_error: 94.5523 - val_loss: 93.7328 - val_mean_squared_error: 93.7328\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 90.6799 - mean_squared_error: 90.6799 - val_loss: 89.3831 - val_mean_squared_error: 89.3830\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 87.8206 - mean_squared_error: 87.8205 - val_loss: 86.2190 - val_mean_squared_error: 86.2190\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 85.2939 - mean_squared_error: 85.2939 - val_loss: 84.3790 - val_mean_squared_error: 84.3790\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 82.9414 - mean_squared_error: 82.9414 - val_loss: 82.1097 - val_mean_squared_error: 82.1096\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 81.2395 - mean_squared_error: 81.2395 - val_loss: 82.6480 - val_mean_squared_error: 82.6480\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 79.6121 - mean_squared_error: 79.6121 - val_loss: 78.3002 - val_mean_squared_error: 78.3002\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 78.6223 - mean_squared_error: 78.6223 - val_loss: 77.1045 - val_mean_squared_error: 77.1045\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 11s 489us/step - loss: 76.8832 - mean_squared_error: 76.8832 - val_loss: 76.4141 - val_mean_squared_error: 76.4141\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 75.9544 - mean_squared_error: 75.9544 - val_loss: 77.2232 - val_mean_squared_error: 77.2232\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 75.1099 - mean_squared_error: 75.1099 - val_loss: 76.0779 - val_mean_squared_error: 76.0780\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 73.8999 - mean_squared_error: 73.8999 - val_loss: 83.9773 - val_mean_squared_error: 83.9773\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 73.2471 - mean_squared_error: 73.2471 - val_loss: 72.8513 - val_mean_squared_error: 72.8512\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 72.2965 - mean_squared_error: 72.2965 - val_loss: 72.2288 - val_mean_squared_error: 72.2289\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 71.6721 - mean_squared_error: 71.6721 - val_loss: 71.5364 - val_mean_squared_error: 71.5364\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 476us/step - loss: 70.8849 - mean_squared_error: 70.8849 - val_loss: 71.7501 - val_mean_squared_error: 71.7501\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 69.9108 - mean_squared_error: 69.9109 - val_loss: 70.8845 - val_mean_squared_error: 70.8845\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 69.3795 - mean_squared_error: 69.3795 - val_loss: 76.1637 - val_mean_squared_error: 76.1636\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 68.6984 - mean_squared_error: 68.6984 - val_loss: 68.5066 - val_mean_squared_error: 68.5066\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 68.2990 - mean_squared_error: 68.2990 - val_loss: 68.0470 - val_mean_squared_error: 68.0469\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 67.5695 - mean_squared_error: 67.5695 - val_loss: 68.2465 - val_mean_squared_error: 68.2466\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 66.8943 - mean_squared_error: 66.8943 - val_loss: 66.9011 - val_mean_squared_error: 66.9011\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 66.5342 - mean_squared_error: 66.5341 - val_loss: 75.6316 - val_mean_squared_error: 75.6316\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 65.9243 - mean_squared_error: 65.9242 - val_loss: 73.6422 - val_mean_squared_error: 73.6422\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 66.0958 - mean_squared_error: 66.0959 - val_loss: 66.6866 - val_mean_squared_error: 66.6866\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 64.6494 - mean_squared_error: 64.6494 - val_loss: 65.2658 - val_mean_squared_error: 65.2658\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 64.2343 - mean_squared_error: 64.2342 - val_loss: 65.3966 - val_mean_squared_error: 65.3966\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.9139 - mean_squared_error: 63.9139 - val_loss: 67.1330 - val_mean_squared_error: 67.1330\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.6355 - mean_squared_error: 63.6355 - val_loss: 64.9409 - val_mean_squared_error: 64.9409\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 63.3423 - mean_squared_error: 63.3424 - val_loss: 63.6147 - val_mean_squared_error: 63.6147\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 62.7363 - mean_squared_error: 62.7363 - val_loss: 63.2003 - val_mean_squared_error: 63.2003\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 62.4136 - mean_squared_error: 62.4136 - val_loss: 64.4742 - val_mean_squared_error: 64.4742\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 62.2304 - mean_squared_error: 62.2304 - val_loss: 64.8009 - val_mean_squared_error: 64.8009\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 61.4908 - mean_squared_error: 61.4908 - val_loss: 70.6578 - val_mean_squared_error: 70.6578\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 61.3903 - mean_squared_error: 61.3903 - val_loss: 62.0988 - val_mean_squared_error: 62.0988\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 61.1391 - mean_squared_error: 61.1391 - val_loss: 61.6015 - val_mean_squared_error: 61.6015\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 60.6411 - mean_squared_error: 60.6411 - val_loss: 61.9591 - val_mean_squared_error: 61.9590\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 60.5290 - mean_squared_error: 60.5290 - val_loss: 61.7533 - val_mean_squared_error: 61.7533\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 60.2688 - mean_squared_error: 60.2688 - val_loss: 61.3080 - val_mean_squared_error: 61.3080\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 60.0428 - mean_squared_error: 60.0428 - val_loss: 63.2721 - val_mean_squared_error: 63.2721\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 59.6323 - mean_squared_error: 59.6323 - val_loss: 61.5203 - val_mean_squared_error: 61.5203\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 59.4549 - mean_squared_error: 59.4549 - val_loss: 69.0625 - val_mean_squared_error: 69.0625\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 59.1626 - mean_squared_error: 59.1626 - val_loss: 65.2701 - val_mean_squared_error: 65.2700\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 59.2000 - mean_squared_error: 59.2000 - val_loss: 61.1037 - val_mean_squared_error: 61.1037\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 58.8551 - mean_squared_error: 58.8551 - val_loss: 60.5174 - val_mean_squared_error: 60.5174\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 58.6555 - mean_squared_error: 58.6555 - val_loss: 60.1961 - val_mean_squared_error: 60.1961\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 58.4580 - mean_squared_error: 58.4580 - val_loss: 60.1408 - val_mean_squared_error: 60.1408\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 58.2221 - mean_squared_error: 58.2221 - val_loss: 67.2405 - val_mean_squared_error: 67.2405\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 57.9585 - mean_squared_error: 57.9585 - val_loss: 61.3997 - val_mean_squared_error: 61.3997\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 58.0301 - mean_squared_error: 58.0301 - val_loss: 59.5131 - val_mean_squared_error: 59.5131\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.9810 - mean_squared_error: 57.9810 - val_loss: 59.4100 - val_mean_squared_error: 59.4100\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.2821 - mean_squared_error: 57.2820 - val_loss: 64.0996 - val_mean_squared_error: 64.0996\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 57.3915 - mean_squared_error: 57.3916 - val_loss: 58.8835 - val_mean_squared_error: 58.8835\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 57.0258 - mean_squared_error: 57.0258 - val_loss: 60.3232 - val_mean_squared_error: 60.3231\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 57.1265 - mean_squared_error: 57.1265 - val_loss: 58.7920 - val_mean_squared_error: 58.7920\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 56.7606 - mean_squared_error: 56.7606 - val_loss: 58.9788 - val_mean_squared_error: 58.9788\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 56.5759 - mean_squared_error: 56.5759 - val_loss: 59.3525 - val_mean_squared_error: 59.3525\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 56.4313 - mean_squared_error: 56.4313 - val_loss: 59.1135 - val_mean_squared_error: 59.1135\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 56.3610 - mean_squared_error: 56.3611 - val_loss: 58.0255 - val_mean_squared_error: 58.0255\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 56.1825 - mean_squared_error: 56.1825 - val_loss: 57.9168 - val_mean_squared_error: 57.9168\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 55.9799 - mean_squared_error: 55.9800 - val_loss: 59.0326 - val_mean_squared_error: 59.0326\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 55.8874 - mean_squared_error: 55.8875 - val_loss: 57.8233 - val_mean_squared_error: 57.8233\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 55.7126 - mean_squared_error: 55.7127 - val_loss: 57.5332 - val_mean_squared_error: 57.5332\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.5472 - mean_squared_error: 55.5472 - val_loss: 58.7186 - val_mean_squared_error: 58.7186\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 55.5497 - mean_squared_error: 55.5497 - val_loss: 57.6707 - val_mean_squared_error: 57.6707\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 55.1834 - mean_squared_error: 55.1834 - val_loss: 57.4826 - val_mean_squared_error: 57.4827\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 55.2304 - mean_squared_error: 55.2304 - val_loss: 56.9331 - val_mean_squared_error: 56.9331\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 54.9293 - mean_squared_error: 54.9293 - val_loss: 61.5005 - val_mean_squared_error: 61.5005\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 54.8554 - mean_squared_error: 54.8554 - val_loss: 56.6402 - val_mean_squared_error: 56.6402\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 54.5810 - mean_squared_error: 54.5811 - val_loss: 58.2102 - val_mean_squared_error: 58.2102\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.6324 - mean_squared_error: 54.6324 - val_loss: 62.2628 - val_mean_squared_error: 62.2629\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 54.6389 - mean_squared_error: 54.6389 - val_loss: 56.1781 - val_mean_squared_error: 56.1781\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 54.0976 - mean_squared_error: 54.0976 - val_loss: 58.6007 - val_mean_squared_error: 58.6007\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 54.2311 - mean_squared_error: 54.2312 - val_loss: 57.9425 - val_mean_squared_error: 57.9425\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 53.9353 - mean_squared_error: 53.9353 - val_loss: 57.4021 - val_mean_squared_error: 57.4021\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 53.9586 - mean_squared_error: 53.9586 - val_loss: 55.8243 - val_mean_squared_error: 55.8243\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 53.7653 - mean_squared_error: 53.7653 - val_loss: 56.2673 - val_mean_squared_error: 56.2673\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 53.7104 - mean_squared_error: 53.7104 - val_loss: 56.8650 - val_mean_squared_error: 56.8650\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 53.4938 - mean_squared_error: 53.4937 - val_loss: 56.3474 - val_mean_squared_error: 56.3474\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 53.5180 - mean_squared_error: 53.5180 - val_loss: 56.5151 - val_mean_squared_error: 56.5150\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 10s 468us/step - loss: 53.3259 - mean_squared_error: 53.3259 - val_loss: 56.2850 - val_mean_squared_error: 56.2850\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 53.2528 - mean_squared_error: 53.2528 - val_loss: 60.5114 - val_mean_squared_error: 60.5114\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 53.1286 - mean_squared_error: 53.1286 - val_loss: 55.7077 - val_mean_squared_error: 55.7076\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 53.1059 - mean_squared_error: 53.1059 - val_loss: 55.7100 - val_mean_squared_error: 55.7100\n",
      "Epoch 93/100\n",
      "22046/22046 [==============================] - 10s 470us/step - loss: 52.9098 - mean_squared_error: 52.9098 - val_loss: 55.1406 - val_mean_squared_error: 55.1406\n",
      "Epoch 94/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.7668 - mean_squared_error: 52.7668 - val_loss: 59.0593 - val_mean_squared_error: 59.0593\n",
      "Epoch 95/100\n",
      "22046/22046 [==============================] - 10s 469us/step - loss: 52.8347 - mean_squared_error: 52.8347 - val_loss: 55.5714 - val_mean_squared_error: 55.5714\n",
      "Epoch 96/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 52.6881 - mean_squared_error: 52.6881 - val_loss: 54.5993 - val_mean_squared_error: 54.5993\n",
      "Epoch 97/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.4487 - mean_squared_error: 52.4487 - val_loss: 54.9460 - val_mean_squared_error: 54.9460\n",
      "Epoch 98/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.4186 - mean_squared_error: 52.4186 - val_loss: 65.8144 - val_mean_squared_error: 65.8145\n",
      "Epoch 99/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.5957 - mean_squared_error: 52.5957 - val_loss: 54.6067 - val_mean_squared_error: 54.6066\n",
      "Epoch 100/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 52.0909 - mean_squared_error: 52.0909 - val_loss: 55.0202 - val_mean_squared_error: 55.0202\n",
      "Training Loss: [687.7567, 212.3794, 151.6733, 134.8478, 123.9333, 114.068, 105.0626, 99.0053, 94.5523, 90.6799, 87.8206, 85.2939, 82.9414, 81.2395, 79.6121, 78.6223, 76.8832, 75.9544, 75.1099, 73.8999, 73.2471, 72.2965, 71.6721, 70.8849, 69.9108, 69.3795, 68.6984, 68.299, 67.5695, 66.8943, 66.5342, 65.9243, 66.0958, 64.6494, 64.2343, 63.9139, 63.6355, 63.3423, 62.7363, 62.4136, 62.2304, 61.4908, 61.3903, 61.1391, 60.6411, 60.529, 60.2688, 60.0428, 59.6323, 59.4549, 59.1626, 59.2, 58.8551, 58.6555, 58.458, 58.2221, 57.9585, 58.0301, 57.981, 57.2821, 57.3915, 57.0258, 57.1265, 56.7606, 56.5759, 56.4313, 56.361, 56.1825, 55.9799, 55.8874, 55.7126, 55.5472, 55.5497, 55.1834, 55.2304, 54.9293, 54.8554, 54.581, 54.6324, 54.6389, 54.0976, 54.2311, 53.9353, 53.9586, 53.7653, 53.7104, 53.4938, 53.518, 53.3259, 53.2528, 53.1286, 53.1059, 52.9098, 52.7668, 52.8347, 52.6881, 52.4487, 52.4186, 52.5957, 52.0909]\n",
      "Validation Loss: [337.5062, 170.1528, 145.8259, 130.9465, 127.9625, 107.6077, 101.0245, 96.9606, 93.7328, 89.3831, 86.219, 84.379, 82.1097, 82.648, 78.3002, 77.1045, 76.4141, 77.2232, 76.0779, 83.9773, 72.8513, 72.2288, 71.5364, 71.7501, 70.8845, 76.1637, 68.5066, 68.047, 68.2465, 66.9011, 75.6316, 73.6422, 66.6866, 65.2658, 65.3966, 67.133, 64.9409, 63.6147, 63.2003, 64.4742, 64.8009, 70.6578, 62.0988, 61.6015, 61.9591, 61.7533, 61.308, 63.2721, 61.5203, 69.0625, 65.2701, 61.1037, 60.5174, 60.1961, 60.1408, 67.2405, 61.3997, 59.5131, 59.41, 64.0996, 58.8835, 60.3232, 58.792, 58.9788, 59.3525, 59.1135, 58.0255, 57.9168, 59.0326, 57.8233, 57.5332, 58.7186, 57.6707, 57.4826, 56.9331, 61.5005, 56.6402, 58.2102, 62.2628, 56.1781, 58.6007, 57.9425, 57.4021, 55.8243, 56.2673, 56.865, 56.3474, 56.5151, 56.285, 60.5114, 55.7077, 55.71, 55.1406, 59.0593, 55.5714, 54.5993, 54.946, 65.8144, 54.6067, 55.0202]\n",
      "\n",
      "We are now training cross-validation set # 3\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 522us/step - loss: 500.4849 - mean_squared_error: 500.4845 - val_loss: 179.3079 - val_mean_squared_error: 179.3079\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 519us/step - loss: 153.9780 - mean_squared_error: 153.9780 - val_loss: 137.8533 - val_mean_squared_error: 137.8534\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 127.5295 - mean_squared_error: 127.5294 - val_loss: 122.1453 - val_mean_squared_error: 122.1453\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 115.3421 - mean_squared_error: 115.3421 - val_loss: 112.7562 - val_mean_squared_error: 112.7562\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 107.2021 - mean_squared_error: 107.2021 - val_loss: 107.7292 - val_mean_squared_error: 107.7292\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 101.9496 - mean_squared_error: 101.9496 - val_loss: 100.6053 - val_mean_squared_error: 100.6053\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 11s 498us/step - loss: 97.1915 - mean_squared_error: 97.1915 - val_loss: 95.3259 - val_mean_squared_error: 95.3259\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 93.9563 - mean_squared_error: 93.9562 - val_loss: 91.0556 - val_mean_squared_error: 91.0556\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 11s 499us/step - loss: 90.9173 - mean_squared_error: 90.9173 - val_loss: 88.6494 - val_mean_squared_error: 88.6495\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 499us/step - loss: 88.4857 - mean_squared_error: 88.4857 - val_loss: 91.7159 - val_mean_squared_error: 91.7160\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 11s 495us/step - loss: 86.4042 - mean_squared_error: 86.4041 - val_loss: 85.0856 - val_mean_squared_error: 85.0856\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 11s 492us/step - loss: 84.3023 - mean_squared_error: 84.3024 - val_loss: 84.4052 - val_mean_squared_error: 84.4052\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 11s 500us/step - loss: 82.6882 - mean_squared_error: 82.6882 - val_loss: 82.2307 - val_mean_squared_error: 82.2307\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 12s 523us/step - loss: 81.0935 - mean_squared_error: 81.0935 - val_loss: 80.0829 - val_mean_squared_error: 80.0828\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 11s 498us/step - loss: 79.7750 - mean_squared_error: 79.7750 - val_loss: 84.8723 - val_mean_squared_error: 84.8723\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 476us/step - loss: 78.4444 - mean_squared_error: 78.4444 - val_loss: 77.5403 - val_mean_squared_error: 77.5403\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 77.0779 - mean_squared_error: 77.0779 - val_loss: 76.7024 - val_mean_squared_error: 76.7024\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 76.1872 - mean_squared_error: 76.1872 - val_loss: 75.6010 - val_mean_squared_error: 75.6010\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 503us/step - loss: 74.5560 - mean_squared_error: 74.5560 - val_loss: 75.8391 - val_mean_squared_error: 75.8391\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 518us/step - loss: 73.7185 - mean_squared_error: 73.7185 - val_loss: 73.0963 - val_mean_squared_error: 73.0963\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 72.4721 - mean_squared_error: 72.4721 - val_loss: 72.2176 - val_mean_squared_error: 72.2176\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 71.5388 - mean_squared_error: 71.5388 - val_loss: 71.9753 - val_mean_squared_error: 71.9753\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 70.7118 - mean_squared_error: 70.7118 - val_loss: 70.2450 - val_mean_squared_error: 70.2450\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 69.6781 - mean_squared_error: 69.6780 - val_loss: 87.2975 - val_mean_squared_error: 87.2975\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 69.1930 - mean_squared_error: 69.1929 - val_loss: 68.8142 - val_mean_squared_error: 68.8142\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 67.9196 - mean_squared_error: 67.9197 - val_loss: 68.1342 - val_mean_squared_error: 68.1342\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 11s 496us/step - loss: 67.1959 - mean_squared_error: 67.1960 - val_loss: 67.9241 - val_mean_squared_error: 67.9241\n",
      "Epoch 28/100\n",
      " 3488/22046 [===>..........................] - ETA: 8s - loss: 68.0161 - mean_squared_error: 68.0162"
     ]
    }
   ],
   "source": [
    "# Import relevant packages for neural network training\n",
    "import sys\n",
    "import csv\n",
    "if 'tensorflow' in sys.modules == False:\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "import keras\n",
    "## Create FSRCNN architecture\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, Conv2DTranspose, merge \n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "!pip install scikit-image\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "\n",
    "for d in High:\n",
    "    for s in Low:\n",
    "\n",
    "        # Create empty lists to store results\n",
    "        TrainLoss = []\n",
    "        TestLoss = []\n",
    "        \n",
    "        for p in range(5):\n",
    "\n",
    "            # Create the appropriate training and testing sets\n",
    "            if i == 0:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:]), axis=0)\n",
    "                TestOut = Dataset[Index5,:]\n",
    "            elif i == 1:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index4,:]\n",
    "            elif i == 2:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index3,:]\n",
    "            elif i == 3:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index2,:]\n",
    "            else:\n",
    "                TrainOut = np.concatenate((Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index1,:]\n",
    "\n",
    "\n",
    "            # Generate train and test sets\n",
    "            TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
    "            TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
    "            for i in range(np.shape(TrainOut)[0]):\n",
    "                TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
    "            for i in range(np.shape(TestOut)[0]):\n",
    "                TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))       \n",
    "\n",
    "\n",
    "            #Feature Extraction\n",
    "            model = Sequential()\n",
    "            input_img = Input(shape=(32,32,3))\n",
    "            model = Conv2D(filters = d, kernel_size = (5, 5), padding='same', kernel_initializer='he_normal')(input_img)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Shrink\n",
    "            model = Conv2D(filters = 16, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Mapping\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Exapansion\n",
    "            model = Conv2D(filters = d, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Deconvolution\n",
    "            model = Conv2DTranspose(filters = 3, kernel_size = (9, 9), strides=(4, 4), padding='same')(model)\n",
    "            output_img = model\n",
    "\n",
    "            model = Model(input_img, output_img) #Create the model object\n",
    "            adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #Training optimizer\n",
    "            model.compile(loss = \"mean_squared_error\", optimizer = adam, metrics=[\"mean_squared_error\"]) #How we measure error\n",
    "\n",
    "            #model.summary()\n",
    "\n",
    "            # Train model and evaluate performance\n",
    "            print('We are now training cross-validation set #',p+1)\n",
    "            Results = model.fit(y=TrainOut, x=TrainIn, validation_data = (TestIn,TestOut), epochs=100, batch_size = 32, validation_freq=1)\n",
    "\n",
    "\n",
    "            # Display and store performance results\n",
    "            Results.history['loss'] = [round(l, 4) for l in Results.history['loss']]\n",
    "            Results.history['val_loss'] = [round(l, 4) for l in Results.history['val_loss']]\n",
    "\n",
    "            print('Training Loss:',Results.history['loss'])\n",
    "            print('Validation Loss:',Results.history['val_loss'])\n",
    "\n",
    "            TrainLoss.append(Results.history['loss'])\n",
    "            TestLoss.append(Results.history['val_loss'])\n",
    "            print('')\n",
    "\n",
    "\n",
    "        # Save and export as CSV files\n",
    "        with open(str(d)+\"_\"+str(s)+\"_4Maps_TrainLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TrainLoss)\n",
    "        with open(str(d)+\"_\"+str(s)+\"_4Maps_TestLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TestLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for neural network training\n",
    "import sys\n",
    "import csv\n",
    "if 'tensorflow' in sys.modules == False:\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "import keras\n",
    "## Create FSRCNN architecture\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, Conv2DTranspose, merge \n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "!pip install scikit-image\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "\n",
    "for d in High:\n",
    "    for s in Low:\n",
    "\n",
    "        # Create empty lists to store results\n",
    "        TrainLoss = []\n",
    "        TestLoss = []\n",
    "        \n",
    "        for p in range(5):\n",
    "\n",
    "            # Create the appropriate training and testing sets\n",
    "            if i == 0:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:]), axis=0)\n",
    "                TestOut = Dataset[Index5,:]\n",
    "            elif i == 1:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index4,:]\n",
    "            elif i == 2:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index3,:]\n",
    "            elif i == 3:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index2,:]\n",
    "            else:\n",
    "                TrainOut = np.concatenate((Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index1,:]\n",
    "\n",
    "\n",
    "            # Generate train and test sets\n",
    "            TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
    "            TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
    "            for i in range(np.shape(TrainOut)[0]):\n",
    "                TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
    "            for i in range(np.shape(TestOut)[0]):\n",
    "                TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))       \n",
    "\n",
    "\n",
    "            #Feature Extraction\n",
    "            model = Sequential()\n",
    "            input_img = Input(shape=(32,32,3))\n",
    "            model = Conv2D(filters = d, kernel_size = (5, 5), padding='same', kernel_initializer='he_normal')(input_img)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Shrink\n",
    "            model = Conv2D(filters = 16, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Mapping\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Exapansion\n",
    "            model = Conv2D(filters = d, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Deconvolution\n",
    "            model = Conv2DTranspose(filters = 3, kernel_size = (9, 9), strides=(4, 4), padding='same')(model)\n",
    "            output_img = model\n",
    "\n",
    "            model = Model(input_img, output_img) #Create the model object\n",
    "            adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #Training optimizer\n",
    "            model.compile(loss = \"mean_squared_error\", optimizer = adam, metrics=[\"mean_squared_error\"]) #How we measure error\n",
    "\n",
    "            #model.summary()\n",
    "\n",
    "            # Train model and evaluate performance\n",
    "            print('We are now training cross-validation set #',p+1)\n",
    "            Results = model.fit(y=TrainOut, x=TrainIn, validation_data = (TestIn,TestOut), epochs=100, batch_size = 32, validation_freq=1)\n",
    "\n",
    "\n",
    "            # Display and store performance results\n",
    "            Results.history['loss'] = [round(l, 4) for l in Results.history['loss']]\n",
    "            Results.history['val_loss'] = [round(l, 4) for l in Results.history['val_loss']]\n",
    "\n",
    "            print('Training Loss:',Results.history['loss'])\n",
    "            print('Validation Loss:',Results.history['val_loss'])\n",
    "\n",
    "            TrainLoss.append(Results.history['loss'])\n",
    "            TestLoss.append(Results.history['val_loss'])\n",
    "            print('')\n",
    "\n",
    "\n",
    "        # Save and export as CSV files\n",
    "        with open(str(d)+\"_\"+str(s)+\"_3Maps_TrainLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TrainLoss)\n",
    "        with open(str(d)+\"_\"+str(s)+\"_3Maps_TestLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TestLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages for neural network training\n",
    "import sys\n",
    "import csv\n",
    "if 'tensorflow' in sys.modules == False:\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "import keras\n",
    "## Create FSRCNN architecture\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, Conv2DTranspose, merge \n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "!pip install scikit-image\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "\n",
    "for d in High:\n",
    "    for s in Low:\n",
    "\n",
    "        # Create empty lists to store results\n",
    "        TrainLoss = []\n",
    "        TestLoss = []\n",
    "        \n",
    "        for p in range(5):\n",
    "\n",
    "            # Create the appropriate training and testing sets\n",
    "            if i == 0:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:]), axis=0)\n",
    "                TestOut = Dataset[Index5,:]\n",
    "            elif i == 1:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index3,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index4,:]\n",
    "            elif i == 2:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index2,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index3,:]\n",
    "            elif i == 3:\n",
    "                TrainOut = np.concatenate((Dataset[Index1,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index2,:]\n",
    "            else:\n",
    "                TrainOut = np.concatenate((Dataset[Index2,:],Dataset[Index3,:],Dataset[Index4,:],Dataset[Index5,:]), axis=0)\n",
    "                TestOut = Dataset[Index1,:]\n",
    "\n",
    "\n",
    "            # Generate train and test sets\n",
    "            TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
    "            TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
    "            for i in range(np.shape(TrainOut)[0]):\n",
    "                TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
    "            for i in range(np.shape(TestOut)[0]):\n",
    "                TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))       \n",
    "\n",
    "\n",
    "            #Feature Extraction\n",
    "            model = Sequential()\n",
    "            input_img = Input(shape=(32,32,3))\n",
    "            model = Conv2D(filters = d, kernel_size = (5, 5), padding='same', kernel_initializer='he_normal')(input_img)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Shrink\n",
    "            model = Conv2D(filters = 16, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Mapping\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "            model = Conv2D(filters = s, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Exapansion\n",
    "            model = Conv2D(filters = d, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "            model = PReLU()(model)\n",
    "\n",
    "            #Deconvolution\n",
    "            model = Conv2DTranspose(filters = 3, kernel_size = (9, 9), strides=(4, 4), padding='same')(model)\n",
    "            output_img = model\n",
    "\n",
    "            model = Model(input_img, output_img) #Create the model object\n",
    "            adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #Training optimizer\n",
    "            model.compile(loss = \"mean_squared_error\", optimizer = adam, metrics=[\"mean_squared_error\"]) #How we measure error\n",
    "\n",
    "            #model.summary()\n",
    "\n",
    "            # Train model and evaluate performance\n",
    "            print('We are now training cross-validation set #',p+1)\n",
    "            Results = model.fit(y=TrainOut, x=TrainIn, validation_data = (TestIn,TestOut), epochs=100, batch_size = 32, validation_freq=1)\n",
    "\n",
    "\n",
    "            # Display and store performance results\n",
    "            Results.history['loss'] = [round(l, 4) for l in Results.history['loss']]\n",
    "            Results.history['val_loss'] = [round(l, 4) for l in Results.history['val_loss']]\n",
    "\n",
    "            print('Training Loss:',Results.history['loss'])\n",
    "            print('Validation Loss:',Results.history['val_loss'])\n",
    "\n",
    "            TrainLoss.append(Results.history['loss'])\n",
    "            TestLoss.append(Results.history['val_loss'])\n",
    "            print('')\n",
    "\n",
    "\n",
    "        # Save and export as CSV files\n",
    "        with open(str(d)+\"_\"+str(s)+\"_2Maps_TrainLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TrainLoss)\n",
    "        with open(str(d)+\"_\"+str(s)+\"_2Maps_TestLoss.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(TestLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine RAM Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine RAM Usage\n",
    "import sys\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
