{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘cell_images.zip’ already there; not retrieving.\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.2.0.32)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.1)\n",
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease             \n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease         \n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\u001b[0m33m             \u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "libxrender1 is already the newest version (1:0.9.10-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
      "Uninfected Dataset size is: (13779, 128, 128, 3)\n",
      "Parasitized Dataset size is: (13779, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Download NIH dataset zip file\n",
    "!wget -nc ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
    "\n",
    "# Extract images if not already extracted\n",
    "ROOT_DIR = os.path.join(\"/\", \"content\")\n",
    "if not os.path.isdir(\"cell_images\"):\n",
    "    print(\"Extracting images...\")\n",
    "    with ZipFile(os.path.join(\"cell_images.zip\"), \"r\") as zipObj:\n",
    "        zipObj.extractall()\n",
    "    print(\"Done!\")\n",
    "\n",
    "# Install and import relevant packages\n",
    "import numpy as np\n",
    "import os\n",
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6 libxrender1\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Create new folders to save rescaled images\n",
    "if not os.path.isdir(\"RescaledSet\"):\n",
    "    os.mkdir(\"RescaledSet\")\n",
    "if not os.path.isdir(\"RescaledSet/Parasitized\"):\n",
    "    os.mkdir(\"RescaledSet/Parasitized\")\n",
    "if not os.path.isdir(\"RescaledSet/Uninfected\"):\n",
    "    os.mkdir(\"RescaledSet/Uninfected\")\n",
    "\n",
    "# Generate list of parasitized file names\n",
    "ParasitizedFiles = os.listdir(\"cell_images/Parasitized/\")\n",
    "UninfectedFiles = os.listdir(\"cell_images/Uninfected/\")\n",
    "\n",
    "# Remove Thumb.db files\n",
    "while 'Thumbs.db' in ParasitizedFiles: ParasitizedFiles.remove('Thumbs.db')   \n",
    "while 'Thumbs.db' in UninfectedFiles: UninfectedFiles.remove('Thumbs.db')  \n",
    "\n",
    "# Pre-allocate memory space for images\n",
    "Parasitized = np.empty([13779,128,128,3])\n",
    "Uninfected = np.empty([13779,128,128,3])\n",
    "\n",
    "# Resize and load parasitized images\n",
    "for i in range(13779):\n",
    "    TempImage = cv2.imread('cell_images/Parasitized/'+ParasitizedFiles[i])\n",
    "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
    "    Parasitized[i,:,:,:] = ResizedImage\n",
    "\n",
    "# Resize and load uninfected images\n",
    "for i in range(13779):\n",
    "    TempImage = cv2.imread('cell_images/Uninfected/'+UninfectedFiles[i])\n",
    "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
    "    Uninfected[i,:,:,:] = ResizedImage\n",
    "    \n",
    "print('Uninfected Dataset size is:',np.shape(Uninfected))\n",
    "print('Parasitized Dataset size is:',np.shape(Parasitized))\n",
    "\n",
    "# Generate dataset labels\n",
    "ParasitizedLabels = np.repeat([[0,1]], 13779, axis=0)\n",
    "UninfectedLabels = np.repeat([[1,0]], 13779, axis=0)\n",
    "Labels = np.concatenate((ParasitizedLabels,UninfectedLabels), axis=0)\n",
    "\n",
    "# Generate image dataset\n",
    "Dataset = np.concatenate((Parasitized, Uninfected), axis=0)\n",
    "\n",
    "# Generate 5-fold cross-validation groups\n",
    "CVIndices = np.random.permutation(Dataset.shape[0])\n",
    "TrainInd, TestInd = CVIndices[:22046], CVIndices[22046:]\n",
    "\n",
    "# Generate train and test sets\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "TrainOut = Dataset[TrainInd,:]\n",
    "TestOut = Dataset[TestInd,:]\n",
    "TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
    "TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
    "for i in range(np.shape(TrainOut)[0]):\n",
    "    TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
    "for i in range(np.shape(TestOut)[0]):\n",
    "    TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))\n",
    "\n",
    "# del Dataset\n",
    "del Parasitized\n",
    "del Uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.1.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.18.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (44.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Generate train and test sets\n",
    "! pip install scikit-image\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "del TrainOut\n",
    "del TrainIn\n",
    "del TestOut\n",
    "del TestIn\n",
    "del model\n",
    "\n",
    "CVIndices = np.random.permutation(Dataset.shape[0])\n",
    "TestInd, TrainInd = CVIndices[22046:], CVIndices[:22046]\n",
    "TrainOut = Dataset[TrainInd,:]\n",
    "TestOut = Dataset[TestInd,:]\n",
    "TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
    "TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
    "for i in range(np.shape(TrainOut)[0]):\n",
    "    TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
    "for i in range(np.shape(TestOut)[0]):\n",
    "    TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 56)        4256      \n",
      "_________________________________________________________________\n",
      "p_re_lu_22 (PReLU)           (None, 32, 32, 56)        57344     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 32, 16)        912       \n",
      "_________________________________________________________________\n",
      "p_re_lu_23 (PReLU)           (None, 32, 32, 16)        16384     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 12)        1740      \n",
      "_________________________________________________________________\n",
      "p_re_lu_24 (PReLU)           (None, 32, 32, 12)        12288     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 12)        1308      \n",
      "_________________________________________________________________\n",
      "p_re_lu_25 (PReLU)           (None, 32, 32, 12)        12288     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 12)        1308      \n",
      "_________________________________________________________________\n",
      "p_re_lu_26 (PReLU)           (None, 32, 32, 12)        12288     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 12)        1308      \n",
      "_________________________________________________________________\n",
      "p_re_lu_27 (PReLU)           (None, 32, 32, 12)        12288     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 56)        728       \n",
      "_________________________________________________________________\n",
      "p_re_lu_28 (PReLU)           (None, 32, 32, 56)        57344     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 3)       13611     \n",
      "=================================================================\n",
      "Total params: 205,395\n",
      "Trainable params: 205,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 22046 samples, validate on 5512 samples\n",
      "Epoch 1/100\n",
      "22046/22046 [==============================] - 11s 491us/step - loss: 554.6794 - mean_squared_error: 554.6790 - val_loss: 217.0818 - val_mean_squared_error: 217.0818\n",
      "Epoch 2/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 184.9660 - mean_squared_error: 184.9659 - val_loss: 165.9831 - val_mean_squared_error: 165.9831\n",
      "Epoch 3/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 154.8548 - mean_squared_error: 154.8547 - val_loss: 156.7992 - val_mean_squared_error: 156.7992\n",
      "Epoch 4/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 139.4703 - mean_squared_error: 139.4703 - val_loss: 131.8592 - val_mean_squared_error: 131.8592\n",
      "Epoch 5/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 129.3874 - mean_squared_error: 129.3874 - val_loss: 123.2251 - val_mean_squared_error: 123.2251\n",
      "Epoch 6/100\n",
      "22046/22046 [==============================] - 10s 456us/step - loss: 122.1170 - mean_squared_error: 122.1171 - val_loss: 121.0357 - val_mean_squared_error: 121.0357\n",
      "Epoch 7/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 116.6515 - mean_squared_error: 116.6514 - val_loss: 114.4203 - val_mean_squared_error: 114.4203\n",
      "Epoch 8/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 112.3077 - mean_squared_error: 112.3077 - val_loss: 118.1441 - val_mean_squared_error: 118.1442\n",
      "Epoch 9/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 108.7356 - mean_squared_error: 108.7356 - val_loss: 105.3309 - val_mean_squared_error: 105.3309\n",
      "Epoch 10/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 106.1753 - mean_squared_error: 106.1753 - val_loss: 108.6266 - val_mean_squared_error: 108.6265\n",
      "Epoch 11/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 103.2875 - mean_squared_error: 103.2875 - val_loss: 110.1084 - val_mean_squared_error: 110.1085\n",
      "Epoch 12/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 101.0699 - mean_squared_error: 101.0699 - val_loss: 97.8612 - val_mean_squared_error: 97.8612\n",
      "Epoch 13/100\n",
      "22046/22046 [==============================] - 11s 480us/step - loss: 99.7034 - mean_squared_error: 99.7034 - val_loss: 95.8461 - val_mean_squared_error: 95.8460\n",
      "Epoch 14/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 95.7742 - mean_squared_error: 95.7742 - val_loss: 94.9839 - val_mean_squared_error: 94.9839\n",
      "Epoch 15/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 94.5566 - mean_squared_error: 94.5567 - val_loss: 93.1949 - val_mean_squared_error: 93.1949\n",
      "Epoch 16/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 93.4323 - mean_squared_error: 93.4322 - val_loss: 92.1799 - val_mean_squared_error: 92.1799\n",
      "Epoch 17/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 91.0303 - mean_squared_error: 91.0303 - val_loss: 97.9337 - val_mean_squared_error: 97.9337\n",
      "Epoch 18/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 90.1223 - mean_squared_error: 90.1223 - val_loss: 88.3504 - val_mean_squared_error: 88.3504\n",
      "Epoch 19/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 88.1731 - mean_squared_error: 88.1730 - val_loss: 87.2628 - val_mean_squared_error: 87.2629\n",
      "Epoch 20/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 86.6817 - mean_squared_error: 86.6817 - val_loss: 85.1022 - val_mean_squared_error: 85.1022\n",
      "Epoch 21/100\n",
      "22046/22046 [==============================] - 11s 497us/step - loss: 85.3921 - mean_squared_error: 85.3921 - val_loss: 84.2895 - val_mean_squared_error: 84.2895\n",
      "Epoch 22/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 84.2135 - mean_squared_error: 84.2135 - val_loss: 84.0518 - val_mean_squared_error: 84.0518\n",
      "Epoch 23/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 82.9437 - mean_squared_error: 82.9437 - val_loss: 82.3231 - val_mean_squared_error: 82.3231\n",
      "Epoch 24/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 81.8946 - mean_squared_error: 81.8946 - val_loss: 82.0331 - val_mean_squared_error: 82.0331\n",
      "Epoch 25/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 80.6041 - mean_squared_error: 80.6040 - val_loss: 80.4469 - val_mean_squared_error: 80.4469\n",
      "Epoch 26/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 80.0247 - mean_squared_error: 80.0247 - val_loss: 78.8999 - val_mean_squared_error: 78.8999\n",
      "Epoch 27/100\n",
      "22046/22046 [==============================] - 10s 464us/step - loss: 78.7677 - mean_squared_error: 78.7677 - val_loss: 78.3201 - val_mean_squared_error: 78.3201\n",
      "Epoch 28/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 77.9080 - mean_squared_error: 77.9080 - val_loss: 79.1261 - val_mean_squared_error: 79.1261\n",
      "Epoch 29/100\n",
      "22046/22046 [==============================] - 10s 458us/step - loss: 77.4993 - mean_squared_error: 77.4993 - val_loss: 76.4382 - val_mean_squared_error: 76.4382\n",
      "Epoch 30/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 76.9446 - mean_squared_error: 76.9446 - val_loss: 76.0394 - val_mean_squared_error: 76.0394\n",
      "Epoch 31/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 75.4072 - mean_squared_error: 75.4072 - val_loss: 77.0555 - val_mean_squared_error: 77.0555\n",
      "Epoch 32/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 75.4432 - mean_squared_error: 75.4432 - val_loss: 74.5076 - val_mean_squared_error: 74.5075\n",
      "Epoch 33/100\n",
      "22046/22046 [==============================] - 10s 475us/step - loss: 74.6349 - mean_squared_error: 74.6349 - val_loss: 80.2346 - val_mean_squared_error: 80.2346\n",
      "Epoch 34/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 74.0561 - mean_squared_error: 74.0562 - val_loss: 73.6446 - val_mean_squared_error: 73.6446\n",
      "Epoch 35/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 73.4901 - mean_squared_error: 73.4901 - val_loss: 73.3326 - val_mean_squared_error: 73.3325\n",
      "Epoch 36/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 73.2055 - mean_squared_error: 73.2056 - val_loss: 72.6692 - val_mean_squared_error: 72.6692\n",
      "Epoch 37/100\n",
      "22046/22046 [==============================] - 10s 438us/step - loss: 72.7175 - mean_squared_error: 72.7174 - val_loss: 75.8653 - val_mean_squared_error: 75.8653\n",
      "Epoch 38/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 72.2171 - mean_squared_error: 72.2171 - val_loss: 72.1108 - val_mean_squared_error: 72.1108\n",
      "Epoch 39/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 71.7760 - mean_squared_error: 71.7761 - val_loss: 71.6869 - val_mean_squared_error: 71.6869\n",
      "Epoch 40/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 71.5918 - mean_squared_error: 71.5918 - val_loss: 72.3025 - val_mean_squared_error: 72.3025\n",
      "Epoch 41/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 71.1085 - mean_squared_error: 71.1085 - val_loss: 72.0490 - val_mean_squared_error: 72.0490\n",
      "Epoch 42/100\n",
      "22046/22046 [==============================] - 10s 450us/step - loss: 70.7421 - mean_squared_error: 70.7421 - val_loss: 74.0392 - val_mean_squared_error: 74.0392\n",
      "Epoch 43/100\n",
      "22046/22046 [==============================] - 10s 462us/step - loss: 70.5206 - mean_squared_error: 70.5206 - val_loss: 71.5060 - val_mean_squared_error: 71.5060\n",
      "Epoch 44/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 70.1299 - mean_squared_error: 70.1298 - val_loss: 108.8990 - val_mean_squared_error: 108.8990\n",
      "Epoch 45/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 69.7942 - mean_squared_error: 69.7942 - val_loss: 70.8215 - val_mean_squared_error: 70.8215\n",
      "Epoch 46/100\n",
      "22046/22046 [==============================] - 11s 484us/step - loss: 69.6061 - mean_squared_error: 69.6062 - val_loss: 70.5725 - val_mean_squared_error: 70.5725\n",
      "Epoch 47/100\n",
      "22046/22046 [==============================] - 11s 481us/step - loss: 69.2460 - mean_squared_error: 69.2460 - val_loss: 69.5924 - val_mean_squared_error: 69.5924\n",
      "Epoch 48/100\n",
      "22046/22046 [==============================] - 11s 490us/step - loss: 68.9907 - mean_squared_error: 68.9907 - val_loss: 70.0393 - val_mean_squared_error: 70.0393\n",
      "Epoch 49/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 68.7647 - mean_squared_error: 68.7647 - val_loss: 70.8195 - val_mean_squared_error: 70.8195\n",
      "Epoch 50/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 68.4843 - mean_squared_error: 68.4844 - val_loss: 69.1194 - val_mean_squared_error: 69.1194\n",
      "Epoch 51/100\n",
      "22046/22046 [==============================] - 10s 472us/step - loss: 68.2583 - mean_squared_error: 68.2583 - val_loss: 68.6337 - val_mean_squared_error: 68.6337\n",
      "Epoch 52/100\n",
      "22046/22046 [==============================] - 10s 473us/step - loss: 67.8693 - mean_squared_error: 67.8693 - val_loss: 77.1459 - val_mean_squared_error: 77.1459\n",
      "Epoch 53/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 67.7623 - mean_squared_error: 67.7624 - val_loss: 76.2570 - val_mean_squared_error: 76.2570\n",
      "Epoch 54/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 67.5261 - mean_squared_error: 67.5261 - val_loss: 68.4352 - val_mean_squared_error: 68.4351\n",
      "Epoch 55/100\n",
      "22046/22046 [==============================] - 11s 483us/step - loss: 67.2299 - mean_squared_error: 67.2300 - val_loss: 75.2015 - val_mean_squared_error: 75.2015\n",
      "Epoch 56/100\n",
      "22046/22046 [==============================] - 10s 444us/step - loss: 67.0504 - mean_squared_error: 67.0504 - val_loss: 67.8590 - val_mean_squared_error: 67.8590\n",
      "Epoch 57/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 66.8536 - mean_squared_error: 66.8537 - val_loss: 67.5108 - val_mean_squared_error: 67.5108\n",
      "Epoch 58/100\n",
      "22046/22046 [==============================] - 10s 460us/step - loss: 66.8964 - mean_squared_error: 66.8963 - val_loss: 67.7474 - val_mean_squared_error: 67.7474\n",
      "Epoch 59/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 66.4089 - mean_squared_error: 66.4089 - val_loss: 81.5317 - val_mean_squared_error: 81.5317\n",
      "Epoch 60/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 66.2598 - mean_squared_error: 66.2598 - val_loss: 78.7994 - val_mean_squared_error: 78.7994\n",
      "Epoch 61/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 65.9860 - mean_squared_error: 65.9860 - val_loss: 68.3136 - val_mean_squared_error: 68.3136\n",
      "Epoch 62/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 65.8156 - mean_squared_error: 65.8156 - val_loss: 91.4285 - val_mean_squared_error: 91.4285\n",
      "Epoch 63/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 65.5159 - mean_squared_error: 65.5159 - val_loss: 67.0248 - val_mean_squared_error: 67.0248\n",
      "Epoch 64/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 65.4564 - mean_squared_error: 65.4564 - val_loss: 66.4910 - val_mean_squared_error: 66.4910\n",
      "Epoch 65/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 65.3723 - mean_squared_error: 65.3723 - val_loss: 66.6940 - val_mean_squared_error: 66.6940\n",
      "Epoch 66/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 65.2121 - mean_squared_error: 65.2121 - val_loss: 67.3640 - val_mean_squared_error: 67.3640\n",
      "Epoch 67/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 64.9949 - mean_squared_error: 64.9948 - val_loss: 72.4483 - val_mean_squared_error: 72.4483\n",
      "Epoch 68/100\n",
      "22046/22046 [==============================] - 10s 467us/step - loss: 64.7155 - mean_squared_error: 64.7155 - val_loss: 66.2531 - val_mean_squared_error: 66.2531\n",
      "Epoch 69/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 64.7199 - mean_squared_error: 64.7200 - val_loss: 65.8133 - val_mean_squared_error: 65.8133\n",
      "Epoch 70/100\n",
      "22046/22046 [==============================] - 11s 482us/step - loss: 64.6652 - mean_squared_error: 64.6652 - val_loss: 65.4879 - val_mean_squared_error: 65.4879\n",
      "Epoch 71/100\n",
      "22046/22046 [==============================] - 10s 466us/step - loss: 64.4980 - mean_squared_error: 64.4980 - val_loss: 65.4777 - val_mean_squared_error: 65.4777\n",
      "Epoch 72/100\n",
      "22046/22046 [==============================] - 10s 476us/step - loss: 64.1974 - mean_squared_error: 64.1974 - val_loss: 66.4452 - val_mean_squared_error: 66.4452\n",
      "Epoch 73/100\n",
      "22046/22046 [==============================] - 10s 471us/step - loss: 63.9462 - mean_squared_error: 63.9462 - val_loss: 81.7033 - val_mean_squared_error: 81.7033\n",
      "Epoch 74/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 64.1251 - mean_squared_error: 64.1251 - val_loss: 66.4054 - val_mean_squared_error: 66.4054\n",
      "Epoch 75/100\n",
      "22046/22046 [==============================] - 10s 474us/step - loss: 63.8701 - mean_squared_error: 63.8701 - val_loss: 65.1436 - val_mean_squared_error: 65.1436\n",
      "Epoch 76/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 63.7274 - mean_squared_error: 63.7274 - val_loss: 65.4897 - val_mean_squared_error: 65.4896\n",
      "Epoch 77/100\n",
      "22046/22046 [==============================] - 10s 441us/step - loss: 63.4333 - mean_squared_error: 63.4332 - val_loss: 65.0985 - val_mean_squared_error: 65.0985\n",
      "Epoch 78/100\n",
      "22046/22046 [==============================] - 11s 490us/step - loss: 63.4878 - mean_squared_error: 63.4878 - val_loss: 65.0230 - val_mean_squared_error: 65.0230\n",
      "Epoch 79/100\n",
      "22046/22046 [==============================] - 11s 493us/step - loss: 63.3299 - mean_squared_error: 63.3299 - val_loss: 64.9327 - val_mean_squared_error: 64.9327\n",
      "Epoch 80/100\n",
      "22046/22046 [==============================] - 11s 520us/step - loss: 63.1788 - mean_squared_error: 63.1788 - val_loss: 66.3482 - val_mean_squared_error: 66.3482\n",
      "Epoch 81/100\n",
      "22046/22046 [==============================] - 11s 485us/step - loss: 63.0921 - mean_squared_error: 63.0921 - val_loss: 65.1144 - val_mean_squared_error: 65.1144\n",
      "Epoch 82/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 63.0161 - mean_squared_error: 63.0161 - val_loss: 67.0399 - val_mean_squared_error: 67.0399\n",
      "Epoch 83/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 62.8021 - mean_squared_error: 62.8021 - val_loss: 64.1524 - val_mean_squared_error: 64.1524\n",
      "Epoch 84/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 62.9237 - mean_squared_error: 62.9237 - val_loss: 64.7297 - val_mean_squared_error: 64.7297\n",
      "Epoch 85/100\n",
      "22046/22046 [==============================] - 11s 486us/step - loss: 62.7306 - mean_squared_error: 62.7306 - val_loss: 70.5655 - val_mean_squared_error: 70.5656\n",
      "Epoch 86/100\n",
      "22046/22046 [==============================] - 10s 461us/step - loss: 62.4183 - mean_squared_error: 62.4183 - val_loss: 66.5622 - val_mean_squared_error: 66.5622\n",
      "Epoch 87/100\n",
      "22046/22046 [==============================] - 11s 478us/step - loss: 62.5225 - mean_squared_error: 62.5225 - val_loss: 71.3369 - val_mean_squared_error: 71.3369\n",
      "Epoch 88/100\n",
      "22046/22046 [==============================] - 11s 487us/step - loss: 62.3616 - mean_squared_error: 62.3616 - val_loss: 63.7073 - val_mean_squared_error: 63.7073\n",
      "Epoch 89/100\n",
      "22046/22046 [==============================] - 11s 477us/step - loss: 62.1998 - mean_squared_error: 62.1998 - val_loss: 63.5494 - val_mean_squared_error: 63.5494\n",
      "Epoch 90/100\n",
      "22046/22046 [==============================] - 10s 459us/step - loss: 62.1725 - mean_squared_error: 62.1726 - val_loss: 65.0958 - val_mean_squared_error: 65.0958\n",
      "Epoch 91/100\n",
      "22046/22046 [==============================] - 10s 465us/step - loss: 62.1433 - mean_squared_error: 62.1433 - val_loss: 72.6523 - val_mean_squared_error: 72.6523\n",
      "Epoch 92/100\n",
      "22046/22046 [==============================] - 11s 479us/step - loss: 61.8790 - mean_squared_error: 61.8790 - val_loss: 65.5085 - val_mean_squared_error: 65.5085\n",
      "Epoch 93/100\n",
      "19712/22046 [=========================>....] - ETA: 0s - loss: 61.8868 - mean_squared_error: 61.8868"
     ]
    }
   ],
   "source": [
    "## Create FSRCNN\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, Conv2DTranspose, merge # Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_img = Input(shape=(32,32,3))\n",
    "model = Conv2D(56, (5, 5), padding='same', kernel_initializer='he_normal')(input_img)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(16, (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(12, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(12, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(12, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(12, (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2D(56, (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
    "model = PReLU()(model)\n",
    "model = Conv2DTranspose(3, (9, 9), strides=(4, 4), padding='same')(model)\n",
    "output_img = model\n",
    "\n",
    "model = Model(input_img, output_img)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = adam, metrics=[\"mean_squared_error\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "Results = model.fit(TrainIn, TrainOut, epochs=100, batch_size=32, validation_data=(TestIn,TestOut), validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: [603.4778, 177.1807, 140.7971, 127.0634, 118.3863, 112.1636, 107.1357, 104.0426, 100.6233, 97.7789, 95.8339, 93.9094, 92.0101, 90.4347, 88.4681, 87.619, 85.4094, 84.3058, 83.3763, 81.961, 80.854, 80.0754, 78.8659, 78.2094, 77.3011, 76.5185, 75.7019, 75.2506, 74.0739, 73.6494, 73.1564, 72.7383, 71.7818, 71.5512, 71.0196, 70.3811, 69.822, 69.5974, 69.1962, 68.9069, 68.5386, 68.0346, 68.0191, 67.3101, 67.5725, 66.8465, 66.8657, 66.6049, 66.0988, 65.9479, 66.2408, 65.4877, 65.5312, 65.0516, 65.207, 64.7479, 64.7483, 64.6209, 64.1678, 64.15, 64.0719, 63.7552, 63.7174, 63.4913, 63.748, 62.9288, 63.1247, 63.0251, 62.7186, 62.6796, 62.9762, 62.4469, 62.0599, 62.1274, 62.1146, 61.8613, 61.7741, 61.8657, 61.5643, 61.5268, 61.3072, 61.2596, 61.2738, 61.1602, 60.94, 60.9058, 60.5973, 60.8762, 60.5178, 60.555, 60.2824, 60.2501, 60.4073, 59.8514, 60.0124, 60.0175, 59.6977, 59.7476, 59.7148, 59.5472]\n",
      "Validation Loss: [209.2959, 151.5091, 133.5549, 123.1183, 115.5795, 109.6952, 106.1166, 101.0168, 99.3301, 97.1268, 95.3337, 92.2788, 91.3983, 88.5003, 88.0429, 85.5106, 86.4312, 83.1665, 83.3179, 80.892, 80.1659, 81.039, 78.5088, 77.6535, 92.095, 76.2986, 75.8006, 74.989, 75.8741, 73.5676, 73.806, 74.7346, 78.194, 72.3055, 71.6217, 82.3473, 70.2201, 70.6061, 70.9007, 69.7188, 69.2595, 69.6959, 68.843, 69.3065, 68.3389, 68.8893, 70.4979, 68.2954, 67.5645, 67.9385, 66.7631, 67.3472, 66.7735, 67.7598, 66.4064, 65.9969, 70.8118, 65.9194, 67.1634, 78.4328, 65.9154, 65.2859, 65.0422, 65.1663, 64.7951, 67.2123, 65.745, 64.5651, 65.8454, 65.8594, 64.314, 66.227, 70.4321, 64.5303, 64.4898, 63.8027, 64.1097, 63.1946, 64.236, 63.6908, 63.4599, 63.0594, 63.3257, 62.7516, 77.8461, 62.4281, 62.3999, 62.3624, 62.7397, 68.0273, 62.2669, 62.5309, 68.6986, 63.2279, 62.3369, 62.3054, 61.9249, 69.7736, 61.9205, 69.6382]\n"
     ]
    }
   ],
   "source": [
    "# Display and store performance results\n",
    "Results.history['loss'] = [round(l, 4) for l in Results.history['loss']]\n",
    "Results.history['val_loss'] = [round(l, 4) for l in Results.history['val_loss']]\n",
    "\n",
    "print('Training Loss:',Results.history['loss'])\n",
    "print('Validation Loss:',Results.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
